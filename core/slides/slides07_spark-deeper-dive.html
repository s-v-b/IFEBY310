<!DOCTYPE html>
<html lang="en-US"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e2182856f2c32102dd26b05a5ef16cb5.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/quarto-contrib/reveal-header-1.0.0/add_header.js" defer="true"></script>
<link href="../../site_libs/quarto-contrib/reveal-header-1.0.0/add_header.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/grid-no-htext-1.0.0/grid_no_htext.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.30">

  <meta name="author" content="Équipe de Statistique">
  <meta name="dcterms.date" content="2025-01-17">
  <title>IFEBY310 - Spring 2025 – Spark deeper dive</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #e1e4e8; background-color: #24292e; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #e1e4e8; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #f97583; } /* Attribute */
    code span.bn { color: #79b8ff; } /* BaseN */
    code span.bu { color: #f97583; } /* BuiltIn */
    code span.cf { color: #f97583; } /* ControlFlow */
    code span.ch { color: #9ecbff; } /* Char */
    code span.cn { color: #79b8ff; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #f97583; } /* DataType */
    code span.dv { color: #79b8ff; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #f97583; font-weight: bold; } /* Extension */
    code span.fl { color: #79b8ff; } /* Float */
    code span.fu { color: #b392f0; } /* Function */
    code span.im { color: #9ecbff; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #f97583; } /* Keyword */
    code span.op { color: #e1e4e8; } /* Operator */
    code span.ot { color: #b392f0; } /* Other */
    code span.pp { color: #f97583; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #79b8ff; } /* SpecialChar */
    code span.ss { color: #9ecbff; } /* SpecialString */
    code span.st { color: #9ecbff; } /* String */
    code span.va { color: #ffab70; } /* Variable */
    code span.vs { color: #9ecbff; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-cea8bd4d0ffd43e334db3cf8b0e9d7b6.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script>
  MathJax = {
    loader: {
      load: ['[tex]/boldsymbol']
    },
    tex: {
      tags: "all",
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      packages: {
        '[+]': ['boldsymbol']
      }
    }
  };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<meta property="og:title" content="Spark deeper dive – IFEBY310 - Spring 2025">
<meta property="og:description" content="Technologies Big Data Master MIDS/MFA/LOGOIS">
<meta property="og:site_name" content="IFEBY310 - Spring 2025">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#1c191c" class="quarto-title-block center">
  <h1 class="title">Spark deeper dive</h1>
  <p class="subtitle"><a href="https://s-v-b.github.io/IFEBY030/">Technologies Big Data Master MIDS/MFA/LOGOIS</a></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Équipe de Statistique 
</div>
        <p class="quarto-title-affiliation">
            <a href="https://u-paris.fr">LPSM Université Paris-Cité</a>
          </p>
    </div>
</div>

  <p class="date">2025-01-17</p>
</section><section id="TOC">
<nav role="doc-toc"> 
<h2 id="toc-title">Roadmap</h2>
<ul>
<li><a href="#/shuffles" id="/toc-shuffles">Shuffles</a></li>
<li><a href="#/partitions" id="/toc-partitions">Partitions</a></li>
<li><a href="#/optimizing-shuffles-with-partitioning" id="/toc-optimizing-shuffles-with-partitioning">Optimizing shuffles with partitioning</a></li>
<li><a href="#/optimizing-with-broadcast-join" id="/toc-optimizing-with-broadcast-join">Optimizing with broadcast join</a></li>
<li><a href="#/shuffle-hash-vs-sort-merge-joins" id="/toc-shuffle-hash-vs-sort-merge-joins">Shuffle hash VS sort merge joins</a></li>
<li><a href="#/wide-versus-narrow-dependencies" id="/toc-wide-versus-narrow-dependencies">Wide versus narrow dependencies</a></li>
<li><a href="#/lineage-allows-fault-tolerance" id="/toc-lineage-allows-fault-tolerance">Lineage allows fault tolerance</a></li>
<li><a href="#/catalyst-the-secret-weapon-of-spark.sql" id="/toc-catalyst-the-secret-weapon-of-spark.sql">Catalyst: the secret weapon of <code>spark.sql</code></a></li>
</ul>
</nav>
</section>
<section id="a-deeper-dive-into-spark" class="title-slide slide level1 unlisted center" data-background-color="#1c191c">
<h1>A deeper dive into Spark</h1>

</section>

<section>
<section id="shuffles" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Shuffles</h1>

</section>
<section id="shuffles-1" class="slide level2 center">
<h2>Shuffles</h2>
<p>What happens when we do a <code>reduceByKey</code> on a RDD?</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="op">&gt;&gt;&gt;</span> rdd <span class="op">=</span> sc.parallelize([(<span class="st">"a"</span>, <span class="dv">1</span>), (<span class="st">"b"</span>, <span class="dv">1</span>), (<span class="st">"a"</span>, <span class="dv">1</span>)])</span>
<span id="cb1-2"><a></a><span class="op">&gt;&gt;&gt;</span> rdd.reduceByKey(<span class="kw">lambda</span> a, b: a <span class="op">+</span> b).collect()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s have a look at the <em>Spark UI</em> available at :</p>
<p>http://localhost:4040/jobs/]</p>

<img src="../../images/sparkui.png" style="width: 100%;" class="r-stretch"><aside class="notes">
<p>Relate shuffles to wide transformations</p>
<p>In Spark parlance, in a narrow transformation, each input partition (class of the input partition) contributes to at most one output partition (one class of the output partition).</p>
<p>In a wide transformation, input partitions contribute to several or even many output partitions.</p>
<p>Shuffles correspond to wide transformations.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="shuffles-2" class="slide level2 center">
<h2>Shuffles</h2>
<p><img src="../../images/dag_reducebykey1.png" style="width: 30%;"> <img src="" style="width: 10%;"> <img src="../../images/dag_reducebykey2.png" style="width: 30%;"></p>
<ul>
<li><p>Spark has to <strong>move data from one node to another</strong> to be “grouped” with its “key”</p></li>
<li><p>Doing this is called <em>shuffling</em>. It is never called directly, it happens behind the curtains for some other functions as <code>reduceByKey</code> above.</p></li>
<li><p>This might be <em>very expensive</em> because of <strong>latency</strong></p></li>
</ul>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="shuffles-3" class="slide level2 center">
<h2>Shuffles</h2>
<ul>
<li><p><code>reduceByKey</code> results in <em>one</em> key-value pair <strong>per key</strong></p></li>
<li><p>This single key-value pair <strong>cannot</strong> span across <strong>multiple workers</strong>.</p></li>
</ul>
</section>
<section id="example" class="slide level2 center">
<h2>Example</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> collections <span class="im">import</span> namedtuple</span>
<span id="cb2-2"><a></a><span class="op">&gt;&gt;&gt;</span> columns <span class="op">=</span> [<span class="st">"client_id"</span>, <span class="st">"destination"</span>, <span class="st">"price"</span>]</span>
<span id="cb2-3"><a></a><span class="op">&gt;&gt;&gt;</span> CFFPurchase <span class="op">=</span> namedtuple(<span class="st">"CFFPurchase"</span>, columns)</span>
<span id="cb2-4"><a></a><span class="op">&gt;&gt;&gt;</span> CFFPurchase(<span class="dv">100</span>, <span class="st">"Geneva"</span>, <span class="fl">22.25</span>)</span>
<span id="cb2-5"><a></a>CFFPurchase(client_id<span class="op">=</span><span class="dv">100</span>, destination<span class="op">=</span><span class="st">'Geneva'</span>, price<span class="op">=</span><span class="fl">22.25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Goal</strong>: calculate <em>how many trips and how much money was spent by each client</em></p>
</section>
<section id="example-cont." class="slide level2 center">
<h2>Example (cont.)</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="op">&gt;&gt;&gt;</span> purchases <span class="op">=</span> [</span>
<span id="cb3-2"><a></a>        CFFPurchase(<span class="dv">100</span>, <span class="st">"Geneva"</span>, <span class="fl">22.25</span>),</span>
<span id="cb3-3"><a></a>        CFFPurchase(<span class="dv">100</span>, <span class="st">"Zurich"</span>, <span class="fl">42.10</span>),</span>
<span id="cb3-4"><a></a>        CFFPurchase(<span class="dv">100</span>, <span class="st">"Fribourg"</span>, <span class="fl">12.40</span>),</span>
<span id="cb3-5"><a></a>        CFFPurchase(<span class="dv">101</span>, <span class="st">"St.Gallen"</span>, <span class="fl">8.20</span>),</span>
<span id="cb3-6"><a></a>        CFFPurchase(<span class="dv">101</span>, <span class="st">"Lucerne"</span>, <span class="fl">31.60</span>),</span>
<span id="cb3-7"><a></a>        CFFPurchase(<span class="dv">100</span>, <span class="st">"Basel"</span>, <span class="fl">16.20</span>)</span>
<span id="cb3-8"><a></a>    ]</span>
<span id="cb3-9"><a></a><span class="op">&gt;&gt;&gt;</span> purchases <span class="op">=</span> sc.parallelize(purchases)</span>
<span id="cb3-10"><a></a><span class="op">&gt;&gt;&gt;</span> purchases.collect()</span>
<span id="cb3-11"><a></a>[CFFPurchase(client_id<span class="op">=</span><span class="dv">100</span>, destination<span class="op">=</span><span class="st">'Geneva'</span>, price<span class="op">=</span><span class="fl">22.25</span>),</span>
<span id="cb3-12"><a></a> CFFPurchase(client_id<span class="op">=</span><span class="dv">100</span>, destination<span class="op">=</span><span class="st">'Zurich'</span>, price<span class="op">=</span><span class="fl">42.1</span>),</span>
<span id="cb3-13"><a></a> CFFPurchase(client_id<span class="op">=</span><span class="dv">100</span>, destination<span class="op">=</span><span class="st">'Fribourg'</span>, price<span class="op">=</span><span class="fl">12.4</span>),</span>
<span id="cb3-14"><a></a> CFFPurchase(client_id<span class="op">=</span><span class="dv">101</span>, destination<span class="op">=</span><span class="st">'St.Gallen'</span>, price<span class="op">=</span><span class="fl">8.2</span>),</span>
<span id="cb3-15"><a></a> CFFPurchase(client_id<span class="op">=</span><span class="dv">101</span>, destination<span class="op">=</span><span class="st">'Lucerne'</span>, price<span class="op">=</span><span class="fl">31.6</span>),</span>
<span id="cb3-16"><a></a> CFFPurchase(client_id<span class="op">=</span><span class="dv">100</span>, destination<span class="op">=</span><span class="st">'Basel'</span>, price<span class="op">=</span><span class="fl">16.2</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>How are <code>namedtuple</code> translated into Spark types?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-cont.-1" class="slide level2 center">
<h2>Example (cont.)</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="op">&gt;&gt;&gt;</span> purchases_per_client <span class="op">=</span> (purchases</span>
<span id="cb4-2"><a></a>        <span class="co"># Pair RDD</span></span>
<span id="cb4-3"><a></a>        .<span class="bu">map</span>(<span class="kw">lambda</span> p: (p.client_id, p.price))</span>
<span id="cb4-4"><a></a>        <span class="co"># RDD[p.customerId, List[p.price]]</span></span>
<span id="cb4-5"><a></a>        .groupByKey()                          </span>
<span id="cb4-6"><a></a>        .<span class="bu">map</span>(<span class="kw">lambda</span> p: (p[<span class="dv">0</span>], (<span class="bu">len</span>(p[<span class="dv">1</span>]), <span class="bu">sum</span>(p[<span class="dv">1</span>]))))</span>
<span id="cb4-7"><a></a>        .collect()</span>
<span id="cb4-8"><a></a>    )</span>
<span id="cb4-9"><a></a><span class="op">&gt;&gt;&gt;</span> purchases_per_client</span>
<span id="cb4-10"><a></a>[(<span class="dv">100</span>, (<span class="dv">4</span>, <span class="fl">92.95</span>)), (<span class="dv">101</span>, (<span class="dv">2</span>, <span class="fl">39.8</span>))]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>How would this <strong>looks on a cluster?</strong> (imagine that the dataset has millions of purchases)</p>
</section>
<section id="shuffles-4" class="slide level2 center">
<h2>Shuffles</h2>
<ul>
<li>Lets say we have <strong>3 worker nodes</strong> and our data is <strong>evenly distributed on it</strong>, so the operations above look like this:</li>
</ul>

<img src="../../images/shuffline.png" style="width: 95%;" class="r-stretch"><ul>
<li><p>This shuffling is very expensive because of <em>latency</em></p></li>
<li><p>Can we do a <strong>better job</strong>?</p></li>
</ul>
</section>
<section id="shuffles-5" class="slide level2 center">
<h2>Shuffles</h2>
<p>Perhaps we can <em>reduce before we shuffle</em> in order to greatly reduce the amount of data sent over network. We use <code>reduceByKey</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="op">&gt;&gt;&gt;</span> purchases_per_client <span class="op">=</span> (purchases</span>
<span id="cb5-2"><a></a>        .<span class="bu">map</span>(<span class="kw">lambda</span> p: (p.client_id, (<span class="dv">1</span>, p.price)))</span>
<span id="cb5-3"><a></a>        .reduceByKey(<span class="kw">lambda</span> v1, v2: (v1[<span class="dv">0</span>] <span class="op">+</span> v2[<span class="dv">0</span>], v1[<span class="dv">1</span>] <span class="op">+</span> v2[<span class="dv">1</span>]))</span>
<span id="cb5-4"><a></a>        .collect()</span>
<span id="cb5-5"><a></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This looks like on the cluster:</p>

<img src="../../images/shuffline_2.png" style="width: 80%;" class="r-stretch"></section>
<section id="shuffles-6" class="slide level2 center">
<h2>Shuffles</h2>
<ul>
<li><code>groupByKey</code> (left) VS <code>reduceByKey</code> (right) :</li>
</ul>
<p><img src="../../images/shuffline.png" style="width: 49%;"> <img src="../../images/shuffline_2.png" style="width: 49%;"></p>
<ul>
<li>With <code>reduceByKey</code> we shuffle considerably less amount of data</li>
</ul>
<p><strong>Benefits of this approach:</strong></p>
<ul>
<li>by <em>reducing the data first</em>, the amount of data sent during the shuffle is <strong>greatly reduced</strong>, leading to strong performance gains!</li>
<li>This is because <code>groupByKey</code> requires collecting <strong>all key-value pairs with the same key on the same machine</strong> while <code>reduceByKey</code> <strong>reduces locally</strong> before shuffling.</li>
</ul>
</section></section>
<section>
<section id="partitions" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Partitions</h1>

</section>
<section id="partitioning" class="slide level2 center">
<h2>Partitioning</h2>
<p>How does Spark know which key to put on which machine?</p>
<ul>
<li>By default, Spark uses <em>hash partitioning</em> to determine <strong>which key-value pair</strong> should be sent to <strong>which machine</strong>.</li>
</ul>
<p>The data <strong>within an RDD</strong> is <em>split</em> into several <em>partitions</em>. Some properties of partitions:</p>
<ul>
<li>Partitions <strong>never</strong> span <em>multiple machines</em>, data in the <strong>same partition</strong> is always on the <strong>same worker machine</strong>.</li>
<li><strong>Each machine</strong> in the cluster contains <strong>one</strong> or <strong>more</strong> partitions.</li>
<li>The <em>number of partitions</em> to use is <strong>configurable</strong>. By default, it is the <em>total number of cores on all executor nodes</em>; 6 workers with 4 cores should lead to 24 partitions.</li>
</ul>
</section>
<section id="partitioning-1" class="slide level2 center">
<h2>Partitioning</h2>
<p>Two kinds of partitioning are available in Spark:</p>
<ul>
<li><p><em>Hash</em> partitioning</p></li>
<li><p><em>Range</em> partitioning</p></li>
</ul>
<p>Customizing a partitioning is only possible on a <code>PairRDD</code> and <code>DataFrame</code>, namely <strong>something with keys</strong>.</p>
</section>
<section id="hash-partitioning" class="slide level2 center">
<h2>Hash Partitioning</h2>
<p>Given a Pair RDD that should be grouped, <code>groupByKey</code> first computes per tuple <code>(k,v)</code> its partition <code>p</code>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a>p <span class="op">=</span> k.hashCode() <span class="op">%</span> numPartitions</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then, all tuples in the same partition <code>p</code> are sent to the machine hosting <code>p</code>.</p>
</section>
<section id="partitioning-2" class="slide level2 center">
<h2>Partitioning</h2>
<p><strong>Intuition:</strong> hash partitioning attempts to <em>spread data evenly</em> across partitions <strong>based on the key</strong>.</p>
<p>The other kind of partitioning is <em>range partitioning</em></p>
</section>
<section id="range-partitioning" class="slide level2 center scrollable">
<h2>Range Partitioning</h2>
<ul>
<li>Pair RDDs may contain keys that have an <em>ordering</em> defined, such as <code>int</code>, <code>String</code>, etc.</li>
<li>For such RDDs, <em>range partitioning</em> may be more efficient.</li>
</ul>
<p>Using a <strong>range partitioner</strong>, keys are partitioned according to 2 things:</p>
<ol type="1">
<li>an <strong>ordering</strong> for keys</li>
<li>a set of <strong>sorted ranges</strong> of keys</li>
</ol>
<p>(key, value) pairs with keys in the <strong>same range</strong> end up in the <strong>same partition</strong>.</p>
</section>
<section id="partitioning-3" class="slide level2 center">
<h2>Partitioning</h2>
<p>Consider a Pair RDD with keys: <code>[8, 96, 240, 400, 401, 800]</code>, and a desired number of partitions of 4.</p>
<p>With <strong>hash partitioning</strong></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a>p <span class="op">=</span> k.hashCode() <span class="op">%</span> numPartitions</span>
<span id="cb7-2"><a></a>  <span class="op">=</span> k <span class="op">%</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>leads to:</p>
<ul>
<li>Partition 0: <code>[8, 96, 240, 400, 800]</code></li>
<li>Partition 1: <code>[401]</code></li>
<li>Partition 2: <code>[]</code></li>
<li>Partition 3: <code>[]</code></li>
</ul>
<p>This results in a <em>very unbalanced distribution</em> which <strong>hurts performance</strong>, since the data is <strong>spread mostly on 1 node</strong>, so not very parallel.</p>
</section>
<section id="partitioning-4" class="slide level2 center">
<h2>Partitioning</h2>
<p>In this case, using <strong>range partitioning</strong> can <em>improve the distribution</em> significantly.</p>
<ul>
<li>Assumptions: (a) keys are non-negative, (b) 800 is the biggest key</li>
<li>Ranges: <code>[1-200], [201-400], [401-600], [601-800]</code></li>
</ul>
<p>Based on this the keys are distributed as follows:</p>
<ul>
<li>Partition 0: <code>[8, 96]</code></li>
<li>Partition 1: <code>[240, 400]</code></li>
<li>Partition 2: <code>[401]</code></li>
<li>Partition 3: <code>[800]</code></li>
</ul>
<p>This is <em>much more balanced</em>.</p>
</section>
<section id="partitioning-5" class="slide level2 center scrollable">
<h2>Partitioning</h2>
<p>How do we set a partitioning for our data?</p>
<ol type="1">
<li><p>On a Pair RDD: call <code>partitionBy</code>, providing an explicit <code>Partitioner</code> (<code>scala</code> only, use a partitioning function in <code>pyspark</code>)</p></li>
<li><p>On a DataFrame: Call <code>repartition</code> for <strong>hash partitioning</strong> and <code>repartitionByRange</code> for <strong>range partitioning</strong></p></li>
<li><p>Using transformations that return a RDD or a DataFrame with <strong>specific partitioners</strong>.</p></li>
</ol>
</section>
<section id="partitioning-a-rdd-using-partitionby" class="slide level2 center">
<h2>Partitioning a <code>RDD</code> using <code>partitionBy</code></h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a><span class="op">&gt;&gt;&gt;</span> pairs <span class="op">=</span> purchases.<span class="bu">map</span>(<span class="kw">lambda</span> p: (p.client_id, p.price))</span>
<span id="cb8-2"><a></a><span class="op">&gt;&gt;&gt;</span> pairs <span class="op">=</span> pairs.partitionBy(<span class="dv">3</span>, <span class="st">"client_id"</span>)</span>
<span id="cb8-3"><a></a><span class="op">&gt;&gt;&gt;</span> pairs.getNumPartitions()</span>
<span id="cb8-4"><a></a><span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="partitioning-6" class="slide level2 center scrollable">
<h2>Partitioning</h2>
<p>Using <code>RangePartitioner</code> with <code>pyspark</code> requires</p>
<ol type="1">
<li><p>Specifying the desired number of partitions</p></li>
<li><p>Providing a DataFrame with <strong>orderable keys</strong></p></li>
</ol>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>pairs <span class="op">=</span> purchases.<span class="bu">map</span>(<span class="kw">lambda</span> p: (p.client_id, p.price))</span>
<span id="cb9-2"><a></a>pairs <span class="op">=</span> spark.createDataFrame(pairs, [<span class="st">"id"</span>, <span class="st">"price"</span>])</span>
<span id="cb9-3"><a></a>pairs.repartitionByRange(<span class="dv">3</span>, <span class="st">"price"</span>).persist()</span>
<span id="cb9-4"><a></a>pairs.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>The result of <code>partitionBy</code>, <code>repartition</code>, <code>repartitionByRange</code> <em>should be persisted</em>.</p></li>
<li><p>Otherwise <strong>partitioning is repeatedly applied</strong> (with shuffling!) each time the partitioned data is used.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="partitioning-using-transformations" class="slide level2 center">
<h2>Partitioning using transformations</h2>
<ul>
<li><p>Pair RDDs that are <strong>result of a transformation</strong> on a <em>partitioned</em> Pair RDD use typically the <em>same</em> hash partitioner</p></li>
<li><p>Some operations on RDDs <strong>automatically</strong> result in an RDD with a <strong>known</strong> partitioner - when it makes sense.</p></li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Examples</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>When using <code>sortByKey</code>, a <code>RangePartitioner</code> is used.</p></li>
<li><p>With <code>groupByKey</code>, a default hash partitioner is used.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="operations-on-pair-rdds-that-hold-to-and-propagate-a-partitioner" class="slide level2 center">
<h2>Operations on Pair RDDs that <strong>hold to</strong> and <strong>propagate</strong> a partitioner:</h2>
<ul>
<li><p><code>cogroup</code>, <code>groupWith</code>, <code>join</code>, <code>leftOuterJoin</code>, <code>rightOuterJoin</code></p></li>
<li><p><code>[group,reduce,fold,combine]ByKey</code>, <code>partitionBy</code>, <code>sort</code></p></li>
<li><p><code>mapValues</code>, <code>flatMapValues</code>, <code>filter</code> (if parent has a partitioner)</p></li>
</ul>
<p><strong>All other operations</strong> will produce a result <em>without partitioner</em>!</p>
<aside class="notes">
<p>Why?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="partitioning-7" class="slide level2 center">
<h2>Partitioning</h2>
<p>Consider the <code>map</code> transformation. Given that we have a hash-partitioned Pair RDD, <em>why loosing the partitioner</em> in the returned RDD?</p>
<p>Because its possible for <code>map</code> or <code>flatMap</code> to <em>change</em> the key:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>hashPartitionedRdd.<span class="bu">map</span>(<span class="kw">lambda</span> k, v: (<span class="st">"ooooops"</span>, v))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If the <code>map</code> transformation preserved the previous partitioner, it would no longer makes sense: the keys are all same after this <code>map</code></p>
<p>Hence, use <code>mapValues</code>, since it enables to do <code>map</code> transformations <strong>without changing the keys</strong>, thereby preserving the partitioner.</p>
</section></section>
<section>
<section id="optimizing-shuffles-with-partitioning" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Optimizing shuffles with partitioning</h1>

</section>
<section id="optimizing-with-partitioning" class="slide level2 center">
<h2>Optimizing with partitioning</h2>
<p><strong>Why would we want to repartition the data?</strong></p>
<ul>
<li><p>Because it can bring <em>substantial performance gains</em>, especially before <strong>shuffles</strong>.</p></li>
<li><p>We saw that using <code>reduceByKey</code> instead of <code>groupByKey</code> <em>localizes data better</em> due to different <strong>partitioning</strong> strategies and thus <strong>reduces latency</strong> to deliver <strong>performance gains</strong>.</p></li>
<li><p>By manually repartitioning the data for the same example as before, we can <em>improve the performance even further</em>.</p></li>
<li><p>By using <strong>range partitioners</strong> we can optimize the use of <code>reduceByKey</code> in that example so that it <em>does not involve any shuffling</em> over the network at all!</p></li>
</ul>
</section>
<section id="optimizing-with-partitioning-1" class="slide level2 center">
<h2>Optimizing with partitioning</h2>
<p>Compared to what we did previously, we use <code>sortByKey</code> to produce a range partitioner for the RDD that we immediately persist.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="op">&gt;&gt;&gt;</span> pairs <span class="op">=</span> purchases.<span class="bu">map</span>(<span class="kw">lambda</span> p: (p.client_id, (<span class="dv">1</span>, p.price)))</span>
<span id="cb11-2"><a></a><span class="op">&gt;&gt;&gt;</span> pairs <span class="op">=</span> pairs.sortByKey().persist()</span>
<span id="cb11-3"><a></a><span class="op">&gt;&gt;&gt;</span> pairs.reduceByKey(</span>
<span id="cb11-4"><a></a>       <span class="kw">lambda</span> v1, v2: (v1[<span class="dv">0</span>] <span class="op">+</span> v2[<span class="dv">0</span>], v1[<span class="dv">1</span>] <span class="op">+</span> v2[<span class="dv">1</span>])</span>
<span id="cb11-5"><a></a>    ).collect()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This typically leads to <em>much faster computations</em> in this case (for large RDD, not the small toy example from before).</p>
</section></section>
<section>
<section id="optimizing-with-broadcast-join" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Optimizing with broadcast join</h1>

</section>
<section id="optimizing-with-broadcasting" class="slide level2 center">
<h2>Optimizing with broadcasting</h2>
<p>When joining two DataDrames, where one is small enough to <strong>fit in memory</strong>, it is <em>broadcasted</em> over <strong>all the workers</strong> where the large DataFrame resides (and a hash join is performed). This has two phases:</p>
<ul>
<li><strong>Broadcast</strong>: the smaller DataFrame is broadcasted across workers containing the large one</li>
<li><strong>Hash join</strong>: a standard hash join is executed on each workder</li>
</ul>
<p>There is therefore <em>no shuffling</em> involved and this can be <strong>much faster</strong> than a regular join.</p>
<p>The default threshold for broadcasting is</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a><span class="op">&gt;&gt;&gt;</span> spark.conf.get(<span class="st">"spark.sql.autoBroadcastJoinThreshold"</span>)</span>
<span id="cb12-2"><a></a><span class="co">'10485760'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>meaning 10MB</p>
</section>
<section id="optimizing-with-broadcasting-1" class="slide level2 center">
<h2>Optimizing with broadcasting</h2>
<p>Can be changed using</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="op">&gt;&gt;&gt;</span> spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.autoBroadcastJoinThreshold"</span>, <span class="st">"20971520"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>"spark.broadcast.compress"</code> can be used to configure whether to compress the data before sending it (<code>True</code> by default).</p>
<p>It uses the compression specified in <code>"spark.io.compression.codec config"</code> and the default is <code>"lz4"</code>. We can use other compression codecs but what the hell.</p>
<p>More important: even though a DataFrame is small, sometimes Spark can’t estimate the size of it. We can <strong>enforce</strong> using a <em>broadcast hint</em>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> pyspark.sql.functions <span class="im">import</span> broadcast</span>
<span id="cb14-2"><a></a><span class="op">&gt;&gt;&gt;</span> largeDF.join(broadcast(smallDF))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="optimizing-with-broadcasting-2" class="slide level2 center">
<h2>Optimizing with broadcasting</h2>
<ul>
<li><p>If a <strong>broadcast hint</strong> is specified, the side with the hint will be <em>broadcasted</em> irrespective of <code>autoBroadcastJoinThreshold</code>.</p></li>
<li><p>If <strong>both sides</strong> have broadcast hints, the side <strong>with a smallest estimated size</strong> will be broadcasted.</p></li>
<li><p>If there is <strong>no hint</strong> and the estimated size of DataFrame &lt; <code>autoBroadcastJoinThreshold</code>, that table is usually broadcasted</p></li>
<li><p>Spark has a <strong>BitTorrent-like</strong> implementation to perform broadcast. Allows to <strong>avoid the driver being the bottleneck</strong> when sending data to multiple executors.</p></li>
</ul>
</section>
<section id="optimizing-with-broadcasting-3" class="slide level2 center">
<h2>Optimizing with broadcasting</h2>
<ul>
<li><p><strong>Usually</strong>, a <strong>broadcast join</strong> performs <em>faster</em> than other join algorithms when the broadcast side is small enough.</p></li>
<li><p>However, broadcasting tables is <strong>network-intensive</strong> and can cause <code>out of memory</code> errors or even <strong>perform worse</strong> than other joins if the <em>broadcasted table is too large</em>.</p></li>
<li><p>Broadcast join is <strong>not</strong> supported for a <strong>full outer join</strong>. For <strong>right outer join</strong>, only <strong>left side</strong> table can be broadcasted and for other <strong>left joins</strong> only the <strong>right table</strong> can be broadcasted.</p></li>
</ul>
</section></section>
<section>
<section id="shuffle-hash-vs-sort-merge-joins" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Shuffle hash VS sort merge joins</h1>

</section>
<section id="shuffle-hash-vs-sort-merge-joins-1" class="slide level2 center">
<h2>Shuffle hash VS sort merge joins</h2>
<p>Spark can use mainly <strong>two strategies</strong> for joining:</p>
<ul>
<li><em>Shuffle hash</em> join</li>
<li><em>Sort merge</em> join</li>
</ul>
<p>Sort merge join is the <strong>default join strategy</strong>, since it is very scalable and <em>performs better</em> than other joins <strong>most of the times</strong>.</p>
<p><strong>Shuffle hash join</strong> is used as the join strategy when:</p>
<ul>
<li><code>spark.sql.join.preferSortMergeJoin</code> is set to <code>False</code></li>
<li>the cost to build a hash map is <strong>less</strong> than sorting the data.</li>
</ul>
</section>
<section id="shuffle-hash" class="slide level2 center scrollable">
<h2>Shuffle hash</h2>
<p><strong>Shuffle hash</strong> join has 2 phases:</p>
<ol type="1">
<li>A <em>shuffle</em> phase, where data from the join tables are <strong>partitioned based on the join key</strong>. This <strong>shuffles data</strong> across the partitions. Data with the <em>same keys</em> end up in the <em>same partition</em>: the <strong>data required</strong> for joins is available in the <strong>same partition</strong>.</li>
<li><em>Hash join</em> phase: data on <strong>each partition</strong> performs a <strong>single node</strong> hash join.</li>
</ol>
<p>Thus, shuffle hash join <strong>breaks apart</strong> the big join of two tables into <strong>localized smaller chunks</strong>.</p>
<ul>
<li>Shuffle is <strong>very expensive</strong>, the creation of Hash tables is also <strong>expensive</strong> and <strong>memory bound</strong>.</li>
<li>Shuffle hash join is <strong>not suited</strong> for joins that <em>wouldn’t fit in memory</em>.</li>
</ul>
</section>
<section id="shuffle-hash-1" class="slide level2 center">
<h2>Shuffle hash</h2>
<ul>
<li>The <strong>performance</strong> of shuffle hash join depends on the <em>distribution of the keys</em>. The <strong>greater</strong> number of <strong>unique</strong> join keys the <strong>better</strong> data distribution we get.</li>
<li>Maximum amount of <strong>achievable parallelism</strong> is proportional to the <strong>number of unique keys</strong>.</li>
</ul>
<p>By default, <strong>sort merge join</strong> is <em>preferred</em> over <strong>shuffle hash join</strong>. <code>ShuffledHashJoin</code> is still useful when:</p>
<ul>
<li>Any partition of the resulting table can <strong>fit in memory</strong></li>
<li>One table is <strong>much smaller</strong> than the other one, so that building a <strong>hash table</strong> of the <strong>small</strong> table is <em>smaller</em> than <strong>sorting the large table</strong>.</li>
</ul>
<p>This explains why this shuffle is used for <strong>broadcast joins</strong>.</p>
</section>
<section id="sort-merge-join" class="slide level2 center scrollable">
<h2>Sort merge join</h2>
<p><strong>Sort merge join</strong> is Spark’s <em>default join strategy</em> if:</p>
<ul>
<li>matching join keys are <strong>sortable</strong></li>
<li><strong>not eligible</strong> for <strong>broadcast join</strong> or <strong>shuffle hash join</strong>.</li>
</ul>
<p>It is <strong>very scalable</strong> and is an <strong>inheritance of Hadoop</strong> and map-reduce programs. What makes it <strong>scalable</strong> is that it can <strong>spill data to the disk</strong> and doesn’t require the <strong>entire data</strong> to <em>fit inside the memory</em>.</p>
<p>It has <strong>three</strong> phases:</p>
<ol type="1">
<li><em>Shuffle</em> phase: the two large tables are <strong>(re)partitioned</strong> using the join key(s) across the partitions in the cluster.</li>
<li><em>Sort</em> phase: <strong>sort</strong> the data <strong>within each partition</strong> in parallel.</li>
<li><em>Merge</em> phase: <strong>join</strong> the <strong>sorted</strong> and <strong>partitioned</strong> data. This is simply <strong>merging the datasets</strong> by iterating over the elements and joining the rows having the <strong>same value for the join key</strong>.</li>
</ol>
</section>
<section id="sort-merge-join-1" class="slide level2 center">
<h2>Sort merge join</h2>
<ul>
<li>For ideal performance of the sort merge join, all rows <strong>with the same join key(s)</strong> are available in the <strong>same partition</strong>. This can help with the infamous partition exchange (shuffle) between workers.</li>
<li><strong>Collocated partitions</strong> can <em>avoid unnecessary data shuffle</em>.</li>
<li>Data needs to be <em>evenly distributed</em> in the join keys, so that they can be <strong>equally distributed across the cluster</strong> to achieve the <strong>maximum parallelism</strong> from the available partitions.</li>
</ul>
</section>
<section id="other-join-types" class="slide level2 center">
<h2>Other join types</h2>
<p>There are <strong>other join types</strong>, such as <code>BroadcastNestedLoopJoin</code> in weird situations where <em>no joining keys are specified</em> and either there is a broadcast hint or the size of a table is &lt; <code>autoBroadcastJoinThreshold</code>.</p>
<p>In words: <em>don’t use these</em>, if you see these in an execution plan or in the Spark UI, it usually means that something <strong>has been done poorly</strong>.</p>
</section>
<section id="take-home-messages-on-joins" class="slide level2 center">
<h2>Take home messages on joins</h2>
<ul>
<li><p><strong>Sort merge join</strong> is the <em>default</em> join and performs well in most of the scenarios.</p></li>
<li><p>In <strong>some</strong> cases, if you are confident enough that <strong>shuffle hash join</strong> is <em>better</em> than sort merge join, you can <strong>disable sort merge join</strong> for those scenarios.</p></li>
<li><p>Tune <code>spark.sql.autoBroadcastJoinThreshold</code> accordingly if deemed necessary. Try to use <em>broadcast joins</em> wherever possible and <em>filter out the irrelevant rows</em> to the join key <strong>before</strong> the join to <strong>avoid unnecessary data shuffling</strong>.</p></li>
<li><p>Joins <strong>without unique join keys</strong> or <strong>no join keys</strong> can often be very expensive and <em>should be avoided</em>.</p></li>
</ul>
</section>
<section id="how-do-i-know-when-a-shuffle-will-occur" class="slide level2 center scrollable">
<h2>How do I know when a shuffle will occur?</h2>
<p><strong>Rule of thumb</strong>: a shuffle <strong>can</strong> occur when the resulting data <em>depends on other data</em> (can be the same or another RDD/DataFrame).</p>
<p>We can also <strong>figure out</strong> if a <em>shuffle</em> has been <strong>planned</strong> or <strong>executed</strong> via:</p>
<ol type="1">
<li>The return type of certain transformations (in <code>scala</code> only)</li>
<li>By looking at the <em>Spark UI</em></li>
<li>Using <code>toDebugString</code> on a RDD to see its execution plan:</li>
</ol>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(pairs.toDebugString().decode(<span class="st">"utf-8"</span>))</span>
<span id="cb15-2"><a></a>(<span class="dv">3</span>) PythonRDD[<span class="dv">157</span>] at RDD at PythonRDD.scala:<span class="dv">53</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb15-3"><a></a> <span class="op">|</span>       CachedPartitions: <span class="dv">3</span><span class="op">;</span> MemorySize: <span class="fl">233.0</span> B<span class="op">;</span> ExternalBlockStoreSize: <span class="fl">0.0</span> B<span class="op">;</span> DiskSize: <span class="fl">0.0</span> B</span>
<span id="cb15-4"><a></a> <span class="op">|</span>  MapPartitionsRDD[<span class="dv">156</span>] at mapPartitions at PythonRDD.scala:<span class="dv">133</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb15-5"><a></a> <span class="op">|</span>  ShuffledRDD[<span class="dv">155</span>] at partitionBy at <span class="op">&lt;</span>unknown<span class="op">&gt;</span>:<span class="dv">0</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb15-6"><a></a> <span class="op">+-</span>(<span class="dv">8</span>) PairwiseRDD[<span class="dv">154</span>] at sortByKey at <span class="op">&lt;</span>ipython<span class="op">-</span><span class="bu">input</span><span class="op">-</span><span class="dv">35</span><span class="op">-</span><span class="dv">112008</span><span class="er">c310ec</span><span class="op">&gt;</span>:<span class="dv">2</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb15-7"><a></a>    <span class="op">|</span>  PythonRDD[<span class="dv">153</span>] at sortByKey at <span class="op">&lt;</span>ipython<span class="op">-</span><span class="bu">input</span><span class="op">-</span><span class="dv">35</span><span class="op">-</span><span class="dv">112008</span><span class="er">c310ec</span><span class="op">&gt;</span>:<span class="dv">2</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb15-8"><a></a>    <span class="op">|</span>  ParallelCollectionRDD[<span class="dv">0</span>] at parallelize at PythonRDD.scala:<span class="dv">195</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="how-do-i-know-when-a-shuffle-will-occur-1" class="slide level2 center scrollable">
<h2>How do I know when a shuffle will occur?</h2>
<p>Operations that <strong>might</strong> cause a shuffle:</p>
<ul>
<li><code>cogroup</code>, <code>groupWith</code>, <code>join</code>, <code>leftOuterJoin</code>, <code>rightOuterJoin</code>, <code>groupByKey</code>, <code>reduceByKey</code>, <code>combineByKey</code>, <code>distinct</code>, <code>intersection</code>, <code>repartition</code>, <code>coalesce</code></li>
</ul>
<p>When can we <em>avoid shuffles</em> using <strong>partitioning</strong> ?</p>
<ol type="1">
<li><code>reduceByKey</code> running on a pre-partitioned RDD will cause the values to be computed <strong>locally</strong>, requiring only the final reduced value to be sent to the driver.</li>
<li><code>join</code> called on 2 RDDs that are pre-partitioned with the same partitioner and cached on the same machine will cause the join to be computed <strong>locally</strong>, with no shuffling across the network.</li>
</ol>
</section></section>
<section>
<section id="wide-versus-narrow-dependencies" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Wide versus narrow dependencies</h1>

</section>
<section id="wide-versus-narrow-dependencies-1" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<ul>
<li><p>We have seen that some transformations are <strong>significantly more expensive (latency)</strong> than others</p></li>
<li><p>This is often explained by <em>wide</em> versus <em>narrow dependencies</em>, which dictate <strong>relationships between RDDs</strong> in <strong>graphs of computation</strong>, that has a lot to do with <em>shuffling</em></p></li>
</ul>
</section>
<section id="lineages" class="slide level2 center">
<h2>Lineages</h2>
<ul>
<li><p>Computations on RDDs are represented as a <em>lineage graph</em>: a <em>DAG</em> representing the <strong>computations done on the RDD</strong>.</p></li>
<li><p>This DAG is what Spark <strong>analyzes</strong> to do <strong>optimizations</strong>. Thanks to this, it is possible for an operation to step back and figure out how a result is derived from a particular point.</p></li>
</ul>
</section>
<section id="wide-versus-narrow-dependencies-2" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Example</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a>rdd <span class="op">=</span> sc.textFile(...)</span>
<span id="cb16-2"><a></a></span>
<span id="cb16-3"><a></a>filtered <span class="op">=</span> (</span>
<span id="cb16-4"><a></a>  rdd.<span class="bu">map</span>(...)</span>
<span id="cb16-5"><a></a>     .<span class="bu">filter</span>(...)</span>
<span id="cb16-6"><a></a>     .persist()</span>
<span id="cb16-7"><a></a>)</span>
<span id="cb16-8"><a></a></span>
<span id="cb16-9"><a></a>count <span class="op">=</span> filtered.count()</span>
<span id="cb16-10"><a></a>reduced <span class="op">=</span> filtered.<span class="bu">reduce</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="width:50%;">
<p><img src="../../images/lineage_graph.png"></p>
</div></div>
<!-- end columns -->
</section>
<section id="wide-versus-narrow-dependencies-3" class="slide level2 smaller scrollable center">
<h2>Wide versus narrow dependencies</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>RDDs are made up of <strong>4 parts</strong>:</p>
<ul>
<li><p><strong>Partitions</strong>: <em>atomic pieces</em> of the dataset. <strong>One</strong> or <strong>many</strong> per worker</p></li>
<li><p><strong>Dependencies</strong>: models <em>relationship</em> between <strong>this RDD</strong> and <strong>its partitions</strong> with the RDD(s) it was derived from (dependencies maybe modeled per partition)</p></li>
<li><p>A <strong>function</strong> for <em>computing the dataset</em> based on its parent RDDs</p></li>
<li><p><strong>Metadata</strong> about partitioning <em>scheme</em> and data placement.</p></li>
</ul>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:30%;">
<p><img src="../../images/rdd_anatomy_1.png"></p>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:30%;">
<p><img src="../../images/rdd_anatomy_2.png"></p>
</div></div>
<!-- end columns -->
</section>
<section id="wide-versus-narrow-dependencies-4" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<p><strong>RDD dependencies and shuffles</strong></p>
<ul>
<li>We saw a <strong>rule of thumb</strong>: a <em>shuffle</em> can occur when the <strong>resulting RDD depends on other elements</strong> from the same RDD or another RDD.</li>
<li>In fact, <em>RDD dependencies</em> <strong>encode</strong> when data <em>must be shuffled</em>.</li>
</ul>
<p>Transformations cause shuffles, and can have <strong>2 kinds of dependencies</strong>:</p>
<ul>
<li><strong>Narrow dependencies:</strong> each partition of the parent RDD is used by <em>at most</em> one partition of the child RDD.</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a>[parent RDD partition] <span class="op">--&gt;</span> [child RDD partition]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Fast!</strong> <em>No shuffle</em> necessary. Optimizations like <strong>pipelining</strong> possible.</p>
<p><strong>Transformations with narrow dependencies are fast</strong>.</p>
</section>
<section id="wide-versus-narrow-dependencies-5" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<ul>
<li><strong>Wide dependencies:</strong> each partition of the parent RDD may be used by <em>multiple</em> child partitions</li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource {verbatim} number-lines code-with-copy"><code class="sourceCode"><span id="cb18-1"><a></a>                           ---&gt; [child RDD partition 1]</span>
<span id="cb18-2"><a></a>[parent RDD partition] ---&gt; [child RDD partition 2]</span>
<span id="cb18-3"><a></a>                           ---&gt; [child RDD partition 3]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Slow!</strong> <em>Shuffle necessary</em> for <strong>all</strong> or <strong>some</strong> data over the network.</p>
<p><strong>Transformations with wide dependencies are slow.</strong></p>
</section>
<section id="wide-versus-narrow-dependencies-6" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>

<img src="../../images/narrow_vs_wide_dependencies.png" style="width: 100%;" class="r-stretch"></section>
<section id="wide-versus-narrow-dependencies-7" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<p>Assume that we have a following DAG:</p>
<p><img src="../../images/visual_dag.png" style="width: 55%;">]</p>
</section>
<section id="wide-versus-narrow-dependencies-8" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<p>What do the dependencies look like? Which is <strong>wide</strong> and which is <strong>narrow?</strong></p>

<img src="../../images/visual_dag_resolved.png" style="width: 85%;" class="r-stretch"><ul>
<li>The B to G <code>join</code> is <em>narrow</em> because <code>groupByKey</code> <strong>already partitions</strong> the keys and places them appropriately in B.</li>
<li>Thus, <code>join</code> operations can be <em>narrow or wide</em> depending on <strong>lineage</strong></li>
</ul>
</section>
<section id="wide-versus-narrow-dependencies-9" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<p>Transformations with (usually) <em>narrow</em> dependencies:</p>
<ul>
<li><code>map</code>, <code>mapValues</code>, <code>flatMap</code>, <code>filter</code>, <code>mapPartitions</code>, <code>mapPartitionsWithIndex</code></li>
</ul>
<p>Transformations with (usually) <em>wide</em> dependencies (might cause a <strong>shuffle</strong>):</p>
<ul>
<li><code>cogroup</code>, <code>groupWith</code>, <code>join</code>, <code>leftOuterJoin</code>, <code>rightOuterJoin</code>, <code>groupByKey</code>, <code>reduceByKey</code>, <code>combineByKey</code>, <code>distinct</code>, <code>intersection</code>, <code>repartition</code>, <code>coalesce</code></li>
</ul>
<p>These list are usually correct, but as seen above for <code>join</code>, a correct answer <strong>depends on lineage</strong></p>
</section>
<section id="wide-versus-narrow-dependencies-10" class="slide level2 smaller center">
<h2>Wide versus narrow dependencies</h2>
<p>How do we <strong>find out</strong> if an operation is <strong>wide</strong> or <strong>narrow</strong>?</p>
<ul>
<li><p>Monitor the job with the <em>Spark UI</em> and check if <strong>ShuffleRDD</strong> are used.</p></li>
<li><p>Use the <code>toDebugString</code> method. It prints the <strong>RDD lineage</strong> along with other information relevant to scheduling. Indentations separate <strong>groups of narrow transformations</strong> that may be <strong>pipelined</strong> together with wide transformations that require shuffles. These groupings are called <strong>stages</strong>.</p></li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(pairs.toDebugString().decode(<span class="st">"utf-8"</span>))</span>
<span id="cb19-2"><a></a>(<span class="dv">3</span>) PythonRDD[<span class="dv">157</span>] at RDD at PythonRDD.scala:<span class="dv">53</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb19-3"><a></a> <span class="op">|</span>       CachedPartitions: <span class="dv">3</span><span class="op">;</span> MemorySize: <span class="fl">233.0</span> B<span class="op">;</span> ExternalBlockStoreSize: <span class="fl">0.0</span> B<span class="op">;</span> DiskSize: <span class="fl">0.0</span> B</span>
<span id="cb19-4"><a></a> <span class="op">|</span>  MapPartitionsRDD[<span class="dv">156</span>] at mapPartitions at PythonRDD.scala:<span class="dv">133</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb19-5"><a></a> <span class="op">|</span>  ShuffledRDD[<span class="dv">155</span>] at partitionBy at <span class="op">&lt;</span>unknown<span class="op">&gt;</span>:<span class="dv">0</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb19-6"><a></a> <span class="op">+-</span>(<span class="dv">8</span>) PairwiseRDD[<span class="dv">154</span>] at sortByKey at <span class="op">&lt;</span>ipython<span class="op">-</span><span class="bu">input</span><span class="op">-</span><span class="dv">35</span><span class="op">-</span><span class="dv">112008</span><span class="er">c310ec</span><span class="op">&gt;</span>:<span class="dv">2</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb19-7"><a></a>    <span class="op">|</span>  PythonRDD[<span class="dv">153</span>] at sortByKey at <span class="op">&lt;</span>ipython<span class="op">-</span><span class="bu">input</span><span class="op">-</span><span class="dv">35</span><span class="op">-</span><span class="dv">112008</span><span class="er">c310ec</span><span class="op">&gt;</span>:<span class="dv">2</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span>
<span id="cb19-8"><a></a>    <span class="op">|</span>  ParallelCollectionRDD[<span class="dv">0</span>] at parallelize at PythonRDD.scala:<span class="dv">195</span> [Memory Serialized <span class="dv">1</span><span class="er">x</span> Replicated]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="wide-versus-narrow-dependencies-11" class="slide level2 smaller center">
<h2>Wide versus narrow dependencies</h2>
<ul>
<li>Check the <em>dependencies</em> (only with <code>scala</code> and <code>java</code> APIs): there is a <code>dependencies</code> method on RDDs. It returns a sequence of <code>Dependency</code> objects, which are the dependencies used by <strong>Spark’s scheduler</strong> to know how this RDD <strong>depends on other (or itself) RDDs</strong>.</li>
</ul>
<p>The types of <strong>dependency objects</strong> that this method may return include:</p>
<ul>
<li><strong>Narrow</strong> dependency objects: <code>OneToOneDependency</code>, <code>PruneDependency</code>, <code>RangeDependency</code></li>
<li><strong>Wide</strong> dependency objects: <code>ShuffleDependency</code></li>
</ul>
<p>Example in <code>scala</code>:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode numberSource scala number-lines code-with-copy"><code class="sourceCode scala"><span id="cb20-1"><a></a><span class="kw">val</span> wordsRDD <span class="op">=</span> sc<span class="op">.</span><span class="fu">parallelize</span><span class="op">(</span>largeList<span class="op">)</span></span>
<span id="cb20-2"><a></a><span class="kw">val</span> pairs <span class="op">=</span> wordsRdd<span class="op">.</span><span class="fu">map</span><span class="op">(</span>c<span class="op">=&gt;(</span>c<span class="op">,</span><span class="dv">1</span><span class="op">))</span></span>
<span id="cb20-3"><a></a>                    <span class="op">.</span>groupByKey</span>
<span id="cb20-4"><a></a>                    <span class="op">.</span>dependencies</span>
<span id="cb20-5"><a></a><span class="co">// pairs: Seq[org.apache.spark.Dependency[_]] </span></span>
<span id="cb20-6"><a></a><span class="co">//   = List(org.apache.spark.ShuffleDependency@4294a23d)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="wide-versus-narrow-dependencies-12" class="slide level2 center">
<h2>Wide versus narrow dependencies</h2>
<p>Also, <code>toDebugString</code> is more precise with the <code>scala</code> API:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource scala number-lines code-with-copy"><code class="sourceCode scala"><span id="cb21-1"><a></a><span class="kw">val</span> pairs <span class="op">=</span> wordsRdd<span class="op">.</span><span class="fu">map</span><span class="op">(</span>c<span class="op">=&gt;(</span>c<span class="op">,</span><span class="dv">1</span><span class="op">))</span></span>
<span id="cb21-2"><a></a>                    <span class="op">.</span>groupByKey</span>
<span id="cb21-3"><a></a>                    <span class="op">.</span>toDebugString</span>
<span id="cb21-4"><a></a><span class="co">// pairs: String =</span></span>
<span id="cb21-5"><a></a><span class="co">// (8) ShuffledRDD[219] at groupByKey at &lt;console&gt;:38 []</span></span>
<span id="cb21-6"><a></a><span class="co">//  +-(8) MapPartitionsRDD[218] at map at &lt;console&gt;:37 []</span></span>
<span id="cb21-7"><a></a><span class="co">//     | ParallelCollectionRDD[217] at parallelize at &lt;console&gt;:36 []</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can see immediately that a <code>ShuffledRDD</code> is used</p>
</section></section>
<section>
<section id="lineage-allows-fault-tolerance" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Lineage allows fault tolerance</h1>

</section>
<section id="lineage-allows-fault-tolerance-1" class="slide level2 smaller center">
<h2>Lineage allows fault tolerance</h2>
<p><strong>Lineages</strong> are the key to <em>fault tolerance</em> in Spark</p>
<p>Ideas from <strong>functional programming</strong> enable fault tolerance in Spark:</p>
<ul>
<li>RDDs are <em>immutable</em></li>
<li>Use <strong>higher order functions</strong> like <code>map</code>, <code>flatMap</code>, <code>filter</code> to do <em>functional</em> transformations on this <strong>immutable</strong> data</li>
<li>A function for <strong>computing an RDD based on its parent RDDs</strong> is part the RDD’s representation</li>
</ul>
<p>This is all done in Spark RDDs: a by product of these ideas is <em>fault tolerance</em>:</p>
<ul>
<li>We just need to <strong>keep the information</strong> required by these 3 properties.</li>
<li><strong>Recovering from failures</strong> is simply achieved by <em>recomputing lost partitions</em> using the lineage graph</li>
</ul>
</section>
<section id="lineage-allows-fault-tolerance-2" class="slide level2 smaller center">
<h2>Lineage allows fault tolerance</h2>
<p>Aren’t you amazed by this ?!?</p>
<ul>
<li>Spark provides <strong>fault tolerance</strong> <em>without having to write data on disk!</em></li>
<li>Data can be <strong>rebuilt</strong> using the above information.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<p>If a partition <strong>fails</strong>:</p>
<p><img data-src="../../images/fault_tol_1.png" height="400"></p>
</div><div class="column" style="width:50%;">
<p>Spark <strong>recomputes it</strong> to get back on track:</p>
<p><img data-src="../../images/fault_tol_2.png" height="400"></p>
</div></div>
</section></section>
<section>
<section id="catalyst-the-secret-weapon-of-spark.sql" class="title-slide slide level1 center" data-background-color="#1c191c">
<h1>Catalyst: the secret weapon of <code>spark.sql</code></h1>

</section>
<section id="catalyst-optimizer" class="slide level2 smaller center">
<h2>Catalyst optimizer</h2>
<p>What is the <em>Catalyst</em> <strong>optimizer</strong> ?</p>
<ul>
<li class="fragment"><p>An <strong>optimizer</strong> that <strong>automatically finds</strong> out the <em>most efficient plan</em> to execute data operations specified in the user’s program.</p></li>
<li class="fragment"><p>It <em>translates transformations</em> used to build the dataset to an <strong>optimized physical plan of execution</strong>, which is a DAG of <strong>low-level operations on RDDs</strong>.</p></li>
<li class="fragment"><p>A <em>precious tool</em> for <code>spark.sql</code> in terms of <strong>performance</strong>. It understands the <strong>structure</strong> of the data used and of the <strong>operations</strong> made on it, so the optimizer <em>can make some decisions</em> helping to <strong>reduce execution time</strong>.</p></li>
</ul>
</section>
<section id="catalyst-optimizer-1" class="slide level2 smaller center">
<h2>Catalyst optimizer</h2>
<p>Let’s first define some terminology used in the optimizer</p>
<ul>
<li class="fragment"><p><em>Logical plan</em>: <strong>series of algebraic</strong> or <strong>language constructs</strong>, for example: SELECT, GROUP BY, UNION, etc. Usually <strong>represented as a DAG</strong> where <strong>nodes</strong> are the constructs.</p></li>
<li class="fragment"><p><em>Physical plan</em>: similar to the logical plan, also <strong>represented by a DAG</strong> but concerning <strong>low-level operations</strong> (operations on RDDs).</p></li>
<li class="fragment"><p><em>Unoptimized/optimized plans</em>: a plan becomes <strong>optimized</strong> when the optimizer passed on it and <strong>made some optimizations</strong>, such as merging <code>filter()</code> methods, replacing some instructions by faster another ones, etc.</p></li>
</ul>
<p>Catalyst helps to move from <strong>an unoptimized logical query plan</strong> to an <strong>optimized physical plan</strong></p>
</section>
<section id="catalyst-optimizer-how-it-works" class="slide level2 center">
<h2>Catalyst optimizer: how it works?</h2>

<img src="../../images/catalyst01.png" style="width: 90%;" class="r-stretch"></section>
<section id="catalyst-optimizer-how-it-works-1" class="slide level2 smaller center">
<h2>Catalyst optimizer: how it works?</h2>
<ul>
<li class="fragment"><p>Try to <em>optimize logical plan</em> through <strong>predefined rule-based optimizations</strong>. Some optimizations are:</p>
<ul>
<li class="fragment"><strong>predicate or projection pushdown</strong>, helps to eliminate data not respecting preconditions earlier in the computation;</li>
<li class="fragment"><strong>rearrange filter</strong>;</li>
<li class="fragment"><strong>conversion of decimals operations</strong> to long integer operations;</li>
<li class="fragment"><strong>replacement of some RegEx</strong> expressions by Java’s methods <code>startsWith</code> or <code>contains</code>;</li>
<li class="fragment"><strong>if-else</strong> clauses simplification.</li>
</ul></li>
<li class="fragment"><p>Create the <strong>optimized logical plan</strong>.</p></li>
<li class="fragment"><p>Construct <em>multiple physical plans</em> from the <strong>optimized logical plan</strong>. These are also optimized, some examples are: <strong>merging</strong> different <code>filter()</code>, sending <strong>predicate/projection pushdown</strong> to the <strong>data source</strong> to eliminate data directly from the source.</p></li>
</ul>
</section>
<section id="catalyst-optimizer-how-it-works-2" class="slide level2 smaller center">
<h2>Catalyst optimizer: how it works?</h2>
<ul>
<li class="fragment"><p>Determine <strong>which physical plan</strong> has the <em>lowest cost of execution</em> and choses it as the <strong>physical plan used for the computation</strong>.</p></li>
<li class="fragment"><p>Generate <em>bytecode</em> for the <strong>best physical plan</strong> thanks to a <code>scala</code> feature called <code>quasiquotes</code>.</p></li>
<li class="fragment"><p>Once a physical plan is defined, it’s <em>executed</em> and retrieved data is put to the output DataFrame.</p></li>
</ul>
</section>
<section id="catalyst-optimizer-2" class="slide level2 center">
<h2>Catalyst optimizer</h2>
<p>Let’s understand how Catalyst optimizer works for a given query</p>

<img src="../../images/catalyst02.png" style="width: 80%;" class="r-stretch"></section>
<section id="catalyst-optimizer-3" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst03.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-4" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst04.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-5" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst05.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-6" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst06.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-7" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst07.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-8" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst08.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-9" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst09.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-10" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst10.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-11" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst11.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-12" class="slide level2 center">
<h2>Catalyst optimizer</h2>

<img src="../../images/catalyst12.png" style="width: 100%;" class="r-stretch"></section>
<section id="catalyst-optimizer-13" class="slide level2 center">
<h2>Catalyst optimizer</h2>
<ul>
<li class="fragment"><p>By performing these <strong>transformations</strong>, Catalyst <em>improves the execution times</em> of relational queries and <strong>mitigates the importance of semantics</strong></p></li>
<li class="fragment"><p>Catalyst makes use of some <strong>powerful functional programming</strong> features from <code>Scala</code> to allow developers to concisely specify complex relational optimizations.</p></li>
<li class="fragment"><p>Catalyst helps <em>but only when it can</em>: <strong>explicit</strong> schemas, <strong>precise function calls</strong>, <strong>clever</strong> order of operations <strong>can only help</strong> Catalyst.</p></li>
</ul>
</section></section>
<section id="thank-you" class="title-slide slide level1 unlisted center" data-background-color="#1c191c">
<h1>Thank you!</h1>


<div class="reveal-header">
<div class="header-logo" data-header-logo-link="https://u-paris.fr">
<img data-src="../../images/logo.png">
</div>
<div class="sc-title">
<p> </p>
</div>
<div class="header-text">
<p> </p>
</div>
<div class="sb-title">
<p> </p>
</div>
</div>
</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><a href="http://s-v-b.github.io/IFEBY310">IFEBY030</a> – Technos Big Data – M1 MIDS/MFA/LOGOS – UParis Cité</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: true,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/s-v-b\.github\.io\/IFEBY310\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
                // target, if specified
                link.setAttribute("target", "_blank");
                if (link.getAttribute("rel") === null) {
                  link.setAttribute("rel", "noopener");
                }
                // default icon
                link.classList.add("external");
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
            let selectedAnnoteEl;
            const selectorForAnnotation = ( cell, annotation) => {
              let cellAttr = 'data-code-cell="' + cell + '"';
              let lineAttr = 'data-code-annotation="' +  annotation + '"';
              const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
              return selector;
            }
            const selectCodeLines = (annoteEl) => {
              const doc = window.document;
              const targetCell = annoteEl.getAttribute("data-target-cell");
              const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
              const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
              const lines = annoteSpan.getAttribute("data-code-lines").split(",");
              const lineIds = lines.map((line) => {
                return targetCell + "-" + line;
              })
              let top = null;
              let height = null;
              let parent = null;
              if (lineIds.length > 0) {
                  //compute the position of the single el (top and bottom and make a div)
                  const el = window.document.getElementById(lineIds[0]);
                  top = el.offsetTop;
                  height = el.offsetHeight;
                  parent = el.parentElement.parentElement;
                if (lineIds.length > 1) {
                  const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
                  const bottom = lastEl.offsetTop + lastEl.offsetHeight;
                  height = bottom - top;
                }
                if (top !== null && height !== null && parent !== null) {
                  // cook up a div (if necessary) and position it 
                  let div = window.document.getElementById("code-annotation-line-highlight");
                  if (div === null) {
                    div = window.document.createElement("div");
                    div.setAttribute("id", "code-annotation-line-highlight");
                    div.style.position = 'absolute';
                    parent.appendChild(div);
                  }
                  div.style.top = top - 2 + "px";
                  div.style.height = height + 4 + "px";
                  div.style.left = 0;
                  let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
                  if (gutterDiv === null) {
                    gutterDiv = window.document.createElement("div");
                    gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                    gutterDiv.style.position = 'absolute';
                    const codeCell = window.document.getElementById(targetCell);
                    const gutter = codeCell.querySelector('.code-annotation-gutter');
                    gutter.appendChild(gutterDiv);
                  }
                  gutterDiv.style.top = top - 2 + "px";
                  gutterDiv.style.height = height + 4 + "px";
                }
                selectedAnnoteEl = annoteEl;
              }
            };
            const unselectCodeLines = () => {
              const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
              elementsIds.forEach((elId) => {
                const div = window.document.getElementById(elId);
                if (div) {
                  div.remove();
                }
              });
              selectedAnnoteEl = undefined;
            };
              // Handle positioning of the toggle
          window.addEventListener(
            "resize",
            throttle(() => {
              elRect = undefined;
              if (selectedAnnoteEl) {
                selectCodeLines(selectedAnnoteEl);
              }
            }, 10)
          );
          function throttle(fn, ms) {
          let throttle = false;
          let timer;
            return (...args) => {
              if(!throttle) { // first call gets through
                  fn.apply(this, args);
                  throttle = true;
              } else { // all the others get throttled
                  if(timer) clearTimeout(timer); // cancel #2
                  timer = setTimeout(() => {
                    fn.apply(this, args);
                    timer = throttle = false;
                  }, ms);
              }
            };
          }
            const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
            for (let i=0; i<annoteTargets.length; i++) {
              const annoteTarget = annoteTargets[i];
              const targetCell = annoteTarget.getAttribute("data-target-cell");
              const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
              const contentFn = () => {
                const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
                if (content) {
                  const tipContent = content.cloneNode(true);
                  tipContent.classList.add("code-annotation-tip-content");
                  return tipContent.outerHTML;
                }
              }
              const config = {
                allowHTML: true,
                content: contentFn,
                onShow: (instance) => {
                  selectCodeLines(instance.reference);
                  instance.reference.classList.add('code-annotation-active');
                  window.tippy.hideAll();
                },
                onHide: (instance) => {
                  unselectCodeLines();
                  instance.reference.classList.remove('code-annotation-active');
                },
                maxWidth: 300,
                delay: [50, 0],
                duration: [200, 0],
                offset: [5, 10],
                arrow: true,
                appendTo: function(el) {
                  return el.parentElement.parentElement.parentElement;
                },
                interactive: true,
                interactiveBorder: 10,
                theme: 'light-border',
                placement: 'right',
                popperOptions: {
                  modifiers: [
                  {
                    name: 'flip',
                    options: {
                      flipVariations: false, // true by default
                      allowedAutoPlacements: ['right'],
                      fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                    },
                  },
                  {
                    name: 'preventOverflow',
                    options: {
                      mainAxis: false,
                      altAxis: false
                    }
                  }
                  ]        
                }      
              };
              window.tippy(annoteTarget, config); 
            }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
        <script type="text/javascript">
        (function(d) {
          d.querySelectorAll(".pseudocode-container").forEach(function(el) {
            let pseudocodeOptions = {
              indentSize: el.dataset.indentSize || "1.2em",
              commentDelimiter: el.dataset.commentDelimiter || "//",
              lineNumber: el.dataset.lineNumber === "true" ? true : false,
              lineNumberPunc: el.dataset.lineNumberPunc || ":",
              noEnd: el.dataset.noEnd === "true" ? true : false,
              titlePrefix: el.dataset.captionPrefix || "Algorithm"
            };
            pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
          });
        })(document);
        (function(d) {
          d.querySelectorAll(".pseudocode-container").forEach(function(el) {
            let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
            if (captionSpan !== null) {
              let captionPrefix = el.dataset.captionPrefix + " ";
              let captionNumber = "";
              if (el.dataset.pseudocodeNumber) {
                captionNumber = el.dataset.pseudocodeNumber + " ";
                if (el.dataset.chapterLevel) {
                  captionNumber = el.dataset.chapterLevel + "." + captionNumber;
                }
              }
              captionSpan.innerHTML = captionPrefix + captionNumber;
            }
          });
        })(document);
        </script>
      
    

</body></html>