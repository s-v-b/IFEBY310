{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numpy : broadcasting\\`\n",
        "\n",
        "# Centering and scaling a data matrix\n",
        "\n",
        "In the sequel $X$ is a (data) numerical matrix, that is an element of\n",
        "$\\mathbb{R}^{n \\times p}$. The rows of $X$ (the individuals) are the\n",
        "sample points. Each sample point is a tuple of $p$ elements (the\n",
        "so-called variables).\n",
        "\n",
        "The *sample mean* is defined as $$\n",
        "\\overline{X}= \\begin{pmatrix} \\frac{1}{n}\\sum_{i=1}^n X_{i,j}\\end{pmatrix}_{j\\leq p}\n",
        "$$ In linear algebra, $\\overline{X}$ is the result of vector matrix\n",
        "multiplication: $$\n",
        "\\overline{X} = \\frac{1}{n}\\begin{pmatrix} 1 & \\ldots & 1\\end{pmatrix} \\times X\n",
        "$$ Here, we view $\\overline{X}_n$ as a row vector built from column\n",
        "averages.\n",
        "\n",
        "Centering $X$ consists in subtracting the column average from each\n",
        "matrix element.\n",
        "$$X - \\begin{pmatrix}1 \\\\ \\vdots \\\\ 1\\end{pmatrix} \\times \\overline{X}$$\n",
        "\n",
        "Note that centering consists on projecting the columns of $X$ on the\n",
        "$n-1$ dimensional subspace of $\\mathbb{R}^n$ that is orthogonal to\n",
        "$\\begin{pmatrix} 1 & \\ldots  &  1\\end{pmatrix}^\\top$: Let us call $Y$\n",
        "the matrix obtained from centering the columns of $X$.\n",
        "\n",
        "Scaling $Y$ consists of dividing each coefficient of $Y$ by $1/\\sqrt{n}$\n",
        "times the (Euclidean) norm of its column.\n",
        "\n",
        "Let us call $\\sigma_j$ the Euclidean norm of column $j$ of $Y$\n",
        "($1\\leq j \\leq p$) divided by $1/\\sqrt{n}$: $$\n",
        "\\sigma_j^2 = \\frac{1}{n}\\sum_{i=1}^n Y_{i,j}^2 = \\frac{1}{n} \\sum_{i=1}^n \\left(X_{i,j} - \\overline{X}_j\\right)^2\n",
        "$$ This is also the standard deviation of the $j^{\\text{n}}$ column of\n",
        "$X$.\n",
        "\n",
        "The standardized matrix $Z$ is obtained from the next multiplication $$\n",
        "Z = Y \\times \n",
        "  \\begin{pmatrix} \n",
        "    \\sigma_1 & 0        &  \\ldots      &     & 0 \\\\\n",
        "    0        & \\sigma_2 &   0    &     & \\vdots \\\\\n",
        "    \\vdots   & 0         & \\ddots &     & \\vdots  \\\\\n",
        "    0        & \\ldots   &        &     & \\sigma_d       \n",
        "  \\end{pmatrix}^{-1}\n",
        "$$\n",
        "\n",
        "Note that for $i\\leq n$, $j \\leq p$:\n",
        "$$Z_{i,j} = \\frac{X_{i,j} - \\overline{X}_j}{\\sigma_j}$$\n",
        "\n",
        "$Z$ is called the $z$-score matrix. It shows up in many statistical\n",
        "analyses.\n",
        "\n",
        "In the statistical computing environment `R`, a function called\n",
        "`scale()` computes the $z$-score matrix. On may ask whether NumPy offers\n",
        "such a function.\n",
        "\n",
        "# Scaling in NumPy (standardization)\n",
        "\n",
        "In NumPy, there is no single function equivalent to R’s `scale()`\n",
        "function. However, you can achieve the same result using *broadcasting*."
      ],
      "id": "b4a338e2-81d5-4649-b6e2-10c5b0299b26"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ],
      "id": "3edf3454"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us first generate a toy data matrix with random (Gaussian)\n",
        "coefficients. This is an opportunity to introduce `np.random`.\n",
        "\n",
        "We will work with $n=5$ and $p=3$.\n",
        "\n",
        "We first build a (positive definite) covariance matrix. We ensure\n",
        "positive definiteness starting from the Cholesky factorization."
      ],
      "id": "cf68159d-378b-4d10-834b-4504e16add5a"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "L = np.array([  \n",
        "  [1., 0., 0.], \n",
        "  [.5, 1., 0.], \n",
        "  [.5, .5, 1.]])\n",
        "C = L @ L.transpose()\n",
        "# L is the Cholesky factor of C"
      ],
      "id": "d244d7f8"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a sample of 5 independent normal vectors with mean (1, 2, 3) and covariance C\n",
        "mu = np.array([1, 2, 3])"
      ],
      "id": "85b1c673"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.random.randn(5,3) @ L.transpose() + mu"
      ],
      "id": "af058eab"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In NumPy, function `mean` with well chosen optional `axis` argument\n",
        "returns a 1D array filled with column averages\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> We just did something strange: we added a matrix with shape $(5,3)$\n",
        "> and a vector with length $3$. In linear algebra, this is not\n",
        "> legitimate. We just used the device called *broadcasting*. See below."
      ],
      "id": "19417d61-77b9-47c8-b315-bd8246cbbeb4"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute column averages\n",
        "# That is compute arithmetic mean along axis `0`\n",
        "emp_mean = np.mean(X, axis=0)"
      ],
      "id": "464f9b7b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can magically center the columns using broadcasting."
      ],
      "id": "81f02a60-c8fc-4df9-bc48-3f23b1b4bce7"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_centered = X - emp_mean"
      ],
      "id": "d1c71569"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If broadcasting were note possible, we could still achieve the result by\n",
        "resorting to NumPy implementation of matrix multiplication"
      ],
      "id": "2139e8a3-c9ac-4617-a372-4d4e5ad650f1"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X - np.ones((5,1), dtype=np.float16) @ emp_mean.reshape(1,3)"
      ],
      "id": "f6e7ac3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "is a centered version of `X`:"
      ],
      "id": "eb165047-9894-475b-b45d-0f2fc8526e6c"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_centered - (X - np.ones((5,1), dtype=np.float16) @ emp_mean.reshape(1,3))"
      ],
      "id": "93cb2a3e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute now the column standard deviations using function `np.std`\n",
        "with `axis` argument set to `0`"
      ],
      "id": "fe209948-ab3d-429c-b193-d2152e7cdcc8"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "emp_std = np.std(X, axis=0)"
      ],
      "id": "6557fce6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The $z$-score matrix is obtained using another broadcasting operation."
      ],
      "id": "9194ce21-b504-41a9-97de-5ff56903ccc4"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "Z = (X - emp_mean) / emp_std  # X_centered / emp_std"
      ],
      "id": "81e5b9c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let us perform the sanity checks :"
      ],
      "id": "057c581f-967a-4dbb-8f93-be237fc6d2c5"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "np.mean(Z, axis=0)  # Z is column centered"
      ],
      "id": "4c7e6f84"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.std(Z, axis=0)   # Z is standardized"
      ],
      "id": "5ac57d73"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> Alternatively, we can use `scipy.stats.zscore` which provides R’s\n",
        "> `scale()`-like functionality:\n",
        ">\n",
        "> ``` python\n",
        "> from scipy.stats import zscore\n",
        "> X_scaled_scipy = zscore(X, axis=0)\n",
        "> X_scaled_scipy\n",
        "> ```\n",
        ">\n",
        "> `scipy.stats.zscore` centers and scales the data by default\n",
        "> (equivalent to R’s `scale()` with default arguments).\n",
        ">\n",
        "> Centering and standardization are classical preprocessing steps before\n",
        "> Principal Component Analysis (and before many Machine Learning\n",
        "> procedures).\n",
        "\n",
        "# How does broadcasting work ?\n",
        "\n",
        "## Why broadcasting ? (from the documentation)\n",
        "\n",
        "> The term broadcasting describes how NumPy treats arrays with different\n",
        "> shapes during arithmetic operations. Subject to certain constraints,\n",
        "> the smaller array is “broadcast” across the larger array so that they\n",
        "> have compatible shapes. Broadcasting provides a means of vectorizing\n",
        "> array operations so that looping occurs in C instead of Python. It\n",
        "> does this without making needless copies of data and usually leads to\n",
        "> efficient algorithm implementations. There are, however, cases where\n",
        "> broadcasting is a bad idea because it leads to inefficient use of\n",
        "> memory that slows computation.\n",
        "\n",
        "## How ?\n",
        "\n",
        "> When operating on two arrays, NumPy compares their shapes\n",
        "> element-wise. It starts with the trailing (i.e. rightmost) dimension\n",
        "> and works its way left. Two dimensions are compatible when\n",
        ">\n",
        "> -   they are equal, or\n",
        "> -   one of them is 1.\n",
        "\n",
        "In our setting the shape of `X` and `emp_mean` are `(5,3)` and `(3)`.\n",
        "The rightmost dimensions are equal, hence compatible.\n",
        "\n",
        "> Input arrays do not need to have the same number of dimensions. The\n",
        "> resulting array will have the same number of dimensions as the input\n",
        "> array with the greatest number of dimensions, where the size of each\n",
        "> dimension is the largest size of the corresponding dimension among the\n",
        "> input arrays. Note that missing dimensions are assumed to have size\n",
        "> one.\n",
        "\n",
        "In our setting, `emp_mean` is (virtually) reshaped to `(1,3)` and the\n",
        "two arrays are fully compatible. To match the leading dimension of `X`,\n",
        "we can stack three copies of reshaped `emp_mean`, this is just like\n",
        "multiplying `emp_mean` by `np.array([1.], shape=(3,1))`.\n",
        "\n",
        "> When either of the dimensions compared is one, the other is used. In\n",
        "> other words, dimensions with size 1 are stretched or “copied” to match\n",
        "> the other.\n",
        "\n",
        "# References\n",
        "\n",
        "[Official Numpy\n",
        "documentation](https://numpy.org/devdocs/user/basics.broadcasting.html#basics-broadcasting)"
      ],
      "id": "314d4774-28e0-4416-b401-abf8f2e4f84a"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  }
}