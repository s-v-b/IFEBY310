{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# `DataFrame`"
      ],
      "id": "ceeeaf2c-2411-4374-8161-5e80c7456424"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
      ],
      "id": "cbd0e177"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T20:23:05.867529Z",
          "start_time": "2022-02-08T20:23:01.418071Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "conf = SparkConf().setAppName(\"Spark SQL Course\")\n",
        "sc = SparkContext(conf=conf)  # no need for Spark 3...\n",
        "\n",
        "spark = (SparkSession\n",
        "    .builder\n",
        "    .appName(\"Spark SQL Course\")\n",
        "    .getOrCreate()\n",
        ")"
      ],
      "id": "f4648d7a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:46.926825Z",
          "start_time": "2022-01-26T10:58:46.920913Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "row1 = Row(name=\"John\", age=21)\n",
        "row2 = Row(name=\"James\", age=32)\n",
        "row3 = Row(name=\"Jane\", age=18)\n",
        "row1['name']"
      ],
      "id": "30caf19a"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:57.185741Z",
          "start_time": "2022-01-26T10:58:57.155181Z"
        }
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([row1, row2, row3])"
      ],
      "id": "5e0222c1"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:13.491438Z",
          "start_time": "2022-01-26T10:59:13.486119Z"
        }
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ],
      "id": "bd31d48a"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:17.760344Z",
          "start_time": "2022-01-26T10:59:17.597166Z"
        }
      },
      "outputs": [],
      "source": [
        "df.show()"
      ],
      "id": "78124041"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:25.889372Z",
          "start_time": "2022-01-26T10:59:25.866666Z"
        }
      },
      "outputs": [],
      "source": [
        "print(df.rdd.toDebugString().decode(\"utf-8\"))"
      ],
      "id": "ef6d2d51"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:45.432264Z",
          "start_time": "2022-01-26T10:59:45.426727Z"
        }
      },
      "outputs": [],
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "id": "b510b28c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating dataframes"
      ],
      "id": "c1c5924a-e9cb-41bd-a01d-5d8928037d47"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:18.707591Z",
          "start_time": "2022-01-26T10:58:18.220608Z"
        }
      },
      "outputs": [],
      "source": [
        "rows = [\n",
        "    Row(name=\"John\", age=21, gender=\"male\"),\n",
        "    Row(name=\"James\", age=25, gender=\"female\"),\n",
        "    Row(name=\"Albert\", age=46, gender=\"male\")\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(rows)"
      ],
      "id": "496e0574"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:18.707591Z",
          "start_time": "2022-01-26T10:58:18.220608Z"
        }
      },
      "outputs": [],
      "source": [
        "df.show()"
      ],
      "id": "ad813f64"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(Row)"
      ],
      "id": "84d2527d"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.065539Z",
          "start_time": "2022-01-26T10:58:18.710711Z"
        }
      },
      "outputs": [],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rows = [\n",
        "    [\"John\", 21, \"male\"],\n",
        "    [\"James\", 25, \"female\"],\n",
        "    [\"Albert\", 46, \"male\"]\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(\n",
        "    rows, \n",
        "    column_names\n",
        ")\n",
        "\n",
        "df.show()"
      ],
      "id": "37966e75"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.074335Z",
          "start_time": "2022-01-26T10:58:19.068088Z"
        }
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ],
      "id": "38b861ff"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.840178Z",
          "start_time": "2022-01-26T10:58:19.077057Z"
        }
      },
      "outputs": [],
      "source": [
        "# sc = SparkContext(conf=conf)  # no need for Spark 3...\n",
        "\n",
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rdd = sc.parallelize([\n",
        "    (\"John\", 21, \"male\"),\n",
        "    (\"James\", 25, \"female\"),\n",
        "    (\"Albert\", 46, \"male\")\n",
        "])\n",
        "df = spark.createDataFrame(rdd, column_names)\n",
        "df.show()"
      ],
      "id": "8be726ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schema\n",
        "\n",
        "There is special type schemata. A object of class `StructType` is made\n",
        "of a list of objects of type `StructField`."
      ],
      "id": "f65c17b7-81d6-441c-b8bc-42844bef0f2d"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.850578Z",
          "start_time": "2022-01-26T10:58:19.843835Z"
        }
      },
      "outputs": [],
      "source": [
        "df.schema"
      ],
      "id": "493b8147"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.860631Z",
          "start_time": "2022-01-26T10:58:19.854012Z"
        }
      },
      "outputs": [],
      "source": [
        "type(df.schema)"
      ],
      "id": "de6dd088"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A object of type `StructField` has a name, a PySpark type, an d a\n",
        "boolean parameter."
      ],
      "id": "bee4bb5b-d1ee-4063-b492-6f7e305beaa9"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:20.199419Z",
          "start_time": "2022-01-26T10:58:19.863528Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType(\n",
        "    [\n",
        "        StructField(\"name\", StringType(), True),\n",
        "        StructField(\"age\", IntegerType(), True),\n",
        "        StructField(\"gender\", StringType(), True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "rows = [(\"John\", 21, \"male\")]\n",
        "df = spark.createDataFrame(rows, schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "id": "46b762f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Queries (single table $σ$, $π$)\n",
        "\n",
        "PySpark offers two ways to query a datafrane:\n",
        "\n",
        "-   An ad hod API with methods for the DataFrame class.\n",
        "-   The possibility to post SQL queries (provided a temporary view has\n",
        "    been created)."
      ],
      "id": "93d13cc3-b584-4b03-90cd-aa0aa4b5f50a"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:20.882311Z",
          "start_time": "2022-01-26T10:58:20.201993Z"
        }
      },
      "outputs": [],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rows = [\n",
        "    [\"John\", 21, \"male\"],\n",
        "    [\"Jane\", 25, \"female\"]\n",
        "]\n",
        "# \n",
        "df = spark.createDataFrame(rows, column_names)\n",
        "\n",
        "# Create a temporary view from the DataFrame\n",
        "df.createOrReplaceTempView(\"new_view\")\n",
        "\n",
        "# Apply the query\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, age \n",
        "    FROM \n",
        "        new_view \n",
        "    WHERE \n",
        "        gender='male'\n",
        "\"\"\"\n",
        "\n",
        "men_df = spark.sql(query)\n",
        "men_df.show()"
      ],
      "id": "92020b02"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `SELECT` (projection $π$)"
      ],
      "id": "92f45978-fd80-4499-90e5-c108d73a73b4"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.162623Z",
          "start_time": "2022-01-26T10:58:20.884802Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")    \n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, age \n",
        "    FROM \n",
        "        table\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "22c498dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the API:"
      ],
      "id": "0a2f8a1a-7095-43f9-8b97-4a902ded35b3"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.388097Z",
          "start_time": "2022-01-26T10:58:21.164840Z"
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "        .select(\"name\", \"age\")\n",
        "        .show()\n",
        ")"
      ],
      "id": "97226ab9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`π(df, \"name\", \"age\")`\n",
        "\n",
        "## `WHERE` (filter, selection, $σ$)"
      ],
      "id": "0beab890-70a2-44cd-b07f-6b127473250e"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.704402Z",
          "start_time": "2022-01-26T10:58:21.402155Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table\n",
        "    WHERE \n",
        "        age > 21\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "dd79a639"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the API"
      ],
      "id": "b8f01771-b836-4917-9548-ea024dfb5076"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.924501Z",
          "start_time": "2022-01-26T10:58:21.706741Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "        .where(\"age > 21\")\n",
        "        .show()\n",
        ")"
      ],
      "id": "1ef1d0e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This implements `σ(df, \"age > 21\")`"
      ],
      "id": "699e99fd-dc9b-4732-b37c-86a77cebb908"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:22.377417Z",
          "start_time": "2022-01-26T10:58:21.926708Z"
        }
      },
      "outputs": [],
      "source": [
        "# Alternatively:\n",
        "( \n",
        "    df\n",
        "      .where(df['age'] > 21)\n",
        "      .show()\n",
        ")"
      ],
      "id": "d4e155df"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:22.566385Z",
          "start_time": "2022-01-26T10:58:22.380036Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "      .where(df.age > 21)\n",
        "      .show()\n",
        ")"
      ],
      "id": "e292116a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Method chaining allows to construct complex queries"
      ],
      "id": "8fc0dae4-46ff-4ec2-856a-9869d948ebd5"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:22.837136Z",
          "start_time": "2022-01-26T10:58:22.569324Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "      .where(\"age > 21\")\n",
        "      .select([\"name\", \"age\"])\n",
        "      .show()\n",
        ")"
      ],
      "id": "825292fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This implements\n",
        "\n",
        "        σ(df, \"age > 21\") |>\n",
        "        π([\"name\", \"age\"])\n",
        "\n",
        "## `LIMIT`"
      ],
      "id": "d943036f-69e8-4200-bc0c-4c3ddd1bd564"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:23.315363Z",
          "start_time": "2022-01-26T10:58:22.842106Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table \n",
        "    LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "ead55fb8"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:23.522646Z",
          "start_time": "2022-01-26T10:58:23.318694Z"
        }
      },
      "outputs": [],
      "source": [
        "df.limit(1).show()"
      ],
      "id": "44218937"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:23.778517Z",
          "start_time": "2022-01-26T10:58:23.525281Z"
        }
      },
      "outputs": [],
      "source": [
        "df.select(\"*\").limit(1).show()"
      ],
      "id": "5518cace"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `ORDER BY`"
      ],
      "id": "7407766d-ff73-4f43-a855-afdd93868a19"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.190838Z",
          "start_time": "2022-01-26T10:58:23.781166Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table\n",
        "    ORDER BY \n",
        "        name ASC\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "a83c0535"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.368069Z",
          "start_time": "2022-01-26T10:58:24.193899Z"
        }
      },
      "outputs": [],
      "source": [
        "df.orderBy(df.name.asc()).show()"
      ],
      "id": "c549513d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `ALIAS` (rename)"
      ],
      "id": "ebeada80-fe7b-4506-9c27-01badefe1e45"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.643668Z",
          "start_time": "2022-01-26T10:58:24.370758Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "query = \"SELECT name, age, gender AS sex FROM table\"\n",
        "spark.sql(query).show()"
      ],
      "id": "11d7220b"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(df.age)"
      ],
      "id": "b7c2e72d"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.858104Z",
          "start_time": "2022-01-26T10:58:24.646119Z"
        }
      },
      "outputs": [],
      "source": [
        "df.select(df.name, df.age, df.gender.alias('sex')).show()"
      ],
      "id": "26fc340f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `CAST`"
      ],
      "id": "79c267d2-b880-4b6a-8e27-80599384224d"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.072286Z",
          "start_time": "2022-01-26T10:58:24.860474Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "query = \"SELECT name, cast(age AS float) AS age_f FROM table\"\n",
        "spark.sql(query).show()"
      ],
      "id": "5e6be082"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.384433Z",
          "start_time": "2022-01-26T10:58:25.074523Z"
        }
      },
      "outputs": [],
      "source": [
        "df.select(df.name, df.age.cast(\"float\").alias(\"age_f\")).show()"
      ],
      "id": "bce3a8ad"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.648155Z",
          "start_time": "2022-01-26T10:58:25.386952Z"
        }
      },
      "outputs": [],
      "source": [
        "new_age_col = df.age.cast(\"float\").alias(\"age_f\")\n",
        "type(new_age_col), type(df.age)"
      ],
      "id": "399ded9c"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.select(df.name, new_age_col).show()"
      ],
      "id": "86b79aac"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding new columns"
      ],
      "id": "998527db-8b6c-410e-995a-94c172ad4046"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.931495Z",
          "start_time": "2022-01-26T10:58:25.651283Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        *, \n",
        "        12*age AS age_months \n",
        "    FROM \n",
        "        table\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "467358c1"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:26.195480Z",
          "start_time": "2022-01-26T10:58:25.933620Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "        .withColumn(\"age_months\", df.age * 12)\n",
        "        .show()\n",
        ")"
      ],
      "id": "35b5da02"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:26.422122Z",
          "start_time": "2022-01-26T10:58:26.197759Z"
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "        .select(\"*\", \n",
        "                (df.age * 12).alias(\"age_months\"))\n",
        "        .show()\n",
        ")"
      ],
      "id": "3007aa2b"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "hui = datetime.date.today()\n",
        "\n",
        "hui = hui.replace(year=hui.year-21)\n",
        "\n",
        "str(hui)"
      ],
      "id": "45473f9e"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df.select(\"*\", hui.replace(year=hui.year - df.age ).alias(\"yob\")).show()"
      ],
      "id": "e37b1051"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Column functions\n",
        "\n",
        "## Numeric functions examples"
      ],
      "id": "f2d758e4-bf8b-402a-b1c8-2fec70393f5a"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:26.748718Z",
          "start_time": "2022-01-26T10:58:26.425451Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "columns = [\"brand\", \"cost\"]\n",
        "df = spark.createDataFrame([\n",
        "    (\"garnier\", 3.49),\n",
        "    (\"elseve\", 2.71)\n",
        "], columns)\n",
        "\n",
        "round_cost = fn.round(df.cost, 1)\n",
        "floor_cost = fn.floor(df.cost)\n",
        "ceil_cost = fn.ceil(df.cost)\n",
        "\n",
        "df.withColumn('round', round_cost)\\\n",
        "    .withColumn('floor', floor_cost)\\\n",
        "    .withColumn('ceil', ceil_cost)\\\n",
        "    .show()"
      ],
      "id": "d4435484"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## String functions examples"
      ],
      "id": "5941ca65-44da-437f-a64e-608ae9b1ee13"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.055563Z",
          "start_time": "2022-01-26T10:58:26.751235Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "columns = [\"first_name\", \"last_name\"]\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    (\"John\", \"Doe\"),\n",
        "    (\"Mary\", \"Jane\")\n",
        "], columns)\n",
        "\n",
        "last_name_initial = fn.substring(df.last_name, 0, 1)\n",
        "# last_name_initial_dotted = fn.concat(last_name_initial, \".\")\n",
        "\n",
        "name = fn.concat_ws(\" \", df.first_name, last_name_initial)\n",
        "df.withColumn(\"name\", name).show()"
      ],
      "id": "92392bbe"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    df.selectExpr(\"*\", \"substring(last_name, 0, 1) as lni\")\n",
        "      .selectExpr(\"first_name\", \"last_name\", \"concat(first_name, ' ', lni, '.') as nname\")\n",
        "      .show()\n",
        ")"
      ],
      "id": "da02e5f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Date functions examples"
      ],
      "id": "a0036c6b-5dca-456f-8d9b-0bf92628168e"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.373396Z",
          "start_time": "2022-01-26T10:58:27.057938Z"
        }
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    (date(2015, 1, 1), date(2015, 1, 15)),\n",
        "    (date(2015, 2, 21), date(2015, 3, 8)),\n",
        "], [\"start_date\", \"end_date\"])\n",
        "\n",
        "days_between = fn.datediff(df.end_date, df.start_date)\n",
        "start_month = fn.month(df.start_date)\n",
        "\n",
        "df.withColumn('days_between', days_between)\\\n",
        "    .withColumn('start_month', start_month)\\\n",
        "    .show()"
      ],
      "id": "f6716fc8"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "str(date(2015, 1, 1) - date(2015, 1, 15))"
      ],
      "id": "6863fdd9"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "date(2023, 2 , 14) + timedelta(days=3)"
      ],
      "id": "1438cea4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conditional transformations"
      ],
      "id": "59d5851a-d997-4929-8fcf-a829790bea22"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.630822Z",
          "start_time": "2022-01-26T10:58:27.375855Z"
        }
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([\n",
        "    (\"John\", 21, \"male\"),\n",
        "    (\"Jane\", 25, \"female\"),\n",
        "    (\"Albert\", 46, \"male\"),\n",
        "    (\"Brad\", 49, \"super-hero\")\n",
        "], [\"name\", \"age\", \"gender\"])"
      ],
      "id": "2e102c4d"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.630822Z",
          "start_time": "2022-01-26T10:58:27.375855Z"
        }
      },
      "outputs": [],
      "source": [
        "supervisor = ( \n",
        "    fn.when(df.gender == 'male', 'Mr. Smith')\n",
        "      .when(df.gender == 'female', 'Miss Jones')\n",
        "      .otherwise('NA')\n",
        ")\n",
        "\n",
        "type(supervisor), type(fn.when)"
      ],
      "id": "f28cb60b"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.630822Z",
          "start_time": "2022-01-26T10:58:27.375855Z"
        }
      },
      "outputs": [],
      "source": [
        "df.withColumn(\"supervisor\", supervisor).show()"
      ],
      "id": "88a48b1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User-defined functions"
      ],
      "id": "526b27c3-075f-4903-acbe-858dbbdabba9"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:28.037428Z",
          "start_time": "2022-01-26T10:58:27.633093Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "df = spark.createDataFrame([(1, 3), (4, 2)], [\"first\", \"second\"])\n",
        "\n",
        "def my_func(col_1, col_2):\n",
        "    if (col_1 > col_2):\n",
        "        return \"{} is bigger than {}\".format(col_1, col_2)\n",
        "    else:\n",
        "        return \"{} is bigger than {}\".format(col_2, col_1)\n",
        "\n",
        "my_udf = fn.udf(my_func, StringType())\n",
        "\n",
        "df.withColumn(\"udf\", my_udf(df['first'], df['second'])).show()"
      ],
      "id": "a6b45c39"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Joins ($⋈$)\n",
        "\n",
        "## Using the `spark.sql` API"
      ],
      "id": "cdcdb2bd-c05e-4dc1-b0ab-95bd76ccb12e"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:29.098957Z",
          "start_time": "2022-01-26T10:58:28.042691Z"
        }
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "\n",
        "products = spark.createDataFrame([\n",
        "    ('1', 'mouse', 'microsoft', 39.99),\n",
        "    ('2', 'keyboard', 'logitech', 59.99),\n",
        "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
        "\n",
        "purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '1'),\n",
        "    (date(2017, 11, 5), 1, '2'),\n",
        "], ['date', 'quantity', 'prod_id'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "purchases.join(products, 'prod_id').show()"
      ],
      "id": "b2de603a"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "purchases.join(products, 'prod_id').explain()"
      ],
      "id": "87f081cc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a `SQL` query"
      ],
      "id": "d4559374-c5fa-4dbc-82ae-0d78ab3f39ab"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:29.731271Z",
          "start_time": "2022-01-26T10:58:29.101559Z"
        }
      },
      "outputs": [],
      "source": [
        "products.createOrReplaceTempView(\"products\")\n",
        "purchases.createOrReplaceTempView(\"purchases\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT * \n",
        "    FROM purchases AS prc INNER JOIN \n",
        "        products AS prd \n",
        "    ON prc.prod_id = prd.prod_id\n",
        "\"\"\"\n",
        "spark.sql(query).show()"
      ],
      "id": "663bef4c"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(query).explain()"
      ],
      "id": "c17e033e"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:30.660419Z",
          "start_time": "2022-01-26T10:58:29.734282Z"
        }
      },
      "outputs": [],
      "source": [
        "new_purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '3'),\n",
        "], ['date', 'quantity', 'prod_id_x'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "join_rule = new_purchases.prod_id_x == products.prod_id\n",
        "\n",
        "print(type(join_rule))\n",
        "\n",
        "new_purchases.join(products, join_rule, 'left').show()"
      ],
      "id": "f4a90ff8"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "join_rule.info"
      ],
      "id": "3460465b"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:31.319336Z",
          "start_time": "2022-01-26T10:58:30.663809Z"
        }
      },
      "outputs": [],
      "source": [
        "new_purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '3'),\n",
        "], ['date', 'quantity', 'prod_id_x'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "join_rule = new_purchases.prod_id_x == products.prod_id\n",
        "\n",
        "new_purchases.join(products, join_rule, 'left').show()"
      ],
      "id": "c023d3d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Various types of joins"
      ],
      "id": "1ae69562-92ad-4563-a76d-c0f6e3e7f4ce"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:31.376310Z",
          "start_time": "2022-01-26T10:58:31.323600Z"
        }
      },
      "outputs": [],
      "source": [
        "left = spark.createDataFrame([\n",
        "    (1, \"A1\"), (2, \"A2\"), (3, \"A3\"), (4, \"A4\")], \n",
        "    [\"id\", \"value\"])\n",
        "\n",
        "right = spark.createDataFrame([\n",
        "    (3, \"A3\"), (4, \"A4\"), (4, \"A4_1\"), (5, \"A5\"), (6, \"A6\")], \n",
        "    [\"id\", \"value\"])\n",
        "\n",
        "join_types = [\n",
        "    \"inner\", \"outer\", \"left\", \"right\",\n",
        "    \"leftsemi\", \"leftanti\"\n",
        "]"
      ],
      "id": "63d4fd08"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:34.708236Z",
          "start_time": "2022-01-26T10:58:31.380091Z"
        }
      },
      "outputs": [],
      "source": [
        "for join_type in join_types:\n",
        "    print(join_type)\n",
        "    left.join(right, on=\"id\", how=join_type)\\\n",
        "        .orderBy(\"id\")\\\n",
        "        .show()"
      ],
      "id": "77388f23"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agregations (summarize)\n",
        "\n",
        "## Examples using the API"
      ],
      "id": "c4421d2a-7cce-4e44-a97a-a07593b9ca1d"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:35.398306Z",
          "start_time": "2022-01-26T10:58:34.710552Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "products = spark.createDataFrame([\n",
        "    ('1', 'mouse', 'microsoft', 39.99),\n",
        "    ('2', 'mouse', 'microsoft', 59.99),\n",
        "    ('3', 'keyboard', 'microsoft', 59.99),\n",
        "    ('4', 'keyboard', 'logitech', 59.99),\n",
        "    ('5', 'mouse', 'logitech', 29.99),\n",
        "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
        "\n",
        "( \n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .avg('prod_value')\n",
        "        .show()\n",
        ")"
      ],
      "id": "82e92baf"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:35.782623Z",
          "start_time": "2022-01-26T10:58:35.400724Z"
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .agg(fn.avg('prod_value'))\n",
        "        .show()\n",
        ")"
      ],
      "id": "94b19e5f"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .agg(\n",
        "            fn.mean('prod_value'), \n",
        "            fn.stddev('prod_value')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "c0a34060"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:36.195471Z",
          "start_time": "2022-01-26T10:58:35.784780Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "(\n",
        "    products\n",
        "        .groupBy('prod_brand', 'prod_cat')\\\n",
        "        .agg(\n",
        "            fn.avg('prod_value')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "de0d8dca"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:36.650354Z",
          "start_time": "2022-01-26T10:58:36.207985Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "(\n",
        "    products\n",
        "        .groupBy('prod_brand')\n",
        "        .agg(\n",
        "            fn.round(\n",
        "                fn.avg('prod_value'), 1)\n",
        "                .alias('average'),\n",
        "            fn.ceil(\n",
        "                fn.sum('prod_value'))\n",
        "                .alias('sum'),\n",
        "            fn.min('prod_value')\n",
        "                .alias('min')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "492d1fb6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example using a query"
      ],
      "id": "92c92da6-0822-4db9-afea-522728f19d9b"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:37.089099Z",
          "start_time": "2022-01-26T10:58:36.652842Z"
        }
      },
      "outputs": [],
      "source": [
        "products.createOrReplaceTempView(\"products\")"
      ],
      "id": "d0d6272b"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    prod_brand,\n",
        "    round(avg(prod_value), 1) AS average,\n",
        "    min(prod_value) AS min\n",
        "FROM \n",
        "    products\n",
        "GROUP BY \n",
        "    prod_brand\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "dde1efc3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Window functions\n",
        "\n",
        "## Numerical window functions"
      ],
      "id": "297a0159-c683-40f9-baf2-7e1673684c67"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:37.751296Z",
          "start_time": "2022-01-26T10:58:37.092075Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "# First, we create the Window definition\n",
        "window = Window.partitionBy('prod_brand')\n",
        "\n",
        "print(type(window))"
      ],
      "id": "9c9eeecb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can use `over` to aggregate on this window"
      ],
      "id": "0e398d60-6bb3-4381-a310-3ce99d3d8a0d"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg = fn.avg('prod_value').over(window)\n",
        "\n",
        "# Finally, we can it as a classical column\n",
        "(\n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .show()\n",
        ")"
      ],
      "id": "7cf54f79"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With SQL queries, using multiple windows is not a problem"
      ],
      "id": "0350a86b-686b-452c-9708-2812e8174e5d"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "    SELECT \n",
        "        *, \n",
        "        ROUND(AVG(prod_value) OVER w1, 2)  AS avg_brand_value,\n",
        "        ROUND(AVG(prod_value) OVER w2, 1)  AS avg_prod_value\n",
        "    FROM \n",
        "        products\n",
        "    WINDOW \n",
        "        w1 AS (PARTITION BY prod_brand),\n",
        "        w2 AS (PARTITION BY prod_cat)\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "8944c275"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "window2 = Window.partitionBy('prod_cat')\n",
        "\n",
        "avg2 = fn.avg('prod_value').over(window2)\n",
        "\n",
        "# Finally, we can it as a classical column\n",
        "( \n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .withColumn('avg_prod_value', fn.round(avg2, 1))\n",
        "        .show()\n",
        ")"
      ],
      "id": "ab0ca570"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compare the physical plans associated with the two jobs."
      ],
      "id": "ad37981a-658d-4994-b891-88bab24928e0"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .withColumn('avg_prod_value', fn.round(avg2, 1))\n",
        "        .explain()\n",
        ")"
      ],
      "id": "0f76f692"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(query).explain()"
      ],
      "id": "ad20002a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Windows can be defined on multiple columns"
      ],
      "id": "982badf5-e31d-49c1-aa65-29c1931aa27b"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:38.261379Z",
          "start_time": "2022-01-26T10:58:37.753256Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "window = Window.partitionBy('prod_brand', 'prod_cat')\n",
        "\n",
        "avg = fn.avg('prod_value').over(window)\n",
        "\n",
        "\n",
        "(\n",
        "    products    \n",
        "        .withColumn('avg_value', fn.round(avg, 2))\n",
        "        .show()\n",
        ")"
      ],
      "id": "a8648d83"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lag and Lead"
      ],
      "id": "f4e83a75-0a8e-4342-a953-4c4864fb3548"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:39.785452Z",
          "start_time": "2022-01-26T10:58:39.084502Z"
        }
      },
      "outputs": [],
      "source": [
        "purchases = spark.createDataFrame(\n",
        "    [\n",
        "        (date(2017, 11, 1), 'mouse'),\n",
        "        (date(2017, 11, 2), 'mouse'),\n",
        "        (date(2017, 11, 4), 'keyboard'),\n",
        "        (date(2017, 11, 6), 'keyboard'),\n",
        "        (date(2017, 11, 9), 'keyboard'),\n",
        "        (date(2017, 11, 12), 'mouse'),\n",
        "        (date(2017, 11, 18), 'keyboard')\n",
        "    ], \n",
        "    ['date', 'prod_cat']\n",
        ")\n",
        "\n",
        "purchases.show()\n",
        "\n",
        "window = Window.partitionBy('prod_cat').orderBy('date')\n",
        "\n",
        "prev_purch = fn.lag('date', 1).over(window)\n",
        "next_purch = fn.lead('date', 1).over(window)\n",
        "\n",
        "purchases\\\n",
        "    .withColumn('prev', prev_purch)\\\n",
        "    .withColumn('next', next_purch)\\\n",
        "    .orderBy('prod_cat', 'date')\\\n",
        "    .show()"
      ],
      "id": "2e7fd336"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rank, DenseRank and RowNumber"
      ],
      "id": "f7c296a0-9965-4782-98e1-a446846f09d1"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:40.005845Z",
          "start_time": "2022-01-26T10:58:39.787433Z"
        }
      },
      "outputs": [],
      "source": [
        "contestants = spark.createDataFrame(\n",
        "    [   \n",
        "        ('veterans', 'John', 3000),\n",
        "        ('veterans', 'Bob', 3200),\n",
        "        ('veterans', 'Mary', 4000),\n",
        "        ('young', 'Jane', 4000),\n",
        "        ('young', 'April', 3100),\n",
        "        ('young', 'Alice', 3700),\n",
        "        ('young', 'Micheal', 4000),\n",
        "    ], \n",
        "    ['category', 'name', 'points']\n",
        ")\n",
        "\n",
        "contestants.show()"
      ],
      "id": "c4e0a609"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:40.653650Z",
          "start_time": "2022-01-26T10:58:40.009618Z"
        }
      },
      "outputs": [],
      "source": [
        "window = (\n",
        "    Window\n",
        "        .partitionBy('category')\n",
        "        .orderBy(contestants.points.desc())\n",
        ")\n",
        "\n",
        "rank = fn.rank().over(window)\n",
        "dense_rank = fn.dense_rank().over(window)\n",
        "row_number = fn.row_number().over(window)\n",
        "\n",
        "contestants\\\n",
        "    .withColumn('rank', rank)\\\n",
        "    .withColumn('dense_rank', dense_rank)\\\n",
        "    .withColumn('row_number', row_number)\\\n",
        "    .orderBy('category', fn.col('points').desc())\\\n",
        "    .show()"
      ],
      "id": "829a491e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connection to a database \n",
        "\n",
        "The postgres server runs locally on my laptop, it is equiped with a\n",
        "number of training schemata, including `nycflights` (see\n",
        "<https://s-v-b.github.io/MA15Y030/schemas/schema-nycflights.html>)"
      ],
      "id": "c6abc8f4-6262-41b4-9ad6-f14984a68afa"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_flights = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:postgresql://localhost:5434/bd_2023-24\") \\\n",
        "    .option(\"dbschema\", \"nycflights\")\\\n",
        "    .option(\"dbtable\", \"flights\") \\\n",
        "    .option(\"user\", \"postgres\") \\\n",
        "    .option(\"password\", \"postgres\") \\\n",
        "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
        "    .load()\n",
        "\n",
        "df_flights.printSchema()"
      ],
      "id": "db81b3bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To load the five tables, we avoid cut and paste, and abide to the DRY\n",
        "principle.\n",
        "\n",
        "We package the options in a dictionnary"
      ],
      "id": "3cfaea56-cbac-463a-a18d-5e77301a65f6"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "db_con_settings = {\n",
        "    'url': \"jdbc:postgresql://localhost:5434/bd_2023-24\",\n",
        "    'dbschema':  \"nycflights\",\n",
        "    'user':  \"postgres\",\n",
        "    'password':  \"postgres\",\n",
        "    'driver':  \"org.postgresql.Driver\"\n",
        "}"
      ],
      "id": "3079b009"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We prepare a Python object using dictionnary unpacking."
      ],
      "id": "41cba681-2f36-401f-9037-f40a749673c5"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "o  = spark.read \\\n",
        "    .format(\"jdbc\")\\\n",
        "    .options(**db_con_settings)"
      ],
      "id": "4d6aaf42"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the object to load the different tables in a `for` loop."
      ],
      "id": "cbc14ed3-7093-488a-928d-94bc20f88115"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "tbl_names = ['flights', 'airports', 'airlines', 'planes', 'weather']\n",
        "\n",
        "dic_df = {}\n",
        "\n",
        "for tn in tbl_names:\n",
        "    dic_df[tn] = o.option('dbtable', tn).load()"
      ],
      "id": "79ce7a2f"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k, v in dic_df.items():\n",
        "    v.printSchema()"
      ],
      "id": "247b10d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now query the tables."
      ],
      "id": "c4baf6c1-8e40-440b-b88d-9e08eeac3cd8"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  }
}