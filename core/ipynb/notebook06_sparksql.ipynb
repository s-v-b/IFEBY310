{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# `DataFrame`"
      ],
      "id": "8243ce78-3d21-4fc5-bc48-a5f48d23abfa"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
      ],
      "id": "f287aa5c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "conf = (\n",
        "    SparkConf()\n",
        "        .setAppName(\"Spark SQL Course\")\n",
        ")\n",
        "\n",
        "sc = SparkContext(conf=conf)  # no need for Spark 3...\n",
        "\n",
        "spark = (\n",
        "    SparkSession\n",
        "        .builder\n",
        "        .appName(\"Spark SQL Course\")\n",
        "        .getOrCreate()\n",
        ")"
      ],
      "id": "context_session"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "row1 = Row(name=\"John\", age=21)\n",
        "row2 = Row(name=\"James\", age=32)\n",
        "row3 = Row(name=\"Jane\", age=18)\n",
        "row1['name']"
      ],
      "id": "334c77ef"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:57.185741Z",
            "start_time": "2022-01-26T10:58:57.155181Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([row1, row2, row3])"
      ],
      "id": "32ca8cc8"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:59:13.491438Z",
            "start_time": "2022-01-26T10:59:13.486119Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ],
      "id": "8923a2bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How does `printSchema` compare with Pandas `info()`?"
      ],
      "id": "8fa4802a-fa61-4820-8312-d9066ef15739"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:59:17.760344Z",
            "start_time": "2022-01-26T10:59:17.597166Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.show()"
      ],
      "id": "6f2f8a03"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How does `show` compare with Pandas `head()`"
      ],
      "id": "5183a0ef-0f3a-421b-9062-abc587bcbfa6"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:59:25.889372Z",
            "start_time": "2022-01-26T10:59:25.866666Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "print(df.rdd.toDebugString().decode(\"utf-8\"))"
      ],
      "id": "bd13189c"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:59:45.432264Z",
            "start_time": "2022-01-26T10:59:45.426727Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "id": "5333872b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating dataframes"
      ],
      "id": "dd8888aa-7e5b-458e-87bd-ec2055a9b308"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:18.707591Z",
            "start_time": "2022-01-26T10:58:18.220608Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "rows = [\n",
        "    Row(name=\"John\", age=21, gender=\"male\"),\n",
        "    Row(name=\"James\", age=25, gender=\"female\"),\n",
        "    Row(name=\"Albert\", age=46, gender=\"male\")\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(rows)"
      ],
      "id": "4d9c3a3a"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:18.707591Z",
            "start_time": "2022-01-26T10:58:18.220608Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.show()"
      ],
      "id": "731b0b06"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(Row)"
      ],
      "id": "6a32eb36"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:19.065539Z",
            "start_time": "2022-01-26T10:58:18.710711Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rows = [\n",
        "    [\"John\", 21, \"male\"],\n",
        "    [\"James\", 25, \"female\"],\n",
        "    [\"Albert\", 46, \"male\"]\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(\n",
        "    rows, \n",
        "    column_names\n",
        ")\n",
        "\n",
        "df.show()"
      ],
      "id": "7c79b6f9"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:19.074335Z",
            "start_time": "2022-01-26T10:58:19.068088Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ],
      "id": "ed825ea1"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:19.840178Z",
            "start_time": "2022-01-26T10:58:19.077057Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "# sc = SparkContext(conf=conf)  # no need for Spark 3...\n",
        "\n",
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rdd = sc.parallelize([\n",
        "    (\"John\", 21, \"male\"),\n",
        "    (\"James\", 25, \"female\"),\n",
        "    (\"Albert\", 46, \"male\")\n",
        "])\n",
        "df = spark.createDataFrame(rdd, column_names)\n",
        "df.show()"
      ],
      "id": "4525d9a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schema\n",
        "\n",
        "There is special type schemata. A object of class `StructType` is made\n",
        "of a list of objects of type `StructField`."
      ],
      "id": "49054142-4a08-4cfe-a42e-16f49d507c85"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:19.850578Z",
            "start_time": "2022-01-26T10:58:19.843835Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.schema"
      ],
      "id": "20aa7631"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How does `df.schema` relate to `df.printSchema()`? Where would you use\n",
        "the outputs of `df.schema` and `df.printSchema()`."
      ],
      "id": "35a79339-22db-4f8f-96a6-4dde22af0e79"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:19.860631Z",
            "start_time": "2022-01-26T10:58:19.854012Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "type(df.schema)"
      ],
      "id": "761eb98b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A object of type `StructField` has a *name* like `gender`, a PySpark\n",
        "*type* like `StringType()`, an d a boolean parameter.\n",
        "\n",
        "What does the boolean parameter stand for?"
      ],
      "id": "1ac1edc3-dd9c-485a-8668-f4f416178ff4"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:20.199419Z",
            "start_time": "2022-01-26T10:58:19.863528Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType(\n",
        "    [\n",
        "        StructField(\"name\", StringType(), False),\n",
        "        StructField(\"age\", IntegerType(), True),\n",
        "        StructField(\"gender\", StringType(), True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "rows = [(\"Jane\", 21, \"female\")]\n",
        "df = spark.createDataFrame(rows, schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "id": "2c15d1ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Queries (single table $σ$, $π$)\n",
        "\n",
        "PySpark offers two ways to query a datafrane:\n",
        "\n",
        "-   An ad hoc API with methods for the DataFrame class.\n",
        "-   The possibility to post SQL queries (provided a temporary view has\n",
        "    been created)."
      ],
      "id": "69aefd96-4837-4b4f-8a38-52c529e7c9c5"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:20.882311Z",
            "start_time": "2022-01-26T10:58:20.201993Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rows = [\n",
        "    [\"John\", 21, \"male\"],\n",
        "    [\"Jane\", 25, \"female\"]\n",
        "]\n",
        "# \n",
        "df = spark.createDataFrame(rows, column_names)\n",
        "\n",
        "# Create a temporary view from the DataFrame\n",
        "df.createOrReplaceTempView(\"new_view\")\n",
        "\n",
        "# Apply the query\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, age \n",
        "    FROM \n",
        "        new_view \n",
        "    WHERE \n",
        "        gender='male'\n",
        "\"\"\"\n",
        "\n",
        "men_df = spark.sql(query)\n",
        "men_df.show()"
      ],
      "id": "play-it-like-sql"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **New! (with Spark 4)**\n",
        ">\n",
        "> We can now write SQL queries the way we have been writing in the\n",
        "> `tidyverse` (`R`) using the SQL pipe `|>`."
      ],
      "id": "55e9770c-9a97-4e80-b829-e036054e2cfd"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_age_query = \"\"\"\n",
        "    FROM new_view\n",
        "    |> WHERE gender = 'male'\n",
        "    |> SELECT name, age\n",
        "\"\"\""
      ],
      "id": "play-it-like-dplyr"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to be compared with\n",
        "\n",
        "``` r\n",
        "new_df |> \n",
        "    dplyr::filter(gender=='male') |>\n",
        "    dplyr::select(name, age)\n",
        "```"
      ],
      "id": "c539b2ae-5000-48ad-86a9-7443bd38a4b6"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "men_df = (\n",
        "    spark\n",
        "        .sql(new_age_query)\n",
        "        .show()\n",
        ")"
      ],
      "id": "play-it-like-dplyr-2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Have a look at**\n",
        ">\n",
        "> <https://www.databricks.com/blog/sql-gets-easier-announcing-new-pipe-syntax>\n",
        "\n",
        "## `SELECT` (projection $π$)"
      ],
      "id": "dd2a2e83-c167-4cf8-9b42-fd8b843535b6"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:21.162623Z",
            "start_time": "2022-01-26T10:58:20.884802Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")    \n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, age \n",
        "    FROM \n",
        "        table\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "40f21af8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the API:"
      ],
      "id": "78f263bc-4bf5-4364-9397-124ab7343609"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:21.388097Z",
            "start_time": "2022-01-26T10:58:21.164840Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "        .select(\"name\", \"age\")\n",
        "        .show()\n",
        ")"
      ],
      "id": "f66fa3d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`π(df, \"name\", \"age\")`\n",
        "\n",
        "## `WHERE` (filter, selection, $σ$)"
      ],
      "id": "5ff05cef-8e32-45c3-bf73-cea0300cb666"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:21.704402Z",
            "start_time": "2022-01-26T10:58:21.402155Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table\n",
        "    WHERE \n",
        "        age > 21\n",
        "\"\"\"\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM table \n",
        "    |> WHERE age > 21 \n",
        "    |> SELECT *   \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "df79ae03"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that you can get rid of `|> SELECT *`\n",
        "\n",
        "Using the API"
      ],
      "id": "1576a563-849f-4321-8bb5-07af03cb45a2"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:21.924501Z",
            "start_time": "2022-01-26T10:58:21.706741Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "        .where(\"age > 21\")\n",
        "        .show()\n",
        ")"
      ],
      "id": "5e38c414"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This implements `σ(df, \"age > 21\")`\n",
        "\n",
        "The `where()` method takes different types of inputs as argument:\n",
        "strings that can be interpreted as SQL conditions, but also boolean\n",
        "masks."
      ],
      "id": "bcd52231-4a36-4bb9-a7cf-ed46486fad44"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:22.377417Z",
            "start_time": "2022-01-26T10:58:21.926708Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "# Alternatively:\n",
        "( \n",
        "    df\n",
        "      .where(df['age'] > 21)\n",
        "      .show()\n",
        ")"
      ],
      "id": "868bd4bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or"
      ],
      "id": "8d5352a6-9c89-4756-93b4-7f1555becb0b"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:22.566385Z",
            "start_time": "2022-01-26T10:58:22.380036Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "      .where(df.age > 21)\n",
        "      .show()\n",
        ")"
      ],
      "id": "ad6ce51c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Where (and how) is the boolean mask built?\n",
        "\n",
        "Method chaining allows to construct complex queries"
      ],
      "id": "3986a4fc-3c47-4cc3-a3e7-019a789b53ec"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:22.837136Z",
            "start_time": "2022-01-26T10:58:22.569324Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "      .where(\"age > 21\")\n",
        "      .select([\"name\", \"age\"])\n",
        "      .show()\n",
        ")"
      ],
      "id": "c628eac0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This implements\n",
        "\n",
        "        σ(df, \"age > 21\") |>\n",
        "        π([\"name\", \"age\"])\n",
        "\n",
        "## `LIMIT`"
      ],
      "id": "f605d88a-9d1c-4086-bfe3-812128d4a65b"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:23.315363Z",
            "start_time": "2022-01-26T10:58:22.842106Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table \n",
        "    LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM table\n",
        "    |> LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "baf8066a"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:23.522646Z",
            "start_time": "2022-01-26T10:58:23.318694Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.limit(1).show()"
      ],
      "id": "ccc20711"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:23.778517Z",
            "start_time": "2022-01-26T10:58:23.525281Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.select(\"*\").limit(1).show()"
      ],
      "id": "aec1992b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `ORDER BY`"
      ],
      "id": "8a07f032-d807-487e-867e-19836d647045"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:24.190838Z",
            "start_time": "2022-01-26T10:58:23.781166Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table\n",
        "    ORDER BY \n",
        "        name ASC\n",
        "\"\"\"\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM table\n",
        "    |> ORDER BY name ASC\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "63c7fa46"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the API"
      ],
      "id": "ccf4b65f-c615-429f-aec1-8110981f959e"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:24.368069Z",
            "start_time": "2022-01-26T10:58:24.193899Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.orderBy(df.name.asc()).show()"
      ],
      "id": "af13c46e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `ALIAS` (rename)"
      ],
      "id": "8b2b3276-0431-46c8-80d7-0e0fa3c0df19"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:24.643668Z",
            "start_time": "2022-01-26T10:58:24.370758Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, age, gender  AS sex \n",
        "    FROM \n",
        "        table\n",
        "\"\"\"\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM table\n",
        "    |> SELECT name, age, gender  AS sex\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "63bc4daf"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(df.age)"
      ],
      "id": "4b090d39"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:24.858104Z",
            "start_time": "2022-01-26T10:58:24.646119Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df.select(\n",
        "        df.name, \n",
        "        df.age, \n",
        "        df.gender.alias('sex'))\n",
        "      .show()\n",
        ")"
      ],
      "id": "fc60534d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `CAST`"
      ],
      "id": "fcc06df3-0e55-41e6-86b9-463b159680c8"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:25.072286Z",
            "start_time": "2022-01-26T10:58:24.860474Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, \n",
        "        cast(age AS float) AS age_f \n",
        "    FROM \n",
        "        table\n",
        "\"\"\"\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM table |>  \n",
        "    SELECT \n",
        "        name, \n",
        "        cast(age AS float) AS age_f \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "ce7a6ab0"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:25.384433Z",
            "start_time": "2022-01-26T10:58:25.074523Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "        .select(\n",
        "            df.name, \n",
        "            df.age\n",
        "                .cast(\"float\")\n",
        "                .alias(\"age_f\"))\n",
        "        .show()\n",
        ")"
      ],
      "id": "eeaf07c9"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:25.648155Z",
            "start_time": "2022-01-26T10:58:25.386952Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "new_age_col = df.age.cast(\"float\").alias(\"age_f\")\n",
        "type(new_age_col), type(df.age)"
      ],
      "id": "70519fe7"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.select(df.name, new_age_col).show()"
      ],
      "id": "0fb4118d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding new columns"
      ],
      "id": "1e80d47b-09bc-44e3-b2ad-f521eeeb1c04"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:25.931495Z",
            "start_time": "2022-01-26T10:58:25.651283Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM table |>\n",
        "    SELECT \n",
        "        *, \n",
        "        12*age AS age_months \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "4a3ce15f"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:26.195480Z",
            "start_time": "2022-01-26T10:58:25.933620Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "        .withColumn(\"age_months\", df.age * 12)\n",
        "        .show()\n",
        ")"
      ],
      "id": "5223a072"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:26.422122Z",
            "start_time": "2022-01-26T10:58:26.197759Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "        .select(\"*\", \n",
        "                (df.age * 12).alias(\"age_months\"))\n",
        "        .show()\n",
        ")"
      ],
      "id": "f5524cb2"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "hui = datetime.date.today()\n",
        "\n",
        "str(hui)"
      ],
      "id": "f7096491"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "     .withColumn(\"yob\", datetime.date.today().year - df.age)\n",
        "     .show()\n",
        ")"
      ],
      "id": "e1b25a3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Column functions\n",
        "\n",
        "## Numeric functions examples"
      ],
      "id": "e56427eb-fee6-40df-896d-276beb6db623"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:26.748718Z",
            "start_time": "2022-01-26T10:58:26.425451Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "columns = [\"brand\", \"cost\"]\n",
        "\n",
        "df = spark.createDataFrame(\n",
        "    [(\"garnier\", 3.49),\n",
        "     (\"elseve\", 2.71)], \n",
        "    columns\n",
        ")\n",
        "\n",
        "round_cost = fn.round(df.cost, 1)\n",
        "floor_cost = fn.floor(df.cost)\n",
        "ceil_cost = fn.ceil(df.cost)\n",
        "\n",
        "(\n",
        "    df\n",
        "    .withColumn('round', round_cost)\n",
        "    .withColumn('floor', floor_cost)\n",
        "    .withColumn('ceil', ceil_cost)\n",
        "    .show()\n",
        ")"
      ],
      "id": "9873958e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## String functions examples"
      ],
      "id": "0ce90f50-c03a-4911-9d96-cac412a245f2"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:27.055563Z",
            "start_time": "2022-01-26T10:58:26.751235Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "columns = [\"first_name\", \"last_name\"]\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    (\"John\", \"Doe\"),\n",
        "    (\"Mary\", \"Jane\")\n",
        "], columns)\n",
        "\n",
        "last_name_initial = fn.substring(df.last_name, 0, 1)\n",
        "# last_name_initial_dotted = fn.concat(last_name_initial, \".\")\n",
        "\n",
        "name = fn.concat_ws(\" \", df.first_name, last_name_initial)\n",
        "\n",
        "df.withColumn(\"name\", name).show()"
      ],
      "id": "2d5fc790"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    df.selectExpr(\"*\", \"substring(last_name, 0, 1) as lni\")\n",
        "      .selectExpr(\"first_name\", \"last_name\", \"concat(first_name, ' ', lni, '.') as nname\")\n",
        "      .show()\n",
        ")"
      ],
      "id": "800a4918"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As an SQL query"
      ],
      "id": "1395eeb3-b238-4b70-8aaf-7e4fef841bea"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM table |>\n",
        "    SELECT *, substring(last_name, 0, 1) AS lni |>\n",
        "    SELECT first_name, last_name, concat(first_name, ' ', lni, '.') AS nname\n",
        "\"\"\"\n",
        "spark.sql(query).show()"
      ],
      "id": "8436e8ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Spark SQL offers a large subsets of [SQL\n",
        "functions](https://www.postgresql.org/docs/current/functions.html)\n",
        "\n",
        "## Date functions examples"
      ],
      "id": "0c0bd539-8dc6-4eef-980a-aaae09a228ee"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:27.373396Z",
            "start_time": "2022-01-26T10:58:27.057938Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    (date(2015, 1, 1), date(2015, 1, 15)),\n",
        "    (date(2015, 2, 21), date(2015, 3, 8)),\n",
        "], [\"start_date\", \"end_date\"])\n",
        "\n",
        "days_between = fn.datediff(df.end_date, df.start_date)\n",
        "start_month = fn.month(df.start_date)\n",
        "\n",
        "(\n",
        "    df\n",
        "        .withColumn('days_between', days_between)\n",
        "        .withColumn('start_month', start_month)\n",
        "        .show()\n",
        ")"
      ],
      "id": "6cdada9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that `days_between` is an instance of `Column`, the Spark type for\n",
        "columns in Spark dataframes."
      ],
      "id": "4c2c5372-d578-4e22-9747-ddc7f90cb4e8"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "type(days_between)"
      ],
      "id": "444bb4c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recall the datetime calculus available in Database systems and in many\n",
        "programming framework."
      ],
      "id": "ac8808f1-e63d-4f74-957f-f43ce9acd902"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "str(date(2015, 1, 1) - date(2015, 1, 15))"
      ],
      "id": "ac12e69f"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "date(2023, 2 , 14) + timedelta(days=3)"
      ],
      "id": "8585f659"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conditional transformations"
      ],
      "id": "b22ea759-dc52-4ade-80fc-d4227ed4d0e9"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:27.630822Z",
            "start_time": "2022-01-26T10:58:27.375855Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([\n",
        "    (\"John\", 21, \"male\"),\n",
        "    (\"Jane\", 25, \"female\"),\n",
        "    (\"Albert\", 46, \"male\"),\n",
        "    (\"Brad\", 49, \"super-hero\")\n",
        "], [\"name\", \"age\", \"gender\"])"
      ],
      "id": "dc97abe2"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:27.630822Z",
            "start_time": "2022-01-26T10:58:27.375855Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "supervisor = ( \n",
        "    fn.when(df.gender == 'male', 'Mr. Smith')\n",
        "      .when(df.gender == 'female', 'Miss Jones')\n",
        "      .otherwise('NA')\n",
        ")\n",
        "\n",
        "type(supervisor), type(fn.when)"
      ],
      "id": "828f4c73"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:27.630822Z",
            "start_time": "2022-01-26T10:58:27.375855Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "df.withColumn(\"supervisor\", supervisor).show()"
      ],
      "id": "01cc0603"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User-defined functions"
      ],
      "id": "a7a62333-7fd7-479a-bb19-642afaefc7f6"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:28.037428Z",
            "start_time": "2022-01-26T10:58:27.633093Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "df = spark.createDataFrame([(1, 3), (4, 2)], [\"first\", \"second\"])\n",
        "\n",
        "def my_func(col_1, col_2):\n",
        "    if (col_1 > col_2):\n",
        "        return \"{} is bigger than {}\".format(col_1, col_2)\n",
        "    else:\n",
        "        return \"{} is bigger than {}\".format(col_2, col_1)\n",
        "\n",
        "# registration\n",
        "my_udf = fn.udf(my_func, StringType())\n",
        "\n",
        "# fn.udf is a decorator\n",
        "# it can be used in a a more explicit way\n",
        "\n",
        "@fn.udf(returnType=StringType())\n",
        "def the_same_func(col_1, col_2):\n",
        "    if (col_1 > col_2):\n",
        "        return \"{} is bigger than {}\".format(col_1, col_2)\n",
        "    else:\n",
        "        return \"{} is bigger than {}\".format(col_2, col_1)\n",
        "\n",
        "# at work        \n",
        "(\n",
        "    df\n",
        "        .withColumn(\"udf\", my_udf(df['first'], df['second']))\n",
        "        .withColumn(\"udf_too\", the_same_func(df['first'], df['second']))\n",
        "        .show()\n",
        ")"
      ],
      "id": "3ddcad85"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Using UDF in SQL queries**\n",
        ">\n",
        "> The user-defined-function (UDF) can also be used on SQL queries\n",
        "> provided the decorated function is registered.\n",
        ">\n",
        "> ``` python\n",
        "> df.createOrReplaceTempView(\"table\")\n",
        ">\n",
        "> spark.udf.register(\"the_same_func\", the_same_func)  # the_same_func from @udf above\n",
        "> spark.sql(\"SELECT *, the_same_func(first, second) AS udf FROM table\").show()\n",
        "> ```\n",
        ">\n",
        "> Beware. `spark.udf.register` is not a decorator.\n",
        "\n",
        "> **More on UDF in Spark 4**\n",
        ">\n",
        "> See [User-Defined Table Functions (UDTFs) in\n",
        "> Python](https://docs.databricks.com/gcp/en/udf/python-udtf)\n",
        "\n",
        "# Joins ($⋈$)\n",
        "\n",
        "## Using the `spark.sql` API"
      ],
      "id": "9f596ad4-3f3c-4e3d-9004-7737287e6651"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:29.098957Z",
            "start_time": "2022-01-26T10:58:28.042691Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "\n",
        "products = spark.createDataFrame(\n",
        "    [\n",
        "        ('1', 'mouse', 'microsoft', 39.99),\n",
        "        ('2', 'keyboard', 'logitech', 59.99),\n",
        "    ], \n",
        "    ['prod_id', 'prod_cat', 'prod_brand', 'prod_value']\n",
        ")\n",
        "\n",
        "purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '1'),\n",
        "    (date(2017, 11, 5), 1, '2'),\n",
        "], ['date', 'quantity', 'prod_id'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "purchases.join(products, 'prod_id').show()"
      ],
      "id": "64ded744"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just as in RDBMs, we can ask for explanations:"
      ],
      "id": "e7cf0942-b324-473e-91b8-0e037d28e547"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "purchases.join(products, 'prod_id').explain()"
      ],
      "id": "aa7edeaa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Have a look at the PostgreSQL documentation. What are the different join\n",
        "methods? When is one favored?\n",
        "\n",
        "## Using a `SQL` query"
      ],
      "id": "c60f5597-92a4-4b6f-9ad7-99ce8547c8b8"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:29.731271Z",
            "start_time": "2022-01-26T10:58:29.101559Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "products.createOrReplaceTempView(\"products\")\n",
        "purchases.createOrReplaceTempView(\"purchases\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT * \n",
        "    FROM purchases AS prc INNER JOIN \n",
        "        products AS prd \n",
        "    ON prc.prod_id = prd.prod_id\n",
        "\"\"\"\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM purchases |>\n",
        "    INNER JOIN products USING(prod_id)    \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "d71010d1"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(query).explain()"
      ],
      "id": "03d6fea3"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:30.660419Z",
            "start_time": "2022-01-26T10:58:29.734282Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "new_purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '3'),\n",
        "], ['date', 'quantity', 'prod_id_x'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "join_rule = new_purchases.prod_id_x == products.prod_id\n",
        "\n",
        "print(type(join_rule))\n",
        "\n",
        "new_purchases.join(products, join_rule, 'left').show()"
      ],
      "id": "48382939"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is the type of `join_rule.info`?"
      ],
      "id": "1f118954-fa67-4bf7-8d9c-14e39a72b04d"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "join_rule.info"
      ],
      "id": "9701b8a7"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:31.319336Z",
            "start_time": "2022-01-26T10:58:30.663809Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "new_purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '3'),\n",
        "], ['date', 'quantity', 'prod_id_x'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "join_rule = new_purchases.prod_id_x == products.prod_id\n",
        "\n",
        "new_purchases.join(products, join_rule, 'left').show()"
      ],
      "id": "f48a1dcc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Different kinds of joins**\n",
        ">\n",
        "> Just as in RDBMS, there are different kinds of joins.\n",
        ">\n",
        "> They differ in the way tuples from left and the right tables are\n",
        "> matched (is it a natural join, an equi-join, a $\\theta$ join?). They\n",
        "> also differ in the way they handle non-matching tuples (inner or outer\n",
        "> joins).\n",
        ">\n",
        "> The `join` method has three parameters:\n",
        ">\n",
        "> -   `other`: the right table\n",
        "> -   `on`: the join rule that defines how tuples are matched.\n",
        "> -   `how`: defines the way non-matching tuples are handled.\n",
        "\n",
        "## Various types of joins"
      ],
      "id": "9201dce9-40d1-4dfb-9ca4-eb801a06ec2f"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:31.376310Z",
            "start_time": "2022-01-26T10:58:31.323600Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "left = spark.createDataFrame([\n",
        "    (1, \"A1\"), (2, \"A2\"), (3, \"A3\"), (4, \"A4\")], \n",
        "    [\"id\", \"value\"])\n",
        "\n",
        "right = spark.createDataFrame([\n",
        "    (3, \"A3\"), (4, \"A4\"), (4, \"A4_1\"), (5, \"A5\"), (6, \"A6\")], \n",
        "    [\"id\", \"value\"])\n",
        "\n",
        "join_types = [\n",
        "    \"inner\", \"outer\", \"left\", \"right\",\n",
        "    \"leftsemi\", \"leftanti\"\n",
        "]"
      ],
      "id": "c903c8e8"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:34.708236Z",
            "start_time": "2022-01-26T10:58:31.380091Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "for join_type in join_types:\n",
        "    print(join_type)\n",
        "    left.join(right, on=\"id\", how=join_type)\\\n",
        "        .orderBy(\"id\")\\\n",
        "        .show()"
      ],
      "id": "7fe3ca51"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agregations (summarize)\n",
        "\n",
        "## Examples using the API"
      ],
      "id": "001678eb-139f-4cfe-bad7-ebe5f2fca2ea"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:35.398306Z",
            "start_time": "2022-01-26T10:58:34.710552Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "products = spark.createDataFrame([\n",
        "    ('1', 'mouse', 'microsoft', 39.99),\n",
        "    ('2', 'mouse', 'microsoft', 59.99),\n",
        "    ('3', 'keyboard', 'microsoft', 59.99),\n",
        "    ('4', 'keyboard', 'logitech', 59.99),\n",
        "    ('5', 'mouse', 'logitech', 29.99),\n",
        "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
        "\n",
        "( \n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .avg('prod_value')\n",
        "        .show()\n",
        ")"
      ],
      "id": "55c8b394"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is the type of `products         .groupBy('prod_cat')`?"
      ],
      "id": "b17a47dc-778d-48f5-bb2a-f20918c772d9"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:35.782623Z",
            "start_time": "2022-01-26T10:58:35.400724Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .agg(fn.avg('prod_value'))\n",
        "        .show()\n",
        ")"
      ],
      "id": "e617d4ec"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .agg(\n",
        "            fn.mean('prod_value'), \n",
        "            fn.stddev('prod_value')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "210b9130"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:36.195471Z",
            "start_time": "2022-01-26T10:58:35.784780Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "(\n",
        "    products\n",
        "        .groupBy('prod_brand', 'prod_cat')\\\n",
        "        .agg(\n",
        "            fn.avg('prod_value')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "f25d2930"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:36.650354Z",
            "start_time": "2022-01-26T10:58:36.207985Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "(\n",
        "    products\n",
        "        .groupBy('prod_brand')\n",
        "        .agg(\n",
        "            fn.round(\n",
        "                fn.avg('prod_value'), 1)\n",
        "                .alias('average'),\n",
        "            fn.ceil(\n",
        "                fn.sum('prod_value'))\n",
        "                .alias('sum'),\n",
        "            fn.min('prod_value')\n",
        "                .alias('min')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "27a34c4a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example using a query"
      ],
      "id": "d7ab9a16-70ac-44be-84bf-44e93978187b"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:37.089099Z",
            "start_time": "2022-01-26T10:58:36.652842Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "products.createOrReplaceTempView(\"products\")"
      ],
      "id": "7388a6ef"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    prod_brand,\n",
        "    round(avg(prod_value), 1) AS average,\n",
        "    min(prod_value) AS min\n",
        "FROM \n",
        "    products\n",
        "GROUP BY \n",
        "    prod_brand\n",
        "\"\"\"\n",
        "\n",
        "query = \"\"\"\n",
        "    FROM products \n",
        "    |> AGGREGATE \n",
        "        round(avg(prod_value), 1) AS average,\n",
        "        min(prod_value) AS min GROUP BY prod_brand \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "3aec11e6"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(query).explain()"
      ],
      "id": "c9ff06cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Window functions\n",
        "\n",
        "## Numerical window functions"
      ],
      "id": "6a8e49d1-49c8-4442-a730-dcc5ba27b3b4"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:37.751296Z",
            "start_time": "2022-01-26T10:58:37.092075Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "# First, we create the Window definition\n",
        "window = Window.partitionBy('prod_brand')\n",
        "\n",
        "print(type(window))"
      ],
      "id": "a4b0ae0d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can use `over` to aggregate on this window"
      ],
      "id": "b22e6550-e62c-4afe-8e38-2a814b183a86"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg = fn.avg('prod_value').over(window)\n",
        "\n",
        "# Finally, we can it as a classical column\n",
        "(\n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .show()\n",
        ")"
      ],
      "id": "eb865255"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With SQL queries, using windows ?"
      ],
      "id": "1b93ddef-c07f-4bc3-b7b8-5a79d36197d1"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "    SELECT \n",
        "        *, \n",
        "        ROUND(AVG(prod_value) OVER w1, 2)  AS avg_brand_value,\n",
        "        ROUND(AVG(prod_value) OVER w2, 1)  AS avg_prod_value\n",
        "    FROM \n",
        "        products\n",
        "    WINDOW \n",
        "        w1 AS (PARTITION BY prod_brand),\n",
        "        w2 AS (PARTITION BY prod_cat)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "query2 = \"\"\"\n",
        "    FROM products |>\n",
        "    SELECT\n",
        "        *,  \n",
        "        ROUND(AVG(prod_value) OVER w1, 2)  AS avg_brand_value,\n",
        "        ROUND(AVG(prod_value) OVER w2, 1)  AS avg_prod_value\n",
        "        WINDOW \n",
        "            w1 AS (PARTITION BY prod_brand),\n",
        "            w2 AS (PARTITION BY prod_cat)\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query2).show()"
      ],
      "id": "664e4ab9"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "window2 = Window.partitionBy('prod_cat')\n",
        "\n",
        "avg2 = fn.avg('prod_value').over(window2)\n",
        "\n",
        "# Finally, we can do it as a classical column\n",
        "( \n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .withColumn('avg_prod_value', fn.round(avg2, 1))\n",
        "        .show()\n",
        ")"
      ],
      "id": "873cf35e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compare the physical plans associated with the two jobs."
      ],
      "id": "d58424db-f26a-4c60-89b5-30cf4f6766c0"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .withColumn('avg_prod_value', fn.round(avg2, 1))\n",
        "        .explain()\n",
        ")"
      ],
      "id": "752bc858"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(query).explain()"
      ],
      "id": "1eb87038"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Windows can be defined on multiple columns"
      ],
      "id": "411300aa-14b6-45bb-a4aa-35db30f45bf2"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:38.261379Z",
            "start_time": "2022-01-26T10:58:37.753256Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "window = Window.partitionBy('prod_brand', 'prod_cat')\n",
        "\n",
        "avg = fn.avg('prod_value').over(window)\n",
        "\n",
        "\n",
        "(\n",
        "    products    \n",
        "        .withColumn('avg_value', fn.round(avg, 2))\n",
        "        .show()\n",
        ")"
      ],
      "id": "2e7100cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lag and Lead"
      ],
      "id": "c15c20a0-45ff-44f4-b82f-02586005c56b"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:39.785452Z",
            "start_time": "2022-01-26T10:58:39.084502Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "purchases = spark.createDataFrame(\n",
        "    [\n",
        "        (date(2017, 11, 1), 'mouse'),\n",
        "        (date(2017, 11, 2), 'mouse'),\n",
        "        (date(2017, 11, 4), 'keyboard'),\n",
        "        (date(2017, 11, 6), 'keyboard'),\n",
        "        (date(2017, 11, 9), 'keyboard'),\n",
        "        (date(2017, 11, 12), 'mouse'),\n",
        "        (date(2017, 11, 18), 'keyboard')\n",
        "    ], \n",
        "    ['date', 'prod_cat']\n",
        ")\n",
        "\n",
        "purchases.show()\n",
        "\n",
        "window = Window.partitionBy('prod_cat').orderBy('date')\n",
        "\n",
        "prev_purch = fn.lag('date', 1).over(window)\n",
        "next_purch = fn.lead('date', 1).over(window)\n",
        "\n",
        "purchases\\\n",
        "    .withColumn('prev', prev_purch)\\\n",
        "    .withColumn('next', next_purch)\\\n",
        "    .orderBy('prod_cat', 'date')\\\n",
        "    .show()"
      ],
      "id": "aef4c356"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rank, DenseRank and RowNumber"
      ],
      "id": "7e4e2fee-61ea-40d7-aa33-437cdb2f12f9"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:40.005845Z",
            "start_time": "2022-01-26T10:58:39.787433Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "contestants = spark.createDataFrame(\n",
        "    [   \n",
        "        ('veterans', 'John', 3000),\n",
        "        ('veterans', 'Bob', 3200),\n",
        "        ('veterans', 'Mary', 4000),\n",
        "        ('young', 'Jane', 4000),\n",
        "        ('young', 'April', 3100),\n",
        "        ('young', 'Alice', 3700),\n",
        "        ('young', 'Micheal', 4000),\n",
        "    ], \n",
        "    ['category', 'name', 'points']\n",
        ")\n",
        "\n",
        "contestants.show()"
      ],
      "id": "644eaa34"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2022-01-26T10:58:40.653650Z",
            "start_time": "2022-01-26T10:58:40.009618Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "window = (\n",
        "    Window\n",
        "        .partitionBy('category')\n",
        "        .orderBy(contestants.points.desc())\n",
        ")\n",
        "\n",
        "rank = fn.rank().over(window)\n",
        "dense_rank = fn.dense_rank().over(window)\n",
        "row_number = fn.row_number().over(window)\n",
        "\n",
        "(\n",
        "contestants\n",
        "    .withColumn('rank', rank)\n",
        "    .withColumn('dense_rank', dense_rank)\n",
        "    .withColumn('row_number', row_number)\n",
        "    .orderBy('category', fn.col('points').desc())\n",
        "    .show()\n",
        ")"
      ],
      "id": "7b38ce94"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  }
}