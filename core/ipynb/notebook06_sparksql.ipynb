{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# `DataFrame`"
      ],
      "id": "0c143403-0db5-4359-bcc4-ea82a6df70fd"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
      ],
      "id": "b7a22293"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T20:23:05.867529Z",
          "start_time": "2022-02-08T20:23:01.418071Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "conf = SparkConf().setAppName(\"Spark SQL Course\")\n",
        "sc = SparkContext(conf=conf)  # no need for Spark 3...\n",
        "\n",
        "spark = (SparkSession\n",
        "    .builder\n",
        "    .appName(\"Spark SQL Course\")\n",
        "    .getOrCreate()\n",
        ")"
      ],
      "id": "789ed89a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:46.926825Z",
          "start_time": "2022-01-26T10:58:46.920913Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "row1 = Row(name=\"John\", age=21)\n",
        "row2 = Row(name=\"James\", age=32)\n",
        "row3 = Row(name=\"Jane\", age=18)\n",
        "row1['name']"
      ],
      "id": "fabc53d8"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:57.185741Z",
          "start_time": "2022-01-26T10:58:57.155181Z"
        }
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([row1, row2, row3])"
      ],
      "id": "a5249d32"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:13.491438Z",
          "start_time": "2022-01-26T10:59:13.486119Z"
        }
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ],
      "id": "805d833f"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:17.760344Z",
          "start_time": "2022-01-26T10:59:17.597166Z"
        }
      },
      "outputs": [],
      "source": [
        "df.show()"
      ],
      "id": "874874ab"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:25.889372Z",
          "start_time": "2022-01-26T10:59:25.866666Z"
        }
      },
      "outputs": [],
      "source": [
        "print(df.rdd.toDebugString().decode(\"utf-8\"))"
      ],
      "id": "083c342a"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:59:45.432264Z",
          "start_time": "2022-01-26T10:59:45.426727Z"
        }
      },
      "outputs": [],
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "id": "4c664b20"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating dataframes"
      ],
      "id": "3b4252a5-de08-4f89-b1eb-84e61cc3b898"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:18.707591Z",
          "start_time": "2022-01-26T10:58:18.220608Z"
        }
      },
      "outputs": [],
      "source": [
        "rows = [\n",
        "    Row(name=\"John\", age=21, gender=\"male\"),\n",
        "    Row(name=\"James\", age=25, gender=\"female\"),\n",
        "    Row(name=\"Albert\", age=46, gender=\"male\")\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(rows)"
      ],
      "id": "c88b4181"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:18.707591Z",
          "start_time": "2022-01-26T10:58:18.220608Z"
        }
      },
      "outputs": [],
      "source": [
        "df.show()"
      ],
      "id": "03e252e0"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(Row)"
      ],
      "id": "f9ecf6b1"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.065539Z",
          "start_time": "2022-01-26T10:58:18.710711Z"
        }
      },
      "outputs": [],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rows = [\n",
        "    [\"John\", 21, \"male\"],\n",
        "    [\"James\", 25, \"female\"],\n",
        "    [\"Albert\", 46, \"male\"]\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(\n",
        "    rows, \n",
        "    column_names\n",
        ")\n",
        "\n",
        "df.show()"
      ],
      "id": "6eaa661d"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.074335Z",
          "start_time": "2022-01-26T10:58:19.068088Z"
        }
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ],
      "id": "455f1789"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.840178Z",
          "start_time": "2022-01-26T10:58:19.077057Z"
        }
      },
      "outputs": [],
      "source": [
        "# sc = SparkContext(conf=conf)  # no need for Spark 3...\n",
        "\n",
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rdd = sc.parallelize([\n",
        "    (\"John\", 21, \"male\"),\n",
        "    (\"James\", 25, \"female\"),\n",
        "    (\"Albert\", 46, \"male\")\n",
        "])\n",
        "df = spark.createDataFrame(rdd, column_names)\n",
        "df.show()"
      ],
      "id": "05467002"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schema\n",
        "\n",
        "There is special type schemata. A object of class `StructType` is made\n",
        "of a list of objects of type `StructField`."
      ],
      "id": "660a968b-e7dc-46c6-81db-79a28ad943e9"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.850578Z",
          "start_time": "2022-01-26T10:58:19.843835Z"
        }
      },
      "outputs": [],
      "source": [
        "df.schema"
      ],
      "id": "c4a47429"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:19.860631Z",
          "start_time": "2022-01-26T10:58:19.854012Z"
        }
      },
      "outputs": [],
      "source": [
        "type(df.schema)"
      ],
      "id": "9ff8edaa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A object of type `StructField` has a name, a PySpark type, an d a\n",
        "boolean parameter."
      ],
      "id": "284b5ec8-866d-441c-b93b-3680dc30ddbb"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:20.199419Z",
          "start_time": "2022-01-26T10:58:19.863528Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType(\n",
        "    [\n",
        "        StructField(\"name\", StringType(), True),\n",
        "        StructField(\"age\", IntegerType(), True),\n",
        "        StructField(\"gender\", StringType(), True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "rows = [(\"John\", 21, \"male\")]\n",
        "df = spark.createDataFrame(rows, schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "id": "3541a166"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Queries (single table $σ$, $π$)\n",
        "\n",
        "PySpark offers two ways to query a datafrane:\n",
        "\n",
        "-   An ad hod API with methods for the DataFrame class.\n",
        "-   The possibility to post SQL queries (provided a temporary view has\n",
        "    been created)."
      ],
      "id": "94ce209e-9621-4881-bf37-26ed351e4305"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:20.882311Z",
          "start_time": "2022-01-26T10:58:20.201993Z"
        }
      },
      "outputs": [],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rows = [\n",
        "    [\"John\", 21, \"male\"],\n",
        "    [\"Jane\", 25, \"female\"]\n",
        "]\n",
        "# \n",
        "df = spark.createDataFrame(rows, column_names)\n",
        "\n",
        "# Create a temporary view from the DataFrame\n",
        "df.createOrReplaceTempView(\"new_view\")\n",
        "\n",
        "# Apply the query\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, age \n",
        "    FROM \n",
        "        new_view \n",
        "    WHERE \n",
        "        gender='male'\n",
        "\"\"\"\n",
        "\n",
        "men_df = spark.sql(query)\n",
        "men_df.show()"
      ],
      "id": "f8b4ad8f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `SELECT` (projection $π$)"
      ],
      "id": "18958abb-f67b-4012-b3f6-9ed1922cfde9"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.162623Z",
          "start_time": "2022-01-26T10:58:20.884802Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")    \n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        name, age \n",
        "    FROM \n",
        "        table\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "a9717757"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the API:"
      ],
      "id": "be1c6e0a-e0fb-400e-be85-14b01445630c"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.388097Z",
          "start_time": "2022-01-26T10:58:21.164840Z"
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "        .select(\"name\", \"age\")\n",
        "        .show()\n",
        ")"
      ],
      "id": "3f673b88"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`π(df, \"name\", \"age\")`\n",
        "\n",
        "## `WHERE` (filter, selection, $σ$)"
      ],
      "id": "9d07f5a6-a2ac-4123-a65a-6524b650a24e"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.704402Z",
          "start_time": "2022-01-26T10:58:21.402155Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table\n",
        "    WHERE \n",
        "        age > 21\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "dda446ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the API"
      ],
      "id": "fea1f133-5732-4a99-81f8-1c43fabe898d"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:21.924501Z",
          "start_time": "2022-01-26T10:58:21.706741Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "        .where(\"age > 21\")\n",
        "        .show()\n",
        ")"
      ],
      "id": "4e798d24"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This implements `σ(df, \"age > 21\")`"
      ],
      "id": "15a7e2d4-236a-412e-97bd-29a01d736cbf"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:22.377417Z",
          "start_time": "2022-01-26T10:58:21.926708Z"
        }
      },
      "outputs": [],
      "source": [
        "# Alternatively:\n",
        "( \n",
        "    df\n",
        "      .where(df['age'] > 21)\n",
        "      .show()\n",
        ")"
      ],
      "id": "98ed637b"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:22.566385Z",
          "start_time": "2022-01-26T10:58:22.380036Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "      .where(df.age > 21)\n",
        "      .show()\n",
        ")"
      ],
      "id": "b8b66dd7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Method chaining allows to construct complex queries"
      ],
      "id": "e5ade489-09a7-4154-b48a-650c62be1f3c"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:22.837136Z",
          "start_time": "2022-01-26T10:58:22.569324Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "      .where(\"age > 21\")\n",
        "      .select([\"name\", \"age\"])\n",
        "      .show()\n",
        ")"
      ],
      "id": "3655fce9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This implements\n",
        "\n",
        "        σ(df, \"age > 21\") |>\n",
        "        π([\"name\", \"age\"])\n",
        "\n",
        "## `LIMIT`"
      ],
      "id": "9facf5b8-abab-4d5d-ab6b-7e4e1726a9bc"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:23.315363Z",
          "start_time": "2022-01-26T10:58:22.842106Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table \n",
        "    LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "c3cefdd2"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:23.522646Z",
          "start_time": "2022-01-26T10:58:23.318694Z"
        }
      },
      "outputs": [],
      "source": [
        "df.limit(1).show()"
      ],
      "id": "171b220f"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:23.778517Z",
          "start_time": "2022-01-26T10:58:23.525281Z"
        }
      },
      "outputs": [],
      "source": [
        "df.select(\"*\").limit(1).show()"
      ],
      "id": "17b460e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `ORDER BY`"
      ],
      "id": "50714e36-b17e-4061-aa8f-91870cae8853"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.190838Z",
          "start_time": "2022-01-26T10:58:23.781166Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        * \n",
        "    FROM \n",
        "        table\n",
        "    ORDER BY \n",
        "        name ASC\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "4a1d1357"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.368069Z",
          "start_time": "2022-01-26T10:58:24.193899Z"
        }
      },
      "outputs": [],
      "source": [
        "df.orderBy(df.name.asc()).show()"
      ],
      "id": "4194d906"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `ALIAS` (rename)"
      ],
      "id": "9b282a4c-779a-4f9e-8ec6-6f2b58eadcc9"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.643668Z",
          "start_time": "2022-01-26T10:58:24.370758Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "query = \"SELECT name, age, gender AS sex FROM table\"\n",
        "spark.sql(query).show()"
      ],
      "id": "3850b984"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(df.age)"
      ],
      "id": "854a2035"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:24.858104Z",
          "start_time": "2022-01-26T10:58:24.646119Z"
        }
      },
      "outputs": [],
      "source": [
        "df.select(df.name, df.age, df.gender.alias('sex')).show()"
      ],
      "id": "603b7fdb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `CAST`"
      ],
      "id": "23254048-8413-42ea-a83d-c67654dde5aa"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.072286Z",
          "start_time": "2022-01-26T10:58:24.860474Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "query = \"SELECT name, cast(age AS float) AS age_f FROM table\"\n",
        "spark.sql(query).show()"
      ],
      "id": "3a76db4e"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.384433Z",
          "start_time": "2022-01-26T10:58:25.074523Z"
        }
      },
      "outputs": [],
      "source": [
        "df.select(df.name, df.age.cast(\"float\").alias(\"age_f\")).show()"
      ],
      "id": "9bcf254c"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.648155Z",
          "start_time": "2022-01-26T10:58:25.386952Z"
        }
      },
      "outputs": [],
      "source": [
        "new_age_col = df.age.cast(\"float\").alias(\"age_f\")\n",
        "type(new_age_col), type(df.age)"
      ],
      "id": "237c4a3a"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.select(df.name, new_age_col).show()"
      ],
      "id": "d0cb7109"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding new columns"
      ],
      "id": "40082daa-582d-4a63-a465-18c48e54567c"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:25.931495Z",
          "start_time": "2022-01-26T10:58:25.651283Z"
        }
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"table\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT \n",
        "        *, \n",
        "        12*age AS age_months \n",
        "    FROM \n",
        "        table\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "7af70684"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:26.195480Z",
          "start_time": "2022-01-26T10:58:25.933620Z"
        }
      },
      "outputs": [],
      "source": [
        "( \n",
        "    df\n",
        "        .withColumn(\"age_months\", df.age * 12)\n",
        "        .show()\n",
        ")"
      ],
      "id": "59e8e534"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:26.422122Z",
          "start_time": "2022-01-26T10:58:26.197759Z"
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df\n",
        "        .select(\"*\", \n",
        "                (df.age * 12).alias(\"age_months\"))\n",
        "        .show()\n",
        ")"
      ],
      "id": "a156c151"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "hui = datetime.date.today()\n",
        "\n",
        "hui = hui.replace(year=hui.year-21)\n",
        "\n",
        "str(hui)"
      ],
      "id": "6d0db54a"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df.select(\"*\", hui.replace(year=hui.year - df.age ).alias(\"yob\")).show()"
      ],
      "id": "0f6eef2e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Column functions\n",
        "\n",
        "## Numeric functions examples"
      ],
      "id": "af5e9fab-0f91-4cfd-9926-126b76a04e9e"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:26.748718Z",
          "start_time": "2022-01-26T10:58:26.425451Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "columns = [\"brand\", \"cost\"]\n",
        "df = spark.createDataFrame([\n",
        "    (\"garnier\", 3.49),\n",
        "    (\"elseve\", 2.71)\n",
        "], columns)\n",
        "\n",
        "round_cost = fn.round(df.cost, 1)\n",
        "floor_cost = fn.floor(df.cost)\n",
        "ceil_cost = fn.ceil(df.cost)\n",
        "\n",
        "df.withColumn('round', round_cost)\\\n",
        "    .withColumn('floor', floor_cost)\\\n",
        "    .withColumn('ceil', ceil_cost)\\\n",
        "    .show()"
      ],
      "id": "a79ea2b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## String functions examples"
      ],
      "id": "1c361a03-267a-42eb-b736-e4ac8a0404e0"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.055563Z",
          "start_time": "2022-01-26T10:58:26.751235Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "columns = [\"first_name\", \"last_name\"]\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    (\"John\", \"Doe\"),\n",
        "    (\"Mary\", \"Jane\")\n",
        "], columns)\n",
        "\n",
        "last_name_initial = fn.substring(df.last_name, 0, 1)\n",
        "# last_name_initial_dotted = fn.concat(last_name_initial, \".\")\n",
        "\n",
        "name = fn.concat_ws(\" \", df.first_name, last_name_initial)\n",
        "df.withColumn(\"name\", name).show()"
      ],
      "id": "1cd8dbea"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    df.selectExpr(\"*\", \"substring(last_name, 0, 1) as lni\")\n",
        "      .selectExpr(\"first_name\", \"last_name\", \"concat(first_name, ' ', lni, '.') as nname\")\n",
        "      .show()\n",
        ")"
      ],
      "id": "e6a6311f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Date functions examples"
      ],
      "id": "5574c3d7-d63e-4be7-870c-03ff60d4e5b4"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.373396Z",
          "start_time": "2022-01-26T10:58:27.057938Z"
        }
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    (date(2015, 1, 1), date(2015, 1, 15)),\n",
        "    (date(2015, 2, 21), date(2015, 3, 8)),\n",
        "], [\"start_date\", \"end_date\"])\n",
        "\n",
        "days_between = fn.datediff(df.end_date, df.start_date)\n",
        "start_month = fn.month(df.start_date)\n",
        "\n",
        "df.withColumn('days_between', days_between)\\\n",
        "    .withColumn('start_month', start_month)\\\n",
        "    .show()"
      ],
      "id": "2f8995f0"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "str(date(2015, 1, 1) - date(2015, 1, 15))"
      ],
      "id": "327f9eb8"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "date(2023, 2 , 14) + timedelta(days=3)"
      ],
      "id": "8537c43a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conditional transformations"
      ],
      "id": "fc72ba4d-8e30-47de-b45d-e77246d71b4f"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.630822Z",
          "start_time": "2022-01-26T10:58:27.375855Z"
        }
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([\n",
        "    (\"John\", 21, \"male\"),\n",
        "    (\"Jane\", 25, \"female\"),\n",
        "    (\"Albert\", 46, \"male\"),\n",
        "    (\"Brad\", 49, \"super-hero\")\n",
        "], [\"name\", \"age\", \"gender\"])"
      ],
      "id": "92fd87b8"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.630822Z",
          "start_time": "2022-01-26T10:58:27.375855Z"
        }
      },
      "outputs": [],
      "source": [
        "supervisor = ( \n",
        "    fn.when(df.gender == 'male', 'Mr. Smith')\n",
        "      .when(df.gender == 'female', 'Miss Jones')\n",
        "      .otherwise('NA')\n",
        ")\n",
        "\n",
        "type(supervisor), type(fn.when)"
      ],
      "id": "8488cc17"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:27.630822Z",
          "start_time": "2022-01-26T10:58:27.375855Z"
        }
      },
      "outputs": [],
      "source": [
        "df.withColumn(\"supervisor\", supervisor).show()"
      ],
      "id": "7f618144"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User-defined functions"
      ],
      "id": "0e6d49ac-49fd-495c-bef4-71a5a599b52f"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:28.037428Z",
          "start_time": "2022-01-26T10:58:27.633093Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "df = spark.createDataFrame([(1, 3), (4, 2)], [\"first\", \"second\"])\n",
        "\n",
        "def my_func(col_1, col_2):\n",
        "    if (col_1 > col_2):\n",
        "        return \"{} is bigger than {}\".format(col_1, col_2)\n",
        "    else:\n",
        "        return \"{} is bigger than {}\".format(col_2, col_1)\n",
        "\n",
        "my_udf = fn.udf(my_func, StringType())\n",
        "\n",
        "df.withColumn(\"udf\", my_udf(df['first'], df['second'])).show()"
      ],
      "id": "fcb831d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Joins ($⋈$)\n",
        "\n",
        "## Using the `spark.sql` API"
      ],
      "id": "5f1f1e41-9e4e-41e1-9993-373e79b3fc09"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:29.098957Z",
          "start_time": "2022-01-26T10:58:28.042691Z"
        }
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "\n",
        "products = spark.createDataFrame([\n",
        "    ('1', 'mouse', 'microsoft', 39.99),\n",
        "    ('2', 'keyboard', 'logitech', 59.99),\n",
        "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
        "\n",
        "purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '1'),\n",
        "    (date(2017, 11, 5), 1, '2'),\n",
        "], ['date', 'quantity', 'prod_id'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "purchases.join(products, 'prod_id').show()"
      ],
      "id": "abee11b1"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "purchases.join(products, 'prod_id').explain()"
      ],
      "id": "767c68ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a `SQL` query"
      ],
      "id": "26eec902-07e8-4b2b-ad78-276937bda8cc"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:29.731271Z",
          "start_time": "2022-01-26T10:58:29.101559Z"
        }
      },
      "outputs": [],
      "source": [
        "products.createOrReplaceTempView(\"products\")\n",
        "purchases.createOrReplaceTempView(\"purchases\")\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT * \n",
        "    FROM purchases AS prc INNER JOIN \n",
        "        products AS prd \n",
        "    ON prc.prod_id = prd.prod_id\n",
        "\"\"\"\n",
        "spark.sql(query).show()"
      ],
      "id": "38d94e1d"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(query).explain()"
      ],
      "id": "5ccf6c49"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:30.660419Z",
          "start_time": "2022-01-26T10:58:29.734282Z"
        }
      },
      "outputs": [],
      "source": [
        "new_purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '3'),\n",
        "], ['date', 'quantity', 'prod_id_x'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "join_rule = new_purchases.prod_id_x == products.prod_id\n",
        "\n",
        "print(type(join_rule))\n",
        "\n",
        "new_purchases.join(products, join_rule, 'left').show()"
      ],
      "id": "a410f40c"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "join_rule.info"
      ],
      "id": "98735a2e"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:31.319336Z",
          "start_time": "2022-01-26T10:58:30.663809Z"
        }
      },
      "outputs": [],
      "source": [
        "new_purchases = spark.createDataFrame([\n",
        "    (date(2017, 11, 1), 2, '1'),\n",
        "    (date(2017, 11, 2), 1, '3'),\n",
        "], ['date', 'quantity', 'prod_id_x'])\n",
        "\n",
        "# The default join type is the \"INNER\" join\n",
        "join_rule = new_purchases.prod_id_x == products.prod_id\n",
        "\n",
        "new_purchases.join(products, join_rule, 'left').show()"
      ],
      "id": "d340af00"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Various types of joins"
      ],
      "id": "8c5c1769-2b75-4d5c-bbf7-57d91dec6bc5"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:31.376310Z",
          "start_time": "2022-01-26T10:58:31.323600Z"
        }
      },
      "outputs": [],
      "source": [
        "left = spark.createDataFrame([\n",
        "    (1, \"A1\"), (2, \"A2\"), (3, \"A3\"), (4, \"A4\")], \n",
        "    [\"id\", \"value\"])\n",
        "\n",
        "right = spark.createDataFrame([\n",
        "    (3, \"A3\"), (4, \"A4\"), (4, \"A4_1\"), (5, \"A5\"), (6, \"A6\")], \n",
        "    [\"id\", \"value\"])\n",
        "\n",
        "join_types = [\n",
        "    \"inner\", \"outer\", \"left\", \"right\",\n",
        "    \"leftsemi\", \"leftanti\"\n",
        "]"
      ],
      "id": "ba4b1e18"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:34.708236Z",
          "start_time": "2022-01-26T10:58:31.380091Z"
        }
      },
      "outputs": [],
      "source": [
        "for join_type in join_types:\n",
        "    print(join_type)\n",
        "    left.join(right, on=\"id\", how=join_type)\\\n",
        "        .orderBy(\"id\")\\\n",
        "        .show()"
      ],
      "id": "59dfd93c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agregations (summarize)\n",
        "\n",
        "## Examples using the API"
      ],
      "id": "bf62b138-ef1e-4094-8aaa-46579c25b99f"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:35.398306Z",
          "start_time": "2022-01-26T10:58:34.710552Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "products = spark.createDataFrame([\n",
        "    ('1', 'mouse', 'microsoft', 39.99),\n",
        "    ('2', 'mouse', 'microsoft', 59.99),\n",
        "    ('3', 'keyboard', 'microsoft', 59.99),\n",
        "    ('4', 'keyboard', 'logitech', 59.99),\n",
        "    ('5', 'mouse', 'logitech', 29.99),\n",
        "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
        "\n",
        "( \n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .avg('prod_value')\n",
        "        .show()\n",
        ")"
      ],
      "id": "6b0c20d3"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:35.782623Z",
          "start_time": "2022-01-26T10:58:35.400724Z"
        }
      },
      "outputs": [],
      "source": [
        "(\n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .agg(fn.avg('prod_value'))\n",
        "        .show()\n",
        ")"
      ],
      "id": "ad2d66aa"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    products\n",
        "        .groupBy('prod_cat')\n",
        "        .agg(\n",
        "            fn.mean('prod_value'), \n",
        "            fn.stddev('prod_value')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "181a1dd5"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:36.195471Z",
          "start_time": "2022-01-26T10:58:35.784780Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "(\n",
        "    products\n",
        "        .groupBy('prod_brand', 'prod_cat')\\\n",
        "        .agg(\n",
        "            fn.avg('prod_value')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "06f1b371"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:36.650354Z",
          "start_time": "2022-01-26T10:58:36.207985Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as fn\n",
        "\n",
        "(\n",
        "    products\n",
        "        .groupBy('prod_brand')\n",
        "        .agg(\n",
        "            fn.round(\n",
        "                fn.avg('prod_value'), 1)\n",
        "                .alias('average'),\n",
        "            fn.ceil(\n",
        "                fn.sum('prod_value'))\n",
        "                .alias('sum'),\n",
        "            fn.min('prod_value')\n",
        "                .alias('min')\n",
        "        )\n",
        "        .show()\n",
        ")"
      ],
      "id": "e2dca7ce"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example using a query"
      ],
      "id": "1bc60652-00a4-4160-9d6b-3ea89d1bde4c"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:37.089099Z",
          "start_time": "2022-01-26T10:58:36.652842Z"
        }
      },
      "outputs": [],
      "source": [
        "products.createOrReplaceTempView(\"products\")"
      ],
      "id": "de981135"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    prod_brand,\n",
        "    round(avg(prod_value), 1) AS average,\n",
        "    min(prod_value) AS min\n",
        "FROM \n",
        "    products\n",
        "GROUP BY \n",
        "    prod_brand\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "03ef8977"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Window functions\n",
        "\n",
        "## Numerical window functions"
      ],
      "id": "37351965-8590-43ca-9656-94048337a163"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:37.751296Z",
          "start_time": "2022-01-26T10:58:37.092075Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "# First, we create the Window definition\n",
        "window = Window.partitionBy('prod_brand')\n",
        "\n",
        "print(type(window))"
      ],
      "id": "10b9909e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can use `over` to aggregate on this window"
      ],
      "id": "4a6962a4-0915-47db-8169-dbb435af27d9"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg = fn.avg('prod_value').over(window)\n",
        "\n",
        "# Finally, we can it as a classical column\n",
        "(\n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .show()\n",
        ")"
      ],
      "id": "14eb27ca"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With SQL queries, using multiple windows is not a problem"
      ],
      "id": "d28034a2-151f-4e57-ab22-67f4c0e78465"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "    SELECT \n",
        "        *, \n",
        "        ROUND(AVG(prod_value) OVER w1, 2)  AS avg_brand_value,\n",
        "        ROUND(AVG(prod_value) OVER w2, 1)  AS avg_prod_value\n",
        "    FROM \n",
        "        products\n",
        "    WINDOW \n",
        "        w1 AS (PARTITION BY prod_brand),\n",
        "        w2 AS (PARTITION BY prod_cat)\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "id": "d425967e"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "window2 = Window.partitionBy('prod_cat')\n",
        "\n",
        "avg2 = fn.avg('prod_value').over(window2)\n",
        "\n",
        "# Finally, we can it as a classical column\n",
        "( \n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .withColumn('avg_prod_value', fn.round(avg2, 1))\n",
        "        .show()\n",
        ")"
      ],
      "id": "9e400f05"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compare the physical plans associated with the two jobs."
      ],
      "id": "f4deb694-2086-4866-a9e6-4c4eb90853c6"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "( \n",
        "    products\n",
        "        .withColumn('avg_brand_value', fn.round(avg, 2))\n",
        "        .withColumn('avg_prod_value', fn.round(avg2, 1))\n",
        "        .explain()\n",
        ")"
      ],
      "id": "989f5b90"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(query).explain()"
      ],
      "id": "36f10874"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Windows can be defined on multiple columns"
      ],
      "id": "180f25b6-51d1-4434-bae5-637039f9d023"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:38.261379Z",
          "start_time": "2022-01-26T10:58:37.753256Z"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "window = Window.partitionBy('prod_brand', 'prod_cat')\n",
        "\n",
        "avg = fn.avg('prod_value').over(window)\n",
        "\n",
        "\n",
        "(\n",
        "    products    \n",
        "        .withColumn('avg_value', fn.round(avg, 2))\n",
        "        .show()\n",
        ")"
      ],
      "id": "159f8b0b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lag and Lead"
      ],
      "id": "3bf52fa0-d286-4133-8342-c4fa6bc33fbe"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:39.785452Z",
          "start_time": "2022-01-26T10:58:39.084502Z"
        }
      },
      "outputs": [],
      "source": [
        "purchases = spark.createDataFrame(\n",
        "    [\n",
        "        (date(2017, 11, 1), 'mouse'),\n",
        "        (date(2017, 11, 2), 'mouse'),\n",
        "        (date(2017, 11, 4), 'keyboard'),\n",
        "        (date(2017, 11, 6), 'keyboard'),\n",
        "        (date(2017, 11, 9), 'keyboard'),\n",
        "        (date(2017, 11, 12), 'mouse'),\n",
        "        (date(2017, 11, 18), 'keyboard')\n",
        "    ], \n",
        "    ['date', 'prod_cat']\n",
        ")\n",
        "\n",
        "purchases.show()\n",
        "\n",
        "window = Window.partitionBy('prod_cat').orderBy('date')\n",
        "\n",
        "prev_purch = fn.lag('date', 1).over(window)\n",
        "next_purch = fn.lead('date', 1).over(window)\n",
        "\n",
        "purchases\\\n",
        "    .withColumn('prev', prev_purch)\\\n",
        "    .withColumn('next', next_purch)\\\n",
        "    .orderBy('prod_cat', 'date')\\\n",
        "    .show()"
      ],
      "id": "a7a01cf3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rank, DenseRank and RowNumber"
      ],
      "id": "f360ae0e-e066-4c17-b3fc-595b7889321c"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:40.005845Z",
          "start_time": "2022-01-26T10:58:39.787433Z"
        }
      },
      "outputs": [],
      "source": [
        "contestants = spark.createDataFrame(\n",
        "    [   \n",
        "        ('veterans', 'John', 3000),\n",
        "        ('veterans', 'Bob', 3200),\n",
        "        ('veterans', 'Mary', 4000),\n",
        "        ('young', 'Jane', 4000),\n",
        "        ('young', 'April', 3100),\n",
        "        ('young', 'Alice', 3700),\n",
        "        ('young', 'Micheal', 4000),\n",
        "    ], \n",
        "    ['category', 'name', 'points']\n",
        ")\n",
        "\n",
        "contestants.show()"
      ],
      "id": "46f8ba28"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-26T10:58:40.653650Z",
          "start_time": "2022-01-26T10:58:40.009618Z"
        }
      },
      "outputs": [],
      "source": [
        "window = (\n",
        "    Window\n",
        "        .partitionBy('category')\n",
        "        .orderBy(contestants.points.desc())\n",
        ")\n",
        "\n",
        "rank = fn.rank().over(window)\n",
        "dense_rank = fn.dense_rank().over(window)\n",
        "row_number = fn.row_number().over(window)\n",
        "\n",
        "contestants\\\n",
        "    .withColumn('rank', rank)\\\n",
        "    .withColumn('dense_rank', dense_rank)\\\n",
        "    .withColumn('row_number', row_number)\\\n",
        "    .orderBy('category', fn.col('points').desc())\\\n",
        "    .show()"
      ],
      "id": "3f6d2578"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connection to a database \n",
        "\n",
        "The postgres server runs locally on my laptop, it is equiped with a\n",
        "number of training schemata, including `nycflights` (see\n",
        "<https://s-v-b.github.io/MA15Y030/schemas/schema-nycflights.html>)"
      ],
      "id": "4ad0a17d-2017-4c2b-bc6b-fa3bb87b6281"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_flights = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:postgresql://localhost:5434/bd_2023-24\") \\\n",
        "    .option(\"dbschema\", \"nycflights\")\\\n",
        "    .option(\"dbtable\", \"flights\") \\\n",
        "    .option(\"user\", \"postgres\") \\\n",
        "    .option(\"password\", \"postgres\") \\\n",
        "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
        "    .load()\n",
        "\n",
        "df_flights.printSchema()"
      ],
      "id": "43520315"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To load the five tables, we avoid cut and paste, and abide to the DRY\n",
        "principle.\n",
        "\n",
        "We package the options in a dictionnary"
      ],
      "id": "59880cf9-4457-4c77-b86b-6b8c24f1ca9b"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "db_con_settings = {\n",
        "    'url': \"jdbc:postgresql://localhost:5434/bd_2023-24\",\n",
        "    'dbschema':  \"nycflights\",\n",
        "    'user':  \"postgres\",\n",
        "    'password':  \"postgres\",\n",
        "    'driver':  \"org.postgresql.Driver\"\n",
        "}"
      ],
      "id": "c0a4ba71"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We prepare a Python object using dictionnary unpacking."
      ],
      "id": "d39b6000-9b4a-4d81-951d-2f1f83fea9ec"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "o  = spark.read \\\n",
        "    .format(\"jdbc\")\\\n",
        "    .options(**db_con_settings)"
      ],
      "id": "7f9b84ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the object to load the different tables in a `for` loop."
      ],
      "id": "f0decf59-0952-406d-b668-be63a177ae9f"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "tbl_names = ['flights', 'airports', 'airlines', 'planes', 'weather']\n",
        "\n",
        "dic_df = {}\n",
        "\n",
        "for tn in tbl_names:\n",
        "    dic_df[tn] = o.option('dbtable', tn).load()"
      ],
      "id": "ac8dadd5"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k, v in dic_df.items():\n",
        "    v.printSchema()"
      ],
      "id": "1ad9a650"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now query the tables."
      ],
      "id": "0ce81f99-b262-4346-a090-3f6cef77ead1"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  }
}