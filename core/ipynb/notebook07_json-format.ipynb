{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using `JSON` data with `Python`\n",
        "\n",
        "This notebook is concerned with `JSON` a format that serves many\n",
        "purposes. Just as `csv` files, `json` files are important sources and\n",
        "sinks for Spark. As a exchange format, `JSON` is also a serialization\n",
        "tool for Python and many other languages. `JSON` provides a way to\n",
        "accomodate *semi-structured* data in otherwise tabular environments\n",
        "(dataframes and databases tables).\n",
        "\n",
        "The notebook is organized in the following way:\n",
        "\n",
        "-   Serialization/Deserialization of Python builtin types using `JSON`\n",
        "-   Serialization/Deserialization of (some) custom types using `JSON`\n",
        "-   `JSON` readers and writers for Spark dataframes\n",
        "-   Composite types in Spark dataframes\n",
        "-   Advanced `JSON` readers and writers for Spark dataframes\n",
        "\n",
        "> **Warning**\n",
        ">\n",
        "> This notebook is not exhaustive. It does not address several aspects\n",
        "> of JSON management in Spark. Spark is not only able to read from and\n",
        "> write to JSON files, it also offers tools to manage JSON strings\n",
        "> inline (query and construction).\n",
        ">\n",
        "> [See Documentation on SQL\n",
        "> functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)\n",
        "\n",
        "## Serialization and deserialization of built-in types"
      ],
      "id": "01de08e4-78bb-41b8-84f6-cdb4c3191989"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2020-03-17T14:29:25.759874Z",
            "start_time": "2020-03-17T14:29:25.726787Z"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"active\": true,\n",
            "    \"age\": 78,\n",
            "    \"balance\": 345.8,\n",
            "    \"friends\": [\n",
            "        \"Jane\",\n",
            "        \"John\"\n",
            "    ],\n",
            "    \"name\": \"Foo Bar\",\n",
            "    \"other_names\": [\n",
            "        \"Doe\",\n",
            "        \"Joe\"\n",
            "    ],\n",
            "    \"spouse\": null\n",
            "}"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "obj = {\n",
        "    \"name\": \"Foo Bar\",\n",
        "    \"age\": 78,\n",
        "    \"friends\": [\"Jane\",\"John\"],\n",
        "    \"balance\": 345.80,\n",
        "    \"other_names\":(\"Doe\",\"Joe\"),\n",
        "    \"active\": True,\n",
        "    \"spouse\": None\n",
        "}\n",
        "\n",
        "print(json.dumps(obj, sort_keys=True, indent=4))"
      ],
      "id": "116394d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> `json.dumps()` outputs a `JSON` formatted string.\n",
        ">\n",
        "> Not every type of object can be fed to `json.dumps()`."
      ],
      "id": "3a69d2bc-c42a-4332-813d-745ceb130d61"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2020-03-17T14:29:26.039839Z",
            "start_time": "2020-03-17T14:29:26.027858Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "with open('user.json','w') as file:\n",
        "    json.dump(obj, file, sort_keys=True, indent=4)"
      ],
      "id": "578302e1"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2020-03-17T14:29:27.110218Z",
            "start_time": "2020-03-17T14:29:26.479550Z"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"active\": true,\n",
            "    \"age\": 78,\n",
            "    \"balance\": 345.8,\n",
            "    \"friends\": [\n",
            "        \"Jane\",\n",
            "        \"John\"\n",
            "    ],\n",
            "    \"name\": \"Foo Bar\",\n",
            "    \"other_names\": [\n",
            "        \"Doe\",\n",
            "        \"Joe\"\n",
            "    ],\n",
            "    \"spouse\": null\n",
            "}"
          ]
        }
      ],
      "source": [
        "!cat user.json"
      ],
      "id": "cd25014e"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2020-03-17T14:29:27.137307Z",
            "start_time": "2020-03-17T14:29:27.114179Z"
          }
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'active': True,\n",
              " 'age': 78,\n",
              " 'balance': 345.8,\n",
              " 'friends': ['Jane', 'John'],\n",
              " 'name': 'Foo Bar',\n",
              " 'other_names': ['Doe', 'Joe'],\n",
              " 'spouse': None}"
            ]
          }
        }
      ],
      "source": [
        "json.loads('{\"active\": true, \"age\": 78, \"balance\": 345.8, \"friends\": [\"Jane\",\"John\"], \"name\": \"Foo Bar\", \"other_names\": [\"Doe\",\"Joe\"],\"spouse\":null}')"
      ],
      "id": "37ef803c"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2020-03-17T14:29:27.149816Z",
            "start_time": "2020-03-17T14:29:27.140548Z"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'active': True, 'age': 78, 'balance': 345.8, 'friends': ['Jane', 'John'], 'name': 'Foo Bar', 'other_names': ['Doe', 'Joe'], 'spouse': None}"
          ]
        }
      ],
      "source": [
        "with open('user.json', 'r') as file:\n",
        "    user_data = json.load(file)\n",
        "\n",
        "print(user_data)"
      ],
      "id": "22d7cb73"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question**\n",
        ">\n",
        "> What happens if we feed `json.dumps()` with a `numpy` array?\n",
        "\n",
        "> **Question**\n",
        ">\n",
        "> What happens if we feed `json.dumps()` with a `datatime` object?\n",
        "\n",
        "## Serialization and deserialization of custom objects"
      ],
      "id": "4f850dd7-1708-4555-a041-da949522e99c"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class User(object):\n",
        "    \"\"\"Custom User Class\n",
        "    \"\"\"\n",
        "    def __init__(self, name, age, active, balance, \n",
        "                 other_names, friends, spouse):\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.active = active\n",
        "        self.balance = balance\n",
        "        self.other_names = other_names\n",
        "        self.friends = friends\n",
        "        self.spouse = spouse\n",
        "            \n",
        "    def __repr__(self):\n",
        "        s = \"User(\"\n",
        "        s += \"name=\" + repr(self.name)\n",
        "        s += \", age=\" + repr(self.age)\n",
        "        s += \", active=\" + repr(self.active)\n",
        "        s += \", other_names=\" + repr(self.other_names)\n",
        "        s += \", friends=\" + repr(self.friends)\n",
        "        s += \", spouse=\" + repr(self.spouse) + \")\"\n",
        "        return s"
      ],
      "id": "user-def-class-user"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Tip**\n",
        ">\n",
        "> Brush up your dunder/magic methods, for example in *Fluent Python* by\n",
        "> Ramalho (Chapter I: *The Python data model*, Section *Overview of\n",
        "> Special Methods*)\n",
        ">\n",
        "> See also package `dataclasses`\n",
        ">\n",
        "> ``` python\n",
        "> from dataclasses import dataclass\n",
        ">\n",
        "> @dataclass\n",
        "> class User2:\n",
        ">     name: str \n",
        ">     age: int\n",
        ">     active: bool\n",
        ">     balance: float \n",
        ">     other_names: str\n",
        ">     friends: list\n",
        ">     spouse: str\n",
        ">\n",
        "> nobody = User2(\n",
        ">     name=\"Doe\", \n",
        ">     age=21, \n",
        ">     active=True,\n",
        ">     balance= 2.5, \n",
        ">     other_names=\"Roy Bean\", \n",
        ">     friends=[\"Joe\", \"Jack\", \"William\", \"Averell\"], \n",
        ">     spouse=\"Calamity Jane\"\n",
        "> )\n",
        ">\n",
        "> nobody\n",
        "> ```\n",
        ">\n",
        ">     User2(name='Doe', age=21, active=True, balance=2.5, other_names='Roy Bean', friends=['Joe', 'Jack', 'William', 'Averell'], spouse='Calamity Jane')"
      ],
      "id": "91bab20c-9abd-4687-b1bc-29fe88999b5b"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "User(name='Foo Bar', age=78, active=True, other_names=('Doe', 'Joe'), friends=['Jane', 'John'], spouse=None)"
            ]
          }
        }
      ],
      "source": [
        "new_user = User(\n",
        "    name = \"Foo Bar\",\n",
        "    age = 78,\n",
        "    friends = [\"Jane\", \"John\"],\n",
        "    balance = 345.80,\n",
        "    other_names = (\"Doe\", \"Joe\"),\n",
        "    active = True,\n",
        "    spouse = None\n",
        ")\n",
        "\n",
        "new_user"
      ],
      "id": "2baca53e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> Uncomment to see what happens"
      ],
      "id": "f61f4d10-d757-4bee-b703-7ee4d8b4293b"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "quarto-private-1": {
          "key": "ExecuteTime",
          "value": {
            "end_time": "2020-03-17T14:29:49.613442Z",
            "start_time": "2020-03-17T14:29:49.601102Z"
          }
        }
      },
      "outputs": [],
      "source": [
        "# This will raise a TypeError\n",
        "# json.dumps(new_user)"
      ],
      "id": "c00c97f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the custom object `new_user` is not JSON serializable. So\n",
        "let’s build a method that does that for us.\n",
        "\n",
        "-   This comes as no surprise to us, since earlier on we observed that\n",
        "    the `json` module only handles the built-in types, and `User` is not\n",
        "    one.\n",
        "\n",
        "-   We need to send our user data to a client over a network, so how do\n",
        "    we get ourselves out of this error state?\n",
        "\n",
        "-   A simple solution would be to convert our custom type into a\n",
        "    serializable type that is a built-in type. We can conveniently\n",
        "    define a method `convert_to_dict()` that returns a dictionary\n",
        "    representation of our object. `json.dumps()` takes in a optional\n",
        "    argument, `default`, which specifies a function to be called if the\n",
        "    object is not serializable. This function returns a JSON encodable\n",
        "    version of the object.\n",
        "\n",
        "Recall that class `obj` has a `dunder` attribute `__dict__` that\n",
        "provides a basis for obtaining a dictionary with the attributes of any\n",
        "object:"
      ],
      "id": "d98edac8-c74c-432d-8ac7-c0e834b5acb0"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'name': 'Foo Bar',\n",
              " 'age': 78,\n",
              " 'active': True,\n",
              " 'balance': 345.8,\n",
              " 'other_names': ('Doe', 'Joe'),\n",
              " 'friends': ['Jane', 'John'],\n",
              " 'spouse': None}"
            ]
          }
        }
      ],
      "source": [
        "new_user.__dict__"
      ],
      "id": "d7260d6a"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def obj_to_dict(obj):\n",
        "    \"\"\"Converts an object to a dictionary representation of the object including \n",
        "    meta-data information about the object's module and class name.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    obj : `object`\n",
        "        A python object to be converted into a dictionary representation\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output : `dict`\n",
        "        A dictionary representation of the object\n",
        "    \"\"\"\n",
        "    # Add object meta data \n",
        "    obj_dict = {\n",
        "        \"__class__\": obj.__class__.__name__,\n",
        "        \"__module__\": obj.__module__\n",
        "    }\n",
        "    # Add the object properties\n",
        "    return obj_dict | obj.__dict__"
      ],
      "id": "8a678db1"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'__class__': 'User',\n",
              " '__module__': '__main__',\n",
              " 'name': 'Foo Bar',\n",
              " 'age': 78,\n",
              " 'active': True,\n",
              " 'balance': 345.8,\n",
              " 'other_names': ('Doe', 'Joe'),\n",
              " 'friends': ['Jane', 'John'],\n",
              " 'spouse': None}"
            ]
          }
        }
      ],
      "source": [
        "obj_to_dict(new_user)"
      ],
      "id": "1b9c9705"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function `convert_to_dict` does the following:\n",
        "\n",
        "-   create a dictionary named `obj_dict` to act as the dict\n",
        "    representation of our object.\n",
        "\n",
        "-   dunder attributes `__class__.__name__` and `__module__` provide\n",
        "    crucial metadata on the object: the class name and the module name\n",
        "\n",
        "-   add the instance attributes of the object using `obj.__dict__`\n",
        "    (`Python` stores instance attributes in a dictionary)\n",
        "\n",
        "The resulting `obj_dict` is now serializable (provided all attributes of\n",
        "our object are).\n",
        "\n",
        "Now we can comfortably call `json.dumps()` on the object and pass\n",
        "`default=convert_to_dict`\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> Obviously this fails if one of the attributes is not `JSON`\n",
        "> serializable"
      ],
      "id": "1612fca0-c175-4fea-b153-7039661ec61a"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"__class__\": \"User\",\n",
            "    \"__module__\": \"__main__\",\n",
            "    \"active\": true,\n",
            "    \"age\": 78,\n",
            "    \"balance\": 345.8,\n",
            "    \"friends\": [\n",
            "        \"Jane\",\n",
            "        \"John\"\n",
            "    ],\n",
            "    \"name\": \"Foo Bar\",\n",
            "    \"other_names\": [\n",
            "        \"Doe\",\n",
            "        \"Joe\"\n",
            "    ],\n",
            "    \"spouse\": null\n",
            "}"
          ]
        }
      ],
      "source": [
        "print(json.dumps(new_user, default=obj_to_dict, indent=4, sort_keys=True))"
      ],
      "id": "7aec5e1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, if we want to decode (deserialiaze) a custom object, and create the\n",
        "correct object type, we need a function that does the inverse of\n",
        "`obj_to_dict`, since `json.loads` simply returns a `dict`:"
      ],
      "id": "5abf12fc-cba7-4d57-b68f-1628fb0afdff"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'__class__': 'User', '__module__': '__main__', 'name': 'Foo Bar', 'age': 78, 'active': True, 'balance': 345.8, 'other_names': ['Doe', 'Joe'], 'friends': ['Jane', 'John'], 'spouse': None}"
          ]
        }
      ],
      "source": [
        "user_data = json.loads(json.dumps(new_user, default=obj_to_dict))\n",
        "print(user_data)"
      ],
      "id": "c2504319"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It also works for sequences of objects!"
      ],
      "id": "5e039b5b-cd6d-4909-afc2-1a275e77152c"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'__class__': 'User', '__module__': '__main__', 'name': 'Foo Bar', 'age': 78, 'active': True, 'balance': 345.8, 'other_names': ['Doe', 'Joe'], 'friends': ['Jane', 'John'], 'spouse': None}, {'__class__': 'User2', '__module__': '__main__', 'name': 'Doe', 'age': 21, 'active': True, 'balance': 2.5, 'other_names': 'Roy Bean', 'friends': ['Joe', 'Jack', 'William', 'Averell'], 'spouse': 'Calamity Jane'}]"
          ]
        }
      ],
      "source": [
        "users_data = json.loads(json.dumps([new_user, nobody], default=obj_to_dict))\n",
        "\n",
        "print(users_data)"
      ],
      "id": "c18a4235"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> We need `json.loads()` to reconstruct a `User` object from this\n",
        "> dictionary: `json.loads()` takes an optional argument `object_hook`\n",
        "> which specifies a function that returns the desired custom object,\n",
        "> given the decoded output (which in this case, is a `dict`)."
      ],
      "id": "17df48d4-e2d1-4e3b-beb8-35caa98d7d16"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dict_to_obj(input_dict):\n",
        "    \"\"\"Converts a dictionary representation of an object to an instance of the object.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_dict : `dict`\n",
        "        A dictionary representation of the object, containing \"__module__\" \n",
        "        and \"__class__\" metadata\n",
        "\n",
        "    Returns\n",
        "    -------    \n",
        "    obj : `object`\n",
        "        A python object constructed from the dictionary representation    \n",
        "    \"\"\"\n",
        "    assert \"__class__\" in input_dict and \"__module__\" in input_dict\n",
        "    class_name = input_dict.pop(\"__class__\")\n",
        "    module_name = input_dict.pop(\"__module__\")\n",
        "    module = __import__(module_name)\n",
        "    class_ = getattr(module, class_name)\n",
        "    obj = class_(**input_dict)\n",
        "    return obj"
      ],
      "id": "c78a75ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function does the following:\n",
        "\n",
        "-   Extract the class name from the dictionary under the key `__class__`\n",
        "-   Extract the module name from the dictionary under the key\n",
        "    `__module__`\n",
        "-   Imports the module and get the class\n",
        "-   Instantiate the class by giving to the class constructor all the\n",
        "    instance arguments through dictionary unpacking"
      ],
      "id": "c5c7e430-a792-4e40-87c2-b885fbc73320"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "User(name='Foo Bar', age=78, active=True, other_names=['Doe', 'Joe'], friends=['Jane', 'John'], spouse=None)"
            ]
          }
        }
      ],
      "source": [
        "obj_data = json.dumps(new_user, default=obj_to_dict)\n",
        "new_object = json.loads(obj_data, object_hook=dict_to_obj)\n",
        "new_object"
      ],
      "id": "53d65a69"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "__main__.User"
            ]
          }
        }
      ],
      "source": [
        "type(new_object)"
      ],
      "id": "c10c08e7"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "78"
            ]
          }
        }
      ],
      "source": [
        "new_object.age"
      ],
      "id": "d240370f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> Functions `obj_to_dict()` and `dict_to_obj()` are showcases for\n",
        "> special/magic/dunder methods.\n",
        ">\n",
        "> In the definition of class `User`, two special methods were explicitly\n",
        "> defined: `__init__()` and `__repr__()`. But many more are available,\n",
        "> including `__dir__()`.\n",
        ">\n",
        "> Remember that some dunder members of the object are not callable."
      ],
      "id": "cf4d351b-9be3-4e94-8a59-31824a812310"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__']"
            ]
          }
        }
      ],
      "source": [
        "[dude for dude in dir(new_object) \n",
        "          if dude.startswith('__') and \n",
        "             callable(getattr(new_object, dude))]"
      ],
      "id": "1aecc279"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "['__dict__', '__doc__', '__module__', '__weakref__']"
            ]
          }
        }
      ],
      "source": [
        "[dude for dude in dir(new_object) \n",
        "          if dude.startswith('__') and \n",
        "             not callable(getattr(new_object, dude))]"
      ],
      "id": "719f132c"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "78"
            ]
          }
        }
      ],
      "source": [
        "new_object.__getattribute__('age')\n",
        "\n",
        "getattr(new_object, 'age')"
      ],
      "id": "97a8ec52"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> Have a look at [`dataclasses`\n",
        "> documentation](https://docs.python.org/3/library/dataclasses.html).\n",
        ">\n",
        "> See also [Chapter 5: Data class\n",
        "> builders](https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/ch05.html)\n",
        "> in [Fluent Python](https://www.fluentpython.com)\n",
        "\n",
        "# Using `JSON` with Spark\n",
        "\n",
        "First, we download the data if it’s not there yet"
      ],
      "id": "b6f12eeb-2641-49f8-a5d2-e90f6a92e0e9"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests, zipfile, io\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path('drug-enforcement.json.zip')\n",
        "\n",
        "if not path.exists():\n",
        "    url = \"https://s-v-b.github.io/IFEBY310/data/drug-enforcement.json.zip\"\n",
        "    r = requests.get(url)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(path='./')"
      ],
      "id": "90555385"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drug-enforcement.json"
          ]
        }
      ],
      "source": [
        "!ls drug*"
      ],
      "id": "6a55d890"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading a `JSON` dataset with `Spark`"
      ],
      "id": "7d483565-c2a8-4928-bf0a-dd7a4b3ba9b5"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
            "26/02/16 10:10:55 WARN Utils: Your hostname, boucheron-Precision-5480, resolves to a loopback address: 127.0.1.1; using 172.23.32.10 instead (on interface eth0)\n",
            "26/02/16 10:10:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "26/02/16 10:10:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as fn\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = (\n",
        "    SparkSession\n",
        "    .builder\n",
        "    .appName(\"Spark JSON\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "sc = spark._sc"
      ],
      "id": "0a1aace6"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"drug-enforcement.json\""
      ],
      "id": "a0c43210"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, lets look at the data. It’s a large set of JSON records about\n",
        "drugs enforcement."
      ],
      "id": "b0abf32a-33a9-42ab-a04b-814d5029a0d3"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "      \"classification\": \"Class II\",\n",
            "      \"center_classification_date\": \"20121025\",\n",
            "      \"report_date\": \"20121031\",\n",
            "      \"postal_code\": \"08816-2108\",\n",
            "      \"termination_date\": \"20141007\",\n",
            "      \"recall_initiation_date\": \"20120904\",\n",
            "      \"recall_number\": \"D-026-2013\",\n",
            "      \"city\": \"East Brunswick\",\n",
            "      \"event_id\": \"63384\",\n",
            "      \"distribution_pattern\": \"Nationwide\",\n",
            "      \"openfda\": {},\n",
            "      \"recalling_firm\": \"Raritan Pharmaceuticals, Inc.\",\n",
            "      \"voluntary_mandated\": \"Voluntary: Firm Initiated\",\n",
            "      \"state\": \"NJ\",\n",
            "      \"reason_for_recall\": \"Microbial Contamination of Non-Sterile Products: Product is being recalled due to possible microbial contamination by C. difficile discovered in the raw material.\",\n",
            "      \"initial_firm_notification\": \"E-Mail\",\n",
            "      \"status\": \"Terminated\",\n",
            "      \"product_type\": \"Drugs\",\n",
            "      \"country\": \"United States\",\n",
            "      \"product_description\": \"Wal-Mucil 100% Natural Fiber, 100% Natural Psyllium Seed Husk, Fiber Laxative/Supplement, a)160 capsules per bottle (item #503663), and b) 320 capsules per bottle (Item #586143), Distributed by: Walgreen Co., 200 Wilmot Road, Deerfield, IL 60015-4616, www.walgreens.com, a) UPC 3-11917-08151-9, b) UPC 3-11917-07658-4\",\n",
            "      \"code_info\": \"Lots a) 15952, 16270,16425, Exp 06/15; b)16459, 16466, 16467, Exp 07/15\",\n",
            "      \"address_1\": \"8 Joanna Ct\",\n",
            "      \"address_2\": \"\",\n",
            "      \"product_quantity\": \"56,808 bottles\"\n",
            "    },\n",
            "    {\n",
            "      \"classification\": \"Class II\",\n",
            "      \"center_classification_date\": \"20121025\",\n",
            "      \"report_date\": \"20121031\",\n",
            "      \"postal_code\": \"08816-2108\",\n",
            "      \"termination_date\": \"20141007\",\n",
            "      \"recall_initiation_date\": \"20120904\",\n",
            "      \"recall_number\": \"D-031-2013\",\n",
            "      \"city\": \"East Brunswick\",\n",
            "      \"event_id\": \"63384\",\n",
            "      \"distribution_pattern\": \"Nationwide\",\n",
            "      \"openfda\": {},\n",
            "      \"recalling_firm\": \"Raritan Pharmaceuticals, Inc.\",\n",
            "      \"voluntary_mandated\": \"Voluntary: Firm Initiated\",\n",
            "      \"state\": \"NJ\",\n",
            "      \"reason_for_recall\": \"Microbial Contamination of Non-Sterile Products: Product is being recalled due to possible microbial contamination by C. difficile discovered in the raw material.\",\n",
            "      \"initial_firm_notification\": \"E-Mail\",\n",
            "      \"status\": \"Terminated\",\n",
            "      \"product_type\": \"Drugs\",\n",
            "      \"country\": \"United States\",\n",
            "      \"product_description\": \"Premier Value Fiber Plus Calcium Supplement Capsules, 120 capsules per bottle, Distributed by: Chain Drug Consortium, LLC, Boca Raton, FL, UPC 8-40986-01987-6\",\n",
            "      \"code_info\": \"Lot 15087, Exp 08/15\",\n",
            "      \"address_1\": \"8 Joanna Ct\",\n",
            "      \"address_2\": \"\",\n",
            "      \"product_quantity\": \"96 bottles\"\n",
            "    },\n",
            "    {\n",
            "      \"classification\": \"Class III\",\n",
            "      \"center_classification_date\": \"20121106\",\n",
            "      \"report_date\": \"20121114\",\n",
            "      \"postal_code\": \"08807\",\n",
            "      \"termination_date\": \"20130325\",\n",
            "      \"recall_initiation_date\": \"20121015\",\n",
            "      \"recall_number\": \"D-047-2013\",\n",
            "      \"city\": \"Bridgewater\",\n",
            "      \"event_id\": \"63488\",\n",
            "      \"distribution_pattern\": \"Nationwide\",\n",
            "      \"openfda\": {},\n",
            "      \"recalling_firm\": \"Valeant Pharmaceuticals\",\n",
            "      \"voluntary_mandated\": \"Voluntary: Firm Initiated\",\n",
            "      \"state\": \"NJ\",\n",
            "      \"reason_for_recall\": \"Subpotent (Single Ingredient) Drug: This product was found to be subpotent for the salicylic acid ingredient.  Additionally, this product is mislabeled because the label either omits or erroneously added inactive ingredients to the label.\",\n",
            "      \"initial_firm_notification\": \"Letter\",\n",
            "      \"status\": \"Terminated\",\n",
            "      \"product_type\": \"Drugs\",\n",
            "      \"country\": \"United States\",\n",
            "      \"product_description\": \"AcneFree 3-in-1 Acne Night Repair Foam (retinol + salicylic acid 1.5% w/v), 3 oz (85 g) canister, Dist. by: University Medical Pharmaceuticals Corp., Irvine, CA  92618, UPC 7 88521 13548 6.\",\n",
            "      \"code_info\": \"All lots with expiration dates between 10/10/12 through 10/10/14 of UPC 7 88521 13548 6\",\n",
            "      \"address_1\": \"700 Rte 206 North\",\n",
            "      \"address_2\": \"\",\n",
            "      \"product_quantity\": \"81,319 canisters\"\n",
            "    },\n",
            "    {\n",
            "      \"classification\": \"Class III\",\n",
            "      \"center_classification_date\": \"20121220\",\n",
            "      \"report_date\": \"20121226\",\n",
            "      \"postal_code\": \"08558-1311\",\n",
            "      \"termination_date\": \"20140429\",\n",
            "      \"recall_initiation_date\": \"20121204\",\n",
            "      \"recall_number\": \"D-098-2013\",\n",
            "      \"city\": \"Skillman\",\n",
            "      \"more_code_info\": null,\n",
            "      \"event_id\": \"63787\",\n",
            "      \"distribution_pattern\": \"Nationwide\",\n",
            "      \"openfda\": {},\n",
            "      \"recalling_firm\": \"Johnson & Johnson\",\n",
            "      \"voluntary_mandated\": \"Voluntary: Firm Initiated\",\n",
            "      \"state\": \"NJ\",\n",
            "      \"reason_for_recall\": \"Superpotent (Single Ingredient Drug): salicylic acid\",\n",
            "      \"initial_firm_notification\": \"Letter\",\n",
            "      \"status\": \"Terminated\",\n",
            "      \"product_type\": \"Drugs\",\n",
            "      \"country\": \"United States\","
          ]
        }
      ],
      "source": [
        "!head -n 100 drug-enforcement.json"
      ],
      "id": "4c7ce64e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> We need to tell spark that rows span on several lines with the\n",
        "> `multLine` option\n",
        ">\n",
        "> See [Reading from JSON files in Spark\n",
        "> documentation](https://spark.apache.org/docs/latest/sql-data-sources-json.html)"
      ],
      "id": "d2977fad-d9f1-4b78-8f7f-a8076b782a36"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "\n",
        "df = (\n",
        "    spark\n",
        "        .read\n",
        "        .json('file://' + os.path.abspath(filename), \n",
        "               multiLine=True)\n",
        ")"
      ],
      "id": "4d4f2fa3"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address_1: string (nullable = true)\n",
            " |-- address_2: string (nullable = true)\n",
            " |-- center_classification_date: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- classification: string (nullable = true)\n",
            " |-- code_info: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- distribution_pattern: string (nullable = true)\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- initial_firm_notification: string (nullable = true)\n",
            " |-- more_code_info: string (nullable = true)\n",
            " |-- openfda: struct (nullable = true)\n",
            " |    |-- application_number: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- brand_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- generic_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- is_original_packager: array (nullable = true)\n",
            " |    |    |-- element: boolean (containsNull = true)\n",
            " |    |-- manufacturer_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- nui: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- original_packager_product_ndc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- package_ndc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_cs: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_epc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_moa: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_pe: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- product_ndc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- product_type: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- route: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- rxcui: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- spl_id: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- spl_set_id: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- substance_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- unii: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- upc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- postal_code: string (nullable = true)\n",
            " |-- product_description: string (nullable = true)\n",
            " |-- product_quantity: string (nullable = true)\n",
            " |-- product_type: string (nullable = true)\n",
            " |-- reason_for_recall: string (nullable = true)\n",
            " |-- recall_initiation_date: string (nullable = true)\n",
            " |-- recall_number: string (nullable = true)\n",
            " |-- recalling_firm: string (nullable = true)\n",
            " |-- report_date: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- termination_date: string (nullable = true)\n",
            " |-- voluntary_mandated: string (nullable = true)\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ],
      "id": "1c721362"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> In a less user-friendly format:"
      ],
      "id": "4a3894ac-6dfa-415a-b74e-cda9794df12d"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "StructType([StructField('address_1', StringType(), True), StructField('address_2', StringType(), True), StructField('center_classification_date', StringType(), True), StructField('city', StringType(), True), StructField('classification', StringType(), True), StructField('code_info', StringType(), True), StructField('country', StringType(), True), StructField('distribution_pattern', StringType(), True), StructField('event_id', StringType(), True), StructField('initial_firm_notification', StringType(), True), StructField('more_code_info', StringType(), True), StructField('openfda', StructType([StructField('application_number', ArrayType(StringType(), True), True), StructField('brand_name', ArrayType(StringType(), True), True), StructField('generic_name', ArrayType(StringType(), True), True), StructField('is_original_packager', ArrayType(BooleanType(), True), True), StructField('manufacturer_name', ArrayType(StringType(), True), True), StructField('nui', ArrayType(StringType(), True), True), StructField('original_packager_product_ndc', ArrayType(StringType(), True), True), StructField('package_ndc', ArrayType(StringType(), True), True), StructField('pharm_class_cs', ArrayType(StringType(), True), True), StructField('pharm_class_epc', ArrayType(StringType(), True), True), StructField('pharm_class_moa', ArrayType(StringType(), True), True), StructField('pharm_class_pe', ArrayType(StringType(), True), True), StructField('product_ndc', ArrayType(StringType(), True), True), StructField('product_type', ArrayType(StringType(), True), True), StructField('route', ArrayType(StringType(), True), True), StructField('rxcui', ArrayType(StringType(), True), True), StructField('spl_id', ArrayType(StringType(), True), True), StructField('spl_set_id', ArrayType(StringType(), True), True), StructField('substance_name', ArrayType(StringType(), True), True), StructField('unii', ArrayType(StringType(), True), True), StructField('upc', ArrayType(StringType(), True), True)]), True), StructField('postal_code', StringType(), True), StructField('product_description', StringType(), True), StructField('product_quantity', StringType(), True), StructField('product_type', StringType(), True), StructField('reason_for_recall', StringType(), True), StructField('recall_initiation_date', StringType(), True), StructField('recall_number', StringType(), True), StructField('recalling_firm', StringType(), True), StructField('report_date', StringType(), True), StructField('state', StringType(), True), StructField('status', StringType(), True), StructField('termination_date', StringType(), True), StructField('voluntary_mandated', StringType(), True)])"
            ]
          }
        }
      ],
      "source": [
        "df.schema"
      ],
      "id": "2f253f52"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> This dataset is a little bit of a mess!\n",
        ">\n",
        "> This should not be surprising. The data used to populate the Spark\n",
        "> dataframe are not classically tabular but what people call\n",
        "> *semi-structured*. Json is well-suited to store, represent, and\n",
        "> exchange such data.\n",
        ">\n",
        "> In the classical age of tabular data (according to Codd’s principles),\n",
        "> a table cell could only hold a scalar value (numeric, logical, text,\n",
        "> date, timestamp, …), nowadays Relational Database Management Systems\n",
        "> handle Arrays, Composite Types, Range Types, …, and Json (see\n",
        "> [PostgreSQL](https://www.postgresql.org/docs/current/datatype-json.html)).\n",
        ">\n",
        "> Spark, `R`, and `Pandas`, and modern relational databases also allow\n",
        "> us to work with complex types.\n",
        ">\n",
        "> Modern column oriented file format like `parquet` also work with\n",
        "> nested structures.\n",
        "\n",
        "-   First, there is a nested `opendfa` dictionary. Each element of the\n",
        "    dictionary is an array\n",
        "-   A first good idea is to **“flatten” the schema of the DataFrame**,\n",
        "    so that there are no nested types any more.\n",
        "\n",
        "# Flattening a hierarchical schema\n",
        "\n",
        "All the columns in the *nested* structure `openfda` are put up in the\n",
        "schema. These columns nested in the `openfda` are as follows:"
      ],
      "id": "bff17094-10d0-482f-9fd4-ab082665e722"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "['application_number',\n",
              " 'brand_name',\n",
              " 'generic_name',\n",
              " 'is_original_packager',\n",
              " 'manufacturer_name',\n",
              " 'nui',\n",
              " 'original_packager_product_ndc',\n",
              " 'package_ndc',\n",
              " 'pharm_class_cs',\n",
              " 'pharm_class_epc',\n",
              " 'pharm_class_moa',\n",
              " 'pharm_class_pe',\n",
              " 'product_ndc',\n",
              " 'product_type',\n",
              " 'route',\n",
              " 'rxcui',\n",
              " 'spl_id',\n",
              " 'spl_set_id',\n",
              " 'substance_name',\n",
              " 'unii',\n",
              " 'upc']"
            ]
          }
        }
      ],
      "source": [
        "(\n",
        "    df\n",
        "        .select('openfda.*')\n",
        "        .columns\n",
        ")"
      ],
      "id": "501c1894"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------+------------+--------------------+-----------------+----+-----------------------------+-----------+--------------+---------------+---------------+--------------+-----------+------------+-----+-----+------+----------+--------------+----+----+\n",
            "|application_number|brand_name|generic_name|is_original_packager|manufacturer_name| nui|original_packager_product_ndc|package_ndc|pharm_class_cs|pharm_class_epc|pharm_class_moa|pharm_class_pe|product_ndc|product_type|route|rxcui|spl_id|spl_set_id|substance_name|unii| upc|\n",
            "+------------------+----------+------------+--------------------+-----------------+----+-----------------------------+-----------+--------------+---------------+---------------+--------------+-----------+------------+-----+-----+------+----------+--------------+----+----+\n",
            "|              NULL|      NULL|        NULL|                NULL|             NULL|NULL|                         NULL|       NULL|          NULL|           NULL|           NULL|          NULL|       NULL|        NULL| NULL| NULL|  NULL|      NULL|          NULL|NULL|NULL|\n",
            "|              NULL|      NULL|        NULL|                NULL|             NULL|NULL|                         NULL|       NULL|          NULL|           NULL|           NULL|          NULL|       NULL|        NULL| NULL| NULL|  NULL|      NULL|          NULL|NULL|NULL|\n",
            "+------------------+----------+------------+--------------------+-----------------+----+-----------------------------+-----------+--------------+---------------+---------------+--------------+-----------+------------+-----+-----+------+----------+--------------+----+----+\n",
            "only showing top 2 rows"
          ]
        }
      ],
      "source": [
        "df.select(\"openfda.*\").show(2)"
      ],
      "id": "2de61d1f"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "for c in df.select(\"openfda.*\").columns:\n",
        "    df = df.withColumn(\"openfda_\" + c, col(\"openfda.\" + c))"
      ],
      "id": "24982a00"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.select([c for c in df.columns if c != \"openfda\"])"
      ],
      "id": "7d2c687e"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address_1: string (nullable = true)\n",
            " |-- address_2: string (nullable = true)\n",
            " |-- center_classification_date: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- classification: string (nullable = true)\n",
            " |-- code_info: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- distribution_pattern: string (nullable = true)\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- initial_firm_notification: string (nullable = true)\n",
            " |-- more_code_info: string (nullable = true)\n",
            " |-- postal_code: string (nullable = true)\n",
            " |-- product_description: string (nullable = true)\n",
            " |-- product_quantity: string (nullable = true)\n",
            " |-- product_type: string (nullable = true)\n",
            " |-- reason_for_recall: string (nullable = true)\n",
            " |-- recall_initiation_date: string (nullable = true)\n",
            " |-- recall_number: string (nullable = true)\n",
            " |-- recalling_firm: string (nullable = true)\n",
            " |-- report_date: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- termination_date: string (nullable = true)\n",
            " |-- voluntary_mandated: string (nullable = true)\n",
            " |-- openfda_application_number: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_brand_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_generic_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_is_original_packager: array (nullable = true)\n",
            " |    |-- element: boolean (containsNull = true)\n",
            " |-- openfda_manufacturer_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_nui: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_original_packager_product_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_package_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_cs: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_epc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_moa: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_pe: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_product_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_product_type: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_route: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_rxcui: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_spl_id: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_spl_set_id: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_substance_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_unii: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_upc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ],
      "id": "0095cd3c"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26/02/16 10:10:59 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'."
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "[Row(address_1='8 Joanna Ct', address_2='', center_classification_date='20121025', city='East Brunswick', classification='Class II', code_info='Lots a) 15952, 16270,16425, Exp 06/15; b)16459, 16466, 16467, Exp 07/15', country='United States', distribution_pattern='Nationwide', event_id='63384', initial_firm_notification='E-Mail', more_code_info=None, postal_code='08816-2108', product_description='Wal-Mucil 100% Natural Fiber, 100% Natural Psyllium Seed Husk, Fiber Laxative/Supplement, a)160 capsules per bottle (item #503663), and b) 320 capsules per bottle (Item #586143), Distributed by: Walgreen Co., 200 Wilmot Road, Deerfield, IL 60015-4616, www.walgreens.com, a) UPC 3-11917-08151-9, b) UPC 3-11917-07658-4', product_quantity='56,808 bottles', product_type='Drugs', reason_for_recall='Microbial Contamination of Non-Sterile Products: Product is being recalled due to possible microbial contamination by C. difficile discovered in the raw material.', recall_initiation_date='20120904', recall_number='D-026-2013', recalling_firm='Raritan Pharmaceuticals, Inc.', report_date='20121031', state='NJ', status='Terminated', termination_date='20141007', voluntary_mandated='Voluntary: Firm Initiated', openfda_application_number=None, openfda_brand_name=None, openfda_generic_name=None, openfda_is_original_packager=None, openfda_manufacturer_name=None, openfda_nui=None, openfda_original_packager_product_ndc=None, openfda_package_ndc=None, openfda_pharm_class_cs=None, openfda_pharm_class_epc=None, openfda_pharm_class_moa=None, openfda_pharm_class_pe=None, openfda_product_ndc=None, openfda_product_type=None, openfda_route=None, openfda_rxcui=None, openfda_spl_id=None, openfda_spl_set_id=None, openfda_substance_name=None, openfda_unii=None, openfda_upc=None),\n",
              " Row(address_1='8 Joanna Ct', address_2='', center_classification_date='20121025', city='East Brunswick', classification='Class II', code_info='Lot 15087, Exp 08/15', country='United States', distribution_pattern='Nationwide', event_id='63384', initial_firm_notification='E-Mail', more_code_info=None, postal_code='08816-2108', product_description='Premier Value Fiber Plus Calcium Supplement Capsules, 120 capsules per bottle, Distributed by: Chain Drug Consortium, LLC, Boca Raton, FL, UPC 8-40986-01987-6', product_quantity='96 bottles', product_type='Drugs', reason_for_recall='Microbial Contamination of Non-Sterile Products: Product is being recalled due to possible microbial contamination by C. difficile discovered in the raw material.', recall_initiation_date='20120904', recall_number='D-031-2013', recalling_firm='Raritan Pharmaceuticals, Inc.', report_date='20121031', state='NJ', status='Terminated', termination_date='20141007', voluntary_mandated='Voluntary: Firm Initiated', openfda_application_number=None, openfda_brand_name=None, openfda_generic_name=None, openfda_is_original_packager=None, openfda_manufacturer_name=None, openfda_nui=None, openfda_original_packager_product_ndc=None, openfda_package_ndc=None, openfda_pharm_class_cs=None, openfda_pharm_class_epc=None, openfda_pharm_class_moa=None, openfda_pharm_class_pe=None, openfda_product_ndc=None, openfda_product_type=None, openfda_route=None, openfda_rxcui=None, openfda_spl_id=None, openfda_spl_set_id=None, openfda_substance_name=None, openfda_unii=None, openfda_upc=None)]"
            ]
          }
        }
      ],
      "source": [
        "df.head(2)"
      ],
      "id": "b02966da"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the display of the `DataFrame` is not as usual… it displays\n",
        "the dataframe like a list of `Row`, since the columns “openfda\\*”\n",
        "contain arrays of varying length\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> A principled approach to schema flattening is embodied in the next\n",
        "> chunk.\n",
        ">\n",
        "> `df.schema` allows us to perform flattening in a programmatic way."
      ],
      "id": "81916730-c4b7-4412-bd0a-6181314e3a47"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "def flatten_schema(df):\n",
        "    # Get fields and their data types\n",
        "    fields = df.schema.fields\n",
        "    \n",
        "    # Flatten array of column names\n",
        "    flat_cols = []\n",
        "    \n",
        "    for field in fields:\n",
        "        # Handle nested structures\n",
        "        if isinstance(field.dataType, StructType):\n",
        "            nested = df.select(field.name + \".*\").columns\n",
        "            flat_cols.extend([field.name + \".\" + x for x in nested])\n",
        "        else:\n",
        "            flat_cols.append(field.name)\n",
        "    \n",
        "    # Select all flattened columns\n",
        "    df_flattened = df.select([col(x).alias(x.replace(\".\",\"_\")) for x in flat_cols])\n",
        "    \n",
        "    return df_flattened"
      ],
      "id": "a4cd9ef8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> This function definition is from `copilot` under the following prompt:\n",
        ">\n",
        ">     How can I flatten the schema of a spark dataframe?"
      ],
      "id": "7585d5b6-3f2d-4616-8a53-e2df4cd65dbd"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address_1: string (nullable = true)\n",
            " |-- address_2: string (nullable = true)\n",
            " |-- center_classification_date: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- classification: string (nullable = true)\n",
            " |-- code_info: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- distribution_pattern: string (nullable = true)\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- initial_firm_notification: string (nullable = true)\n",
            " |-- more_code_info: string (nullable = true)\n",
            " |-- openfda_application_number: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_brand_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_generic_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_is_original_packager: array (nullable = true)\n",
            " |    |-- element: boolean (containsNull = true)\n",
            " |-- openfda_manufacturer_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_nui: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_original_packager_product_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_package_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_cs: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_epc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_moa: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_pharm_class_pe: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_product_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_product_type: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_route: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_rxcui: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_spl_id: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_spl_set_id: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_substance_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_unii: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- openfda_upc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- postal_code: string (nullable = true)\n",
            " |-- product_description: string (nullable = true)\n",
            " |-- product_quantity: string (nullable = true)\n",
            " |-- product_type: string (nullable = true)\n",
            " |-- reason_for_recall: string (nullable = true)\n",
            " |-- recall_initiation_date: string (nullable = true)\n",
            " |-- recall_number: string (nullable = true)\n",
            " |-- recalling_firm: string (nullable = true)\n",
            " |-- report_date: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- termination_date: string (nullable = true)\n",
            " |-- voluntary_mandated: string (nullable = true)\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.json('file://' + os.path.abspath(filename), multiLine=True)\n",
        "\n",
        "df_flat = flatten_schema(df)\n",
        "\n",
        "df_flat.printSchema()"
      ],
      "id": "a21ab200"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
        "\n",
        "messy_schema = StructType([\n",
        "    StructField(\"id\", IntegerType()),\n",
        "    StructField(\"info\", StructType([\n",
        "        StructField(\"name\", StringType()),\n",
        "        StructField(\"age\", IntegerType()),\n",
        "        StructField(\"zoo\", StructType([\n",
        "            StructField(\"cat\", StringType()),\n",
        "            StructField(\"dog\", StringType())\n",
        "        ]))\n",
        "    ]))\n",
        "])"
      ],
      "id": "208bdd2f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**\n",
        ">\n",
        "> This principled approach is not the end of the story. If the schema\n",
        "> exhibits hierarchical nesting, `flatten_schema()` only removes one\n",
        "> level of nesting."
      ],
      "id": "d1225df8-1667-4299-b4ba-f58340bca6bd"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = [(1, (\"John\", 30, (\"Fritz\", \"Medor\"))), (2, (\"Jane\", 25, (\"Grominet\", \"Goofy\")))]\n",
        "\n",
        "very_nested_df = spark.createDataFrame(data, messy_schema)"
      ],
      "id": "129dcff3"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------+-----------------+\n",
            "| id|info_name|info_age|         info_zoo|\n",
            "+---+---------+--------+-----------------+\n",
            "|  1|     John|      30|   {Fritz, Medor}|\n",
            "|  2|     Jane|      25|{Grominet, Goofy}|\n",
            "+---+---------+--------+-----------------+\n"
          ]
        }
      ],
      "source": [
        "flatten_schema(very_nested_df).show()"
      ],
      "id": "5ef3d64d"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- info_name: string (nullable = true)\n",
            " |-- info_age: integer (nullable = true)\n",
            " |-- info_zoo: struct (nullable = true)\n",
            " |    |-- cat: string (nullable = true)\n",
            " |    |-- dog: string (nullable = true)\n"
          ]
        }
      ],
      "source": [
        "flatten_schema(very_nested_df).printSchema()"
      ],
      "id": "75ff84cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Warning**\n",
        ">\n",
        "> copilot pretends that the flattening function above handles nested\n",
        "> structure recursively. This is not the case.\n",
        ">\n",
        "> Fix this\n",
        "\n",
        "# Missing data\n",
        "\n",
        "A strategy can be to remove rows with missing data. `dropna()` has\n",
        "several options, explained below."
      ],
      "id": "f6189f8a-aac8-4b1f-b8d2-b9ed661e8d20"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "2"
            ]
          }
        }
      ],
      "source": [
        "df.dropna().count()"
      ],
      "id": "3ea9ded2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we remove all lines with at least one missing value, we end up with\n",
        "an empty dataframe !"
      ],
      "id": "9e198f51-88d4-4baf-9317-ba782f0c5173"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "11292"
            ]
          }
        }
      ],
      "source": [
        "df.dropna(how='all').count()"
      ],
      "id": "b46aaf03"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`dropna()` accepts the following arguments\n",
        "\n",
        "-   `how`: can be `'any'` or `'all'`. If `'any'`, rows containing any\n",
        "    null values will be dropped entirely (this is the default). If\n",
        "    `'all'`, only rows which are entirely empty will be dropped.\n",
        "\n",
        "-   `thresh`: accepts an integer representing the “threshold” for how\n",
        "    many empty cells a row must have before being dropped. `tresh` is a\n",
        "    middle ground between `how='any'` and `how='all'`. As a result, the\n",
        "    presence of `thresh` will override `how`\n",
        "\n",
        "-   `subset`: accepts a list of column names. When a subset is present,\n",
        "    N/A values will only be checked against the columns whose names are\n",
        "    provided."
      ],
      "id": "ced10569-7ebb-4b52-8776-aacfb5312a0e"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_columns = len(df.columns)"
      ],
      "id": "bfe0919b"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "2"
            ]
          }
        }
      ],
      "source": [
        "df.dropna(thresh=n_columns).count()"
      ],
      "id": "ccdc6945"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "7550"
            ]
          }
        }
      ],
      "source": [
        "df.dropna(thresh=n_columns-1).count()"
      ],
      "id": "0c54edff"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "11292"
            ]
          }
        }
      ],
      "source": [
        "df.dropna(thresh=n_columns-10).count()"
      ],
      "id": "3e133991"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "11292"
            ]
          }
        }
      ],
      "source": [
        "df = df.dropna(subset=['postal_code', 'city', 'country', 'address_1'])\n",
        "df.count()"
      ],
      "id": "3d7e36cb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But before this, let’s count the number of missing value for each column"
      ],
      "id": "000fccce-609b-4608-a396-6ba2946255a5"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For each column we create a new column containing 1 if the value is null and 0 otherwise.\n",
        "# We need to bast Boolean to Int so that we can use fn.sum after\n",
        "for c in df.columns:\n",
        "    # Do not do this for _isnull columns (just in case you run this cell twice...)\n",
        "    if not c.endswith(\"_isnull\"):\n",
        "        df = df.withColumn(c + \"_isnull\", fn.isnull(col(c)).cast('int'))"
      ],
      "id": "3fe393e9"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "Row(address_1='8 Joanna Ct', address_2='', center_classification_date='20121025', city='East Brunswick', classification='Class II', code_info='Lots a) 15952, 16270,16425, Exp 06/15; b)16459, 16466, 16467, Exp 07/15', country='United States', distribution_pattern='Nationwide', event_id='63384', initial_firm_notification='E-Mail', more_code_info=None, openfda=Row(application_number=None, brand_name=None, generic_name=None, is_original_packager=None, manufacturer_name=None, nui=None, original_packager_product_ndc=None, package_ndc=None, pharm_class_cs=None, pharm_class_epc=None, pharm_class_moa=None, pharm_class_pe=None, product_ndc=None, product_type=None, route=None, rxcui=None, spl_id=None, spl_set_id=None, substance_name=None, unii=None, upc=None), postal_code='08816-2108', product_description='Wal-Mucil 100% Natural Fiber, 100% Natural Psyllium Seed Husk, Fiber Laxative/Supplement, a)160 capsules per bottle (item #503663), and b) 320 capsules per bottle (Item #586143), Distributed by: Walgreen Co., 200 Wilmot Road, Deerfield, IL 60015-4616, www.walgreens.com, a) UPC 3-11917-08151-9, b) UPC 3-11917-07658-4', product_quantity='56,808 bottles', product_type='Drugs', reason_for_recall='Microbial Contamination of Non-Sterile Products: Product is being recalled due to possible microbial contamination by C. difficile discovered in the raw material.', recall_initiation_date='20120904', recall_number='D-026-2013', recalling_firm='Raritan Pharmaceuticals, Inc.', report_date='20121031', state='NJ', status='Terminated', termination_date='20141007', voluntary_mandated='Voluntary: Firm Initiated', address_1_isnull=0, address_2_isnull=0, center_classification_date_isnull=0, city_isnull=0, classification_isnull=0, code_info_isnull=0, country_isnull=0, distribution_pattern_isnull=0, event_id_isnull=0, initial_firm_notification_isnull=0, more_code_info_isnull=1, openfda_isnull=0, postal_code_isnull=0, product_description_isnull=0, product_quantity_isnull=0, product_type_isnull=0, reason_for_recall_isnull=0, recall_initiation_date_isnull=0, recall_number_isnull=0, recalling_firm_isnull=0, report_date_isnull=0, state_isnull=0, status_isnull=0, termination_date_isnull=0, voluntary_mandated_isnull=0)"
            ]
          }
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "816c5688"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "# Get the list of _isnull columns\n",
        "isnull_columns = [c for c in df.columns if c.endswith(\"_isnull\")]\n",
        "\n",
        "# On the _isnull columns :\n",
        "#  - we compute the sum to have the number of null values and rename the column\n",
        "#  - convert to pandas for better readability\n",
        "#  - transpose the pandas dataframe for better readability\n",
        "missing_values = df.select(isnull_columns)\\\n",
        "    .agg(*[fn.sum(c).alias(c.replace(\"_isnull\", \"\")) for c in isnull_columns])\\\n",
        "    .toPandas()\n",
        "\n",
        "missing_values.T\\\n",
        "    .rename({0: \"missing values\"}, axis=\"columns\")"
      ],
      "id": "cbc685b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that `more_code_info` is always null and that `termination_date`\n",
        "if often null. Most of the `openfda*` columns are also almost always\n",
        "empty.\n",
        "\n",
        "We can keep only the columns with no missing values"
      ],
      "id": "da7c3ddc-8199-4cb2-b5a4-8e15c64b097d"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This line can seem complicated, run pieces of each to understand\n",
        "kept_columns = list(\n",
        "    missing_values.columns[(missing_values.iloc[0] == 0).values]\n",
        ")"
      ],
      "id": "43179d1e"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_kept = df.select(kept_columns)"
      ],
      "id": "30ec10d5"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "[Row(address_1='8 Joanna Ct', address_2='', city='East Brunswick', classification='Class II', code_info='Lots a) 15952, 16270,16425, Exp 06/15; b)16459, 16466, 16467, Exp 07/15', country='United States', distribution_pattern='Nationwide', event_id='63384', initial_firm_notification='E-Mail', openfda=Row(application_number=None, brand_name=None, generic_name=None, is_original_packager=None, manufacturer_name=None, nui=None, original_packager_product_ndc=None, package_ndc=None, pharm_class_cs=None, pharm_class_epc=None, pharm_class_moa=None, pharm_class_pe=None, product_ndc=None, product_type=None, route=None, rxcui=None, spl_id=None, spl_set_id=None, substance_name=None, unii=None, upc=None), postal_code='08816-2108', product_description='Wal-Mucil 100% Natural Fiber, 100% Natural Psyllium Seed Husk, Fiber Laxative/Supplement, a)160 capsules per bottle (item #503663), and b) 320 capsules per bottle (Item #586143), Distributed by: Walgreen Co., 200 Wilmot Road, Deerfield, IL 60015-4616, www.walgreens.com, a) UPC 3-11917-08151-9, b) UPC 3-11917-07658-4', product_quantity='56,808 bottles', product_type='Drugs', reason_for_recall='Microbial Contamination of Non-Sterile Products: Product is being recalled due to possible microbial contamination by C. difficile discovered in the raw material.', recall_initiation_date='20120904', recall_number='D-026-2013', recalling_firm='Raritan Pharmaceuticals, Inc.', report_date='20121031', state='NJ', status='Terminated', voluntary_mandated='Voluntary: Firm Initiated'),\n",
              " Row(address_1='8 Joanna Ct', address_2='', city='East Brunswick', classification='Class II', code_info='Lot 15087, Exp 08/15', country='United States', distribution_pattern='Nationwide', event_id='63384', initial_firm_notification='E-Mail', openfda=Row(application_number=None, brand_name=None, generic_name=None, is_original_packager=None, manufacturer_name=None, nui=None, original_packager_product_ndc=None, package_ndc=None, pharm_class_cs=None, pharm_class_epc=None, pharm_class_moa=None, pharm_class_pe=None, product_ndc=None, product_type=None, route=None, rxcui=None, spl_id=None, spl_set_id=None, substance_name=None, unii=None, upc=None), postal_code='08816-2108', product_description='Premier Value Fiber Plus Calcium Supplement Capsules, 120 capsules per bottle, Distributed by: Chain Drug Consortium, LLC, Boca Raton, FL, UPC 8-40986-01987-6', product_quantity='96 bottles', product_type='Drugs', reason_for_recall='Microbial Contamination of Non-Sterile Products: Product is being recalled due to possible microbial contamination by C. difficile discovered in the raw material.', recall_initiation_date='20120904', recall_number='D-031-2013', recalling_firm='Raritan Pharmaceuticals, Inc.', report_date='20121031', state='NJ', status='Terminated', voluntary_mandated='Voluntary: Firm Initiated')]"
            ]
          }
        }
      ],
      "source": [
        "df_kept.head(2)"
      ],
      "id": "43b9bf1a"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address_1: string (nullable = true)\n",
            " |-- address_2: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- classification: string (nullable = true)\n",
            " |-- code_info: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- distribution_pattern: string (nullable = true)\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- initial_firm_notification: string (nullable = true)\n",
            " |-- openfda: struct (nullable = true)\n",
            " |    |-- application_number: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- brand_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- generic_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- is_original_packager: array (nullable = true)\n",
            " |    |    |-- element: boolean (containsNull = true)\n",
            " |    |-- manufacturer_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- nui: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- original_packager_product_ndc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- package_ndc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_cs: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_epc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_moa: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- pharm_class_pe: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- product_ndc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- product_type: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- route: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- rxcui: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- spl_id: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- spl_set_id: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- substance_name: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- unii: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |    |-- upc: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- postal_code: string (nullable = true)\n",
            " |-- product_description: string (nullable = true)\n",
            " |-- product_quantity: string (nullable = true)\n",
            " |-- product_type: string (nullable = true)\n",
            " |-- reason_for_recall: string (nullable = true)\n",
            " |-- recall_initiation_date: string (nullable = true)\n",
            " |-- recall_number: string (nullable = true)\n",
            " |-- recalling_firm: string (nullable = true)\n",
            " |-- report_date: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- voluntary_mandated: string (nullable = true)\n"
          ]
        }
      ],
      "source": [
        "df_kept.printSchema()"
      ],
      "id": "987c1652"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "11292"
            ]
          }
        }
      ],
      "source": [
        "df_kept.count()"
      ],
      "id": "e21c0a0d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Filtering by string values\n",
        "\n",
        "Cases from South San Francisco"
      ],
      "id": "627aae2c-9ce0-4919-87ad-035e69c2d417"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "<p>8 rows × 50 columns</p>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.filter(df.city == \"South San Francisco\")\\\n",
        "    .toPandas()"
      ],
      "id": "42128dc7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Caution**\n",
        ">\n",
        "> Once again, we use `.toPandas()` to pretty format the results in the\n",
        "> notebook.\n",
        ">\n",
        "> But it’s a BAD idea to do this if the spark DataFrame is large, since\n",
        "> it requires a `collect()`\n",
        "\n",
        "Aside from filtering strings by a perfect match, there are plenty of\n",
        "other powerful ways to filter by strings in `pyspark` :\n",
        "\n",
        "-   `df.filter(df.city.contains('San Francisco'))`: returns rows where\n",
        "    strings of a column contain a provided substring. In our example,\n",
        "    filtering by rows which contain the substring “San Francisco” would\n",
        "    be a good way to get all rows in San Francisco, instead of just\n",
        "    “South San Francisco”.\n",
        "\n",
        "-   `df.filter(df.city.startswith('San'))`: Returns rows where a string\n",
        "    starts with a provided substring.\n",
        "\n",
        "-   `df.filter(df.city.endswith('ice'))`: Returns rows where a string\n",
        "    starts with a provided substring.\n",
        "\n",
        "-   `df.filter(df.city.isNull())`: Returns rows where values in a\n",
        "    provided column are null.\n",
        "\n",
        "-   `df.filter(df.city.isNotNull())`: Opposite of the above.\n",
        "\n",
        "-   `df.filter(df.city.like('San%'))`: Performs a SQL-like query\n",
        "    containing the LIKE clause.\n",
        "\n",
        "-   `df.filter(df.city.rlike('[A-Z]*ice$'))`: Performs a regexp filter.\n",
        "\n",
        "-   `df.filter(df.city.isin('San Francisco', 'Los Angeles'))`: Looks for\n",
        "    rows where the string value of a column matches any of the provided\n",
        "    strings exactly.\n",
        "\n",
        "You can try some of these to understand"
      ],
      "id": "c746aefe-fc45-429d-a4a2-216e6cef1747"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "<p>78 rows × 50 columns</p>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.filter(df.city.contains('San Francisco'))\\\n",
        "    .toPandas()"
      ],
      "id": "d76adb79"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "<p>75 rows × 50 columns</p>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "(\n",
        "    df.filter(df.city.isin('San Francisco', 'Los Angeles'))\n",
        "      .toPandas()\n",
        ")"
      ],
      "id": "8d4ba6f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Filtering by Date Values\n",
        "\n",
        "In addition to filtering by strings, we can also filter by columns where\n",
        "the values are stored as dates or datetimes (or strings that can be\n",
        "inferred as dates). Perhaps the most useful way to filter dates is by\n",
        "using the `between()` method, which allows us to find results within a\n",
        "certain date range. Here we find all the results which were reported in\n",
        "the years 2013 and 2014:"
      ],
      "id": "7b38bbba-34a3-4c1f-98a3-9859f09c410d"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "<p>2 rows × 50 columns</p>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "( \n",
        "    df\n",
        "        .filter(df.city == \"South San Francisco\")\n",
        "        .filter(df.report_date.between('2013-01-01 00:00:00','2015-03-11 00:00:00'))\n",
        "        .toPandas()\n",
        ")"
      ],
      "id": "3998bbb4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Caution**\n",
        ">\n",
        "> Is Spark smart enough to understand that the string in column\n",
        "> `report_date` contains a date?"
      ],
      "id": "bd18f934-080a-42be-bf96-2b014f872c62"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "<p>0 rows × 50 columns</p>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.filter(df.city == \"South San Francisco\")\\\n",
        "    .filter(df.center_classification_date.between('2013-01-01 00:00:00','2013-12-31 00:00:00'))\\\n",
        "    .toPandas()"
      ],
      "id": "155d630d"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- center_classification_date: string (nullable = true)\n",
            " |-- recall_initiation_date: string (nullable = true)\n",
            " |-- report_date: string (nullable = true)\n",
            " |-- termination_date: string (nullable = true)\n"
          ]
        }
      ],
      "source": [
        "df_dates = df.select([c for c in df.columns if c.endswith(\"date\")])\n",
        "\n",
        "df_dates.printSchema()"
      ],
      "id": "a1400d8f"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+----------------------+-----------+----------------+\n",
            "|center_classification_date|recall_initiation_date|report_date|termination_date|\n",
            "+--------------------------+----------------------+-----------+----------------+\n",
            "|                  20121025|              20120904|   20121031|        20141007|\n",
            "|                  20121025|              20120904|   20121031|        20141007|\n",
            "|                  20121106|              20121015|   20121114|        20130325|\n",
            "|                  20121220|              20121204|   20121226|        20140429|\n",
            "|                  20121231|              20120926|   20130109|        20161007|\n",
            "+--------------------------+----------------------+-----------+----------------+\n",
            "only showing top 5 rows"
          ]
        }
      ],
      "source": [
        "df_dates.show(5)"
      ],
      "id": "85a00d98"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Columns are not dates (`DateType`) but strings (`StringType`). When\n",
        "comparing `report_date` with `'2013-01-01 00:00:00'` and\n",
        "`'2015-03-11 00:00:00'`, we are comparing strings and are lucky enough\n",
        "that in unicode `'-' < '0' < '...' < '9'` so that `2013-....` is less\n",
        "that any string starting with `20130...`, while any string starting with\n",
        "`2013...` is less than any string starting with `2015..`.\n",
        "\n",
        "> **Caution**\n",
        ">\n",
        "> If some field in a Json string is meant to represent a date or a\n",
        "> datetime object, spark should be given a hint.\n",
        ">\n",
        "> Json loaders (from `Python`) as well as the Spark Json reader have\n",
        "> optional arguments that can be used to indicate the date parser to be\n",
        "> used.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> We have to tell the json loader about two things:\n",
        ">\n",
        "> 1.  which columns should be read as dates\n",
        "> 2.  which format should be used for those columns\n",
        ">\n",
        "> The first point can be settled using the `schema` argument of\n",
        "> `.json()` method (see\n",
        "> [Documentation](https://spark.apache.org/docs/3.5.3/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameReader.json.html))"
      ],
      "id": "0dbf1164-dff9-4caf-9d42-78ab45fc66a1"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "ze_schema = df.schema \n",
        "\n",
        "list_fields = []\n",
        "\n",
        "for f in ze_schema.fields:\n",
        "  if f.name.endswith('date'):\n",
        "    list_fields.append(StructField(f.name, DateType(), True))\n",
        "  else:\n",
        "    list_fields.append(f)\n",
        "\n",
        "ze_schema = StructType(list_fields)"
      ],
      "id": "25c882c3"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative syntax using a dictionary of options\n",
        "options = {\n",
        "    \"dateFormat\": \"yyyyMMdd\",\n",
        "    \"multiLine\": \"true\"\n",
        "}\n",
        "\n",
        "df = (\n",
        "    spark.read\n",
        "        .options(**options)\n",
        "        .json('file:///' + os.path.abspath(filename), ze_schema)\n",
        ")"
      ],
      "id": "78a3cc41"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- center_classification_date: date (nullable = true)\n",
            " |-- recall_initiation_date: date (nullable = true)\n",
            " |-- report_date: date (nullable = true)\n",
            " |-- termination_date: date (nullable = true)\n"
          ]
        }
      ],
      "source": [
        "df.select([c for c in df.columns if c.endswith(\"date\")]).printSchema()"
      ],
      "id": "202933f4"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "<p>2 rows × 50 columns</p>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "(\n",
        "df.filter(df.city == \"South San Francisco\")\n",
        "  .filter(df.center_classification_date.between('2013-01-01 00:00:00','2013-12-31 00:00:00'))\n",
        "  .toPandas()\n",
        ")"
      ],
      "id": "f9136b2f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Handling complex types\n",
        "\n",
        "Bridging the gap between tabular and semi-structured data.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> SQL, `R`, `Pandas` …\n",
        "\n",
        "`struct`, `array`, `map`"
      ],
      "id": "87607ef9-bb72-4fe8-ae87-dabb6ee9d6b9"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# struct"
      ],
      "id": "6b7442d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The problems we faced after loading data from the json file pertained to\n",
        "the fact that column `fda` was of complex `StrucType()` type. We shall\n",
        "revisit this dataframe."
      ],
      "id": "46396a29-bd26-4d3d-b67d-46578afbe843"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = spark.read.json('file:///' + os.path.abspath(filename), multiLine=True)"
      ],
      "id": "9ea3ae4d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataframe schema `df.schema` which is of type `StructType` (defined\n",
        "in `pyspark.sql.types`) can be converted to a json string which in turn\n",
        "can be converted into a Python dictionary."
      ],
      "id": "7881c0df-011e-4a9c-bc77-1bf38181a8f2"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = spark.read.json('file:///' + os.path.abspath(filename), multiLine=True)\n",
        "\n",
        "sj = json.loads(df.schema.json())"
      ],
      "id": "08700364"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We equip the dataframe with a primary key"
      ],
      "id": "375246c6-eb17-4401-bbf5-c000c69a2304"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "\n",
        "w = Window.orderBy(col(\"center_classification_date\"))\n",
        "\n",
        "df = (\n",
        "  df\n",
        "    .withColumn(\"row_id\", fn.row_number().over(w))\n",
        ")"
      ],
      "id": "3b6a6f9c"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "[('openfda',\n",
              "  {'fields': [{'metadata': {},\n",
              "     'name': 'application_number',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'brand_name',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'generic_name',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'is_original_packager',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True,\n",
              "      'elementType': 'boolean',\n",
              "      'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'manufacturer_name',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'nui',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'original_packager_product_ndc',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'package_ndc',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'pharm_class_cs',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'pharm_class_epc',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'pharm_class_moa',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'pharm_class_pe',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'product_ndc',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'product_type',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'route',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'rxcui',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'spl_id',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'spl_set_id',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'substance_name',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'unii',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}},\n",
              "    {'metadata': {},\n",
              "     'name': 'upc',\n",
              "     'nullable': True,\n",
              "     'type': {'containsNull': True,\n",
              "      'elementType': 'string',\n",
              "      'type': 'array'}}],\n",
              "   'type': 'struct'})]"
            ]
          }
        }
      ],
      "source": [
        "[(f['name'], f['type'])  \n",
        "    for f in sj['fields'] if not isinstance(f['type'], str)]"
      ],
      "id": "bcfea280"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Column `openfda` has type `StrucType()` with fields with composite type."
      ],
      "id": "5aa24724-ee59-47a6-ad74-8b1bc9572716"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{IntegerType(),\n",
              " StructType([StructField('application_number', ArrayType(StringType(), True), True), StructField('brand_name', ArrayType(StringType(), True), True), StructField('generic_name', ArrayType(StringType(), True), True), StructField('is_original_packager', ArrayType(BooleanType(), True), True), StructField('manufacturer_name', ArrayType(StringType(), True), True), StructField('nui', ArrayType(StringType(), True), True), StructField('original_packager_product_ndc', ArrayType(StringType(), True), True), StructField('package_ndc', ArrayType(StringType(), True), True), StructField('pharm_class_cs', ArrayType(StringType(), True), True), StructField('pharm_class_epc', ArrayType(StringType(), True), True), StructField('pharm_class_moa', ArrayType(StringType(), True), True), StructField('pharm_class_pe', ArrayType(StringType(), True), True), StructField('product_ndc', ArrayType(StringType(), True), True), StructField('product_type', ArrayType(StringType(), True), True), StructField('route', ArrayType(StringType(), True), True), StructField('rxcui', ArrayType(StringType(), True), True), StructField('spl_id', ArrayType(StringType(), True), True), StructField('spl_set_id', ArrayType(StringType(), True), True), StructField('substance_name', ArrayType(StringType(), True), True), StructField('unii', ArrayType(StringType(), True), True), StructField('upc', ArrayType(StringType(), True), True)])}"
            ]
          }
        }
      ],
      "source": [
        "{f.dataType  for f in df.schema.fields if not f.dataType==StringType()}"
      ],
      "id": "d42c1ac3"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'struct'}"
            ]
          }
        }
      ],
      "source": [
        "{f['type']['type']\n",
        "    for f in sj['fields'] if not isinstance(f['type'], str)}"
      ],
      "id": "0a49e8e7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Projecting on `row_id` and `openfda.*` leads to a (partially) flattened\n",
        "datafame, that, thanks to the `row_id` column can be joined with the\n",
        "original dataframe."
      ],
      "id": "8a0ebdc0-151a-4b62-97ab-a3eead424885"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- row_id: integer (nullable = false)\n",
            " |-- application_number: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- brand_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- generic_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- is_original_packager: array (nullable = true)\n",
            " |    |-- element: boolean (containsNull = true)\n",
            " |-- manufacturer_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- nui: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- original_packager_product_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- package_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- pharm_class_cs: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- pharm_class_epc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- pharm_class_moa: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- pharm_class_pe: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- product_ndc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- product_type: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- route: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- rxcui: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- spl_id: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- spl_set_id: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- substance_name: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- unii: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- upc: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n"
          ]
        }
      ],
      "source": [
        "df_proj = df.select('row_id', 'openfda.*')\n",
        "\n",
        "df_proj.printSchema()"
      ],
      "id": "b6a6b37a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect the length of the arrays."
      ],
      "id": "82148ae6-0ade-48b3-9884-51e0bd445ff6"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+------------------+\n",
            "|Max|min|              Mean|\n",
            "+---+---+------------------+\n",
            "|  2|  1|1.0013531799729365|\n",
            "+---+---+------------------+\n"
          ]
        }
      ],
      "source": [
        "# array\n",
        "df_proj.select(\n",
        "    fn.max(fn.size(col(\"application_number\"))).alias(\"Max\"), \n",
        "    fn.min(fn.size(col(\"application_number\"))).alias(\"min\"), \n",
        "    fn.avg(fn.size(col(\"application_number\"))).alias(\"Mean\")).show(1)"
      ],
      "id": "ba3c47d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In some rows, the *size* of the array is `-1` because the field is\n",
        "`NULL`."
      ],
      "id": "28804c98-5371-4e9f-b098-2e4a71dd1c94"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26/02/16 10:11:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "26/02/16 10:11:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "26/02/16 10:11:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "26/02/16 10:11:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "26/02/16 10:11:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|row_id|\n",
            "+------+\n",
            "|  7159|\n",
            "|  7344|\n",
            "+------+\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "  df_proj\n",
        "    .where(fn.size(col(\"application_number\"))>1)\n",
        "    .select(\"row_id\")\n",
        "    .show(5)\n",
        ")"
      ],
      "id": "634226e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An `array` column can be *exploded*. This is like pivoting into long\n",
        "form. The result contains one row per item in the array."
      ],
      "id": "1942c9e7-3bf8-479b-b59f-43b4eab044e6"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26/02/16 10:11:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "26/02/16 10:11:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "26/02/16 10:11:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "26/02/16 10:11:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+\n",
            "|row_id|n_lignes|\n",
            "+------+--------+\n",
            "|  7159|       2|\n",
            "|  7344|       2|\n",
            "+------+--------+\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "  df_proj\n",
        "    .select('row_id', 'application_number')\n",
        "    .withColumn(\"exploded\", \n",
        "                fn.explode(col(\"application_number\")))\n",
        "    .select('row_id', 'exploded')\n",
        "    .groupBy('row_id')\n",
        "    .agg(fn.count('exploded').alias(\"n_lignes\"))\n",
        "    .where(\"n_lignes > 1\")\n",
        "    .show(5)\n",
        ")"
      ],
      "id": "3cb9d71d"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  }
}